{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 出馬表から追切指数を出力するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/Importdata/30_Traning_Score/Traning_Score_20241215.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# 追切CSVファイルのパスを選択\n",
    "file_path = filedialog.askopenfilename(title=\"追切CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"追切CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# 追切CSVファイルを開く\n",
    "traning_df = pd.read_csv(file_path, low_memory=False,encoding='cp932')\n",
    "\n",
    "traning_df = traning_df.copy()\n",
    "\n",
    "# 予想コメントのカラムを「|」で分割\n",
    "split_columns = traning_df['予想コメント'].str.split('|', expand=True)\n",
    "traning_df['日付'] = split_columns[0]\n",
    "traning_df['コース'] = split_columns[1]\n",
    "traning_df['馬場状態'] = split_columns[2]\n",
    "traning_df['騎乗者'] = split_columns[3]\n",
    "traning_df['タイム'] = split_columns[4]\n",
    "traning_df['周回位置'] = split_columns[5]\n",
    "traning_df['脚色'] = split_columns[6]\n",
    "\n",
    "replace_map = {\n",
    "    '南Ｗ': '美Ｗ',\n",
    "    '南Ｄ': '美ダ',\n",
    "    '南ダ': '美ダ',\n",
    "    '南芝': '美芝'\n",
    "}\n",
    "traning_df['コース'] = traning_df['コース'].replace(replace_map)\n",
    "\n",
    "# 7Fから1Fのカラムを np.nan で初期化\n",
    "distance_columns = ['7F', '6F', '5F', '4F', '3F', '2F', '1F']\n",
    "for col in distance_columns:\n",
    "    traning_df[col] = np.nan  # 初期化\n",
    "\n",
    "# 補正タイム用のカラムを追加\n",
    "for col in distance_columns:\n",
    "    traning_df[f'補正_{col}'] = np.nan  # 初期化\n",
    "\n",
    "# 空文字列を NaN に変換\n",
    "traning_df.replace(\"\", pd.NA, inplace=True)\n",
    "\n",
    "# 'コース', '馬場状態', '騎乗者' 列に欠損値がある行を削除（追切データが存在しないレコードを削除）\n",
    "traning_df = traning_df.dropna(subset=['コース', '馬場状態', '騎乗者'])\n",
    "\n",
    "# 各行のタイム情報を適切カラムに配置する処理\n",
    "for index, row in traning_df.iterrows():\n",
    "    times = row['タイム']\n",
    "    if pd.isna(times):\n",
    "        continue\n",
    "\n",
    "    # タイムリストを取得\n",
    "    time_list = times.split('-')\n",
    "    time_length = len(time_list)\n",
    "\n",
    "    # タイムを後ろから順に適切なカラムに配置\n",
    "    for i in range(time_length):\n",
    "        # 数値に変換できるかチェック\n",
    "        try:\n",
    "            traning_df.at[index, distance_columns[-(time_length - i)]] = float(time_list[i])\n",
    "        except ValueError:\n",
    "            # 数値に変換できない場合は NaN を代入\n",
    "            traning_df.at[index, distance_columns[-(time_length - i)]] = np.nan\n",
    "\n",
    "# 周り位置を数値型に変換\n",
    "traning_df['周回位置'] = pd.to_numeric(traning_df['周回位置'], errors='coerce')\n",
    "\n",
    "# タイム補正処理\n",
    "for index, row in traning_df.iterrows():\n",
    "    if not pd.isna(row['周回位置']):\n",
    "        # 補正値を計算\n",
    "        correction_value = (9 - row['周回位置']) * 0.1\n",
    "\n",
    "        # 最も左に存在するタイムを探す\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "\n",
    "            # 全体時計に補正値を加算\n",
    "            traning_df.at[index, f'補正_{leftmost_col}'] = round(row[leftmost_col] + correction_value, 1)\n",
    "\n",
    "            # 残り区間タイムに均等割り振り\n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        traning_df.at[index, f'補正_{col}'] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            # 周回位置があるがタイムが存在しない場合（通常は発生しない想定）\n",
    "            continue\n",
    "    else:\n",
    "        # 周り位置がない場合、元のタイムを補正タイムに転記\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                traning_df.at[index, f'補正_{col}'] = row[col]\n",
    "\n",
    "# 出力に必要なカラムを選択\n",
    "format_df = traning_df[['レースID(新)', '場所', '芝ダ', '距離', '外回り','競走種別C', 'クラスC',\n",
    "                '調教師','調教師コード','コース', '馬場状態', '騎乗者','補正_7F', '補正_6F', '補正_5F', '補正_4F', '補正_3F', '補正_2F', '補正_1F' ,\n",
    "                '周回位置', '脚色']].copy()\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# クラスコードの分類関数\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 114:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 競争種別とクラスコードを書き換え\n",
    "format_df['競走種別C'] = format_df['競走種別C'].apply(categorize_race_type)\n",
    "format_df['クラスC'] = format_df['クラスC'].apply(categorize_class_code)\n",
    "\n",
    "# タイム関連のカラム\n",
    "time_columns = ['補正_7F', '補正_6F', '補正_5F', '補正_4F', '補正_3F', '補正_2F', '補正_1F']\n",
    "\n",
    "# タイム列を数値型に変換（必要に応じてNaNを処理）\n",
    "format_df[time_columns] = format_df[time_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# マージするためにデータフレームのカラムをリネーム\n",
    "format_df = format_df.rename(columns={'芝ダ': '芝・ダ','外回り': '芝(内・外)','競走種別C': '競走種別','クラスC': 'クラスコード'})\n",
    "\n",
    "# 基準タイムファイルを読み込む\n",
    "standardtime_filepath1 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Standard_Traningdata_*.csv'), key=str)\n",
    "standard_time_data1 = pd.read_csv(standardtime_filepath1, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath2 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/41_course_median_Traningdata_*.csv'), key=str)\n",
    "standard_time_data2 = pd.read_csv(standardtime_filepath2, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath3 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/43_class_median_Traningdata_*.csv'), key=str)\n",
    "standard_time_data3 = pd.read_csv(standardtime_filepath3, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath4 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/44_trainer_median_Traningdata_*.csv'), key=str)\n",
    "standard_time_data4 = pd.read_csv(standardtime_filepath4, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath5 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Top20_Traningdata_*.csv'), key=str)\n",
    "standard_time_data5 = pd.read_csv(standardtime_filepath5, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath6 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Top10_Traningdata_*.csv'), key=str)\n",
    "standard_time_data6 = pd.read_csv(standardtime_filepath6, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath7 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/41_course_top20_Traningdata_*.csv'), key=str)\n",
    "standard_time_data7 = pd.read_csv(standardtime_filepath7, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath8 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/41_course_top10_Traningdata_*.csv'), key=str)\n",
    "standard_time_data8 = pd.read_csv(standardtime_filepath8, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath9 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/43_class_top20_Traningdata_*.csv'), key=str)\n",
    "standard_time_data9 = pd.read_csv(standardtime_filepath9, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath10 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/43_class_top10_Traningdata_*.csv'), key=str)\n",
    "standard_time_data10 = pd.read_csv(standardtime_filepath10, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath11 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/44_trainer_top20_Traningdata_*.csv'), key=str)\n",
    "standard_time_data11 = pd.read_csv(standardtime_filepath11, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath12 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/44_trainer_top10_Traningdata_*.csv'), key=str)\n",
    "standard_time_data12 = pd.read_csv(standardtime_filepath12, encoding='utf-8')\n",
    "\n",
    "# マージ条件\n",
    "merge_keys1 = ['コース']\n",
    "merge_keys2 = ['コース', '馬場状態']\n",
    "merge_keys3 = ['競走種別','クラスコード','コース','馬場状態']\n",
    "merge_keys4 = ['調教師コード','コース','馬場状態']\n",
    "\n",
    "# 出馬表データと基準タイムファイル1を結合\n",
    "merged_data = pd.merge(\n",
    "    format_df,\n",
    "    standard_time_data1,\n",
    "    on=merge_keys1,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 偏差値を計算する関数\n",
    "def calculate_deviation(value, mean, std_dev):\n",
    "    if pd.isna(value) or pd.isna(mean) or pd.isna(std_dev) or std_dev == 0:\n",
    "        return np.nan  # 計算できない場合はNaNを返す\n",
    "    return 50 + 10 * (mean - value) / std_dev\n",
    "\n",
    "# 偏差値を計算して新しいカラムを作成\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'\n",
    "    mean_col = col\n",
    "    std_dev_col = f'標準偏差_{col}'\n",
    "    deviation_col = f'偏差値_{col}'\n",
    "    merged_data[deviation_col] = merged_data.apply(\n",
    "        lambda row: calculate_deviation(row[time_col], row[mean_col], row[std_dev_col]), axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル2との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,  # 1つ目の基準タイムとの結合結果\n",
    "    standard_time_data2,\n",
    "    on=merge_keys2,  # マージ条件\n",
    "    how='left',\n",
    "    suffixes=['','_file2']\n",
    ")\n",
    "\n",
    "# 2つ目の基準タイムを基準に偏差値を計算\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 元データの補正タイム\n",
    "    mean_col = f'補正_{col}_file2'  # 基準タイム2の平均タイム\n",
    "    std_dev_col = f'標準偏差_補正_{col}'  # 基準タイム2の標準偏差\n",
    "    deviation_col = f'偏差値_{col}_file2'\n",
    "    merged_data[deviation_col] = merged_data.apply(\n",
    "        lambda row: calculate_deviation(row[time_col], row[mean_col], row[std_dev_col]), axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル3との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data3,\n",
    "    on=merge_keys3,\n",
    "    how='left',\n",
    "    suffixes=('', '_file3')\n",
    ")\n",
    "\n",
    "# 3つ目の基準タイムを基準に偏差値を計算\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 元データの補正タイム\n",
    "    mean_col = f'補正_{col}_file3'  # 基準タイム3の平均タイム\n",
    "    std_dev_col = f'標準偏差_補正_{col}'  # 基準タイム3の標準偏差\n",
    "    deviation_col = f'偏差値_{col}_file3'\n",
    "    merged_data[deviation_col] = merged_data.apply(\n",
    "        lambda row: calculate_deviation(row[time_col], row[mean_col], row[std_dev_col]), axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル4との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data4,\n",
    "    on=merge_keys4,\n",
    "    how='left',\n",
    "    suffixes=('', '_file4')\n",
    ")\n",
    "\n",
    "# 4つ目の基準タイムを基準に偏差値を計算\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 元データの補正タイム\n",
    "    mean_col = f'補正_{col}_file4'  # 基準タイム4の平均タイム\n",
    "    std_dev_col = f'標準偏差_補正_{col}'  # 基準タイム4の標準偏差\n",
    "    deviation_col = f'偏差値_{col}_file4'\n",
    "    merged_data[deviation_col] = merged_data.apply(\n",
    "        lambda row: calculate_deviation(row[time_col], row[mean_col], row[std_dev_col]), axis=1\n",
    "    )\n",
    "\n",
    "# 総合偏差値を計算\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    deviation_col1 = f'偏差値_{col}'  # 1つ目の基準タイム偏差値\n",
    "    deviation_col2 = f'偏差値_{col}_file2'  # 2つ目の基準タイム偏差値\n",
    "    deviation_col3 = f'偏差値_{col}_file3'  # 2つ目の基準タイム偏差値\n",
    "    deviation_col4 = f'偏差値_{col}_file4'  # 2つ目の基準タイム偏差値\n",
    "    overall_deviation_col = f'総合偏差値_{col}'  # 総合偏差値のカラム名\n",
    "    merged_data[overall_deviation_col] = merged_data[[deviation_col1, deviation_col2,deviation_col3,deviation_col4]].mean(axis=1)\n",
    "    \n",
    "# 加点を計算する関数\n",
    "def calculate_bonus(value, mean, is_saka, col):\n",
    "    \"\"\"\n",
    "    value: 補正タイム\n",
    "    mean: 基準タイム\n",
    "    is_saka: 坂路コースかどうか\n",
    "    col: 対象のハロンカラム（例: '4F', '2F', '1F'）\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or pd.isna(mean):\n",
    "        return 0  # 比較できない場合は加点なし\n",
    "\n",
    "    # 坂路と周回コースで加点基準を分ける\n",
    "    if is_saka:\n",
    "        if col == '4F':\n",
    "            return 0.5 if value < mean else 0\n",
    "        elif col == '2F':\n",
    "            return 1.5 if value < mean else 0\n",
    "        elif col == '1F':\n",
    "            return 1.0 if value < mean else 0\n",
    "    else:\n",
    "        if col == '4F':\n",
    "            return 0.5 if value < mean else 0\n",
    "        elif col == '2F':\n",
    "            return 1.0 if value < mean else 0\n",
    "        elif col == '1F':\n",
    "            return 1.5 if value < mean else 0\n",
    "    return 0\n",
    "\n",
    "# 基準タイムファイル5との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data5,\n",
    "    on=merge_keys1,\n",
    "    how='left',\n",
    "    suffixes=('', '_file5')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file5'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'{col}_file5'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file5'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル6との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data6,\n",
    "    on=merge_keys1,\n",
    "    how='left',\n",
    "    suffixes=('', '_file6')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file6'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'{col}_file6'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file6'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル7との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data7,\n",
    "    on=merge_keys2,\n",
    "    how='left',\n",
    "    suffixes=('', '_file7')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file7'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file7'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file7'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル8との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data8,\n",
    "    on=merge_keys2,\n",
    "    how='left',\n",
    "    suffixes=('', '_file8')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file8'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file8'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file8'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル9との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data9,\n",
    "    on=merge_keys3,\n",
    "    how='left',\n",
    "    suffixes=('', '_file9')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file9'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file9'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file9'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル10との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data10,\n",
    "    on=merge_keys3,\n",
    "    how='left',\n",
    "    suffixes=('', '_file10')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file10'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file10'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file10'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル11との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data11,\n",
    "    on=merge_keys4,\n",
    "    how='left',\n",
    "    suffixes=('', '_file11')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file11'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file11'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file11'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル12との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data12,\n",
    "    on=merge_keys4,\n",
    "    how='left',\n",
    "    suffixes=('', '_file12')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file12'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file12'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file12'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 総合スコアのカラムを動的に抽出\n",
    "score_columns1 = [col for col in merged_data.columns if col.startswith('総合偏差値_')]\n",
    "score_columns2 = [col for col in merged_data.columns if col.startswith('加点_')]\n",
    "\n",
    "# 加点スコアのカラムを合計して「総合加点スコア」を作成\n",
    "merged_data['総合偏差値スコア'] = merged_data[score_columns1].mean(axis=1)\n",
    "merged_data['総合加点スコア'] = merged_data[score_columns2].sum(axis=1)\n",
    "\n",
    "# '騎乗者係数'を追加\n",
    "def assign_rider_coefficient(rider):\n",
    "    if rider == '助手':\n",
    "        return 1\n",
    "    elif rider == '見習':\n",
    "        return 0.8\n",
    "    else:\n",
    "        return 0.9\n",
    "\n",
    "merged_data['騎乗者係数'] = merged_data['騎乗者'].apply(assign_rider_coefficient)\n",
    "\n",
    "# '脚色係数'を追加\n",
    "def assign_leg_action_coefficient(action):\n",
    "    if pd.isna(action):  # 欠損値を確認\n",
    "        return 0.9  # デフォルト値（他の場合と同じ処理）\n",
    "    elif action == '馬也':\n",
    "        return 1.1\n",
    "    elif 'Ｇ' in str(action):  # NaNを回避するためにstr変換\n",
    "        return 1.0\n",
    "    elif '強' in str(action):  # NaNを回避するためにstr変換\n",
    "        return 1.0\n",
    "    elif action == '一杯':\n",
    "        return 0.8\n",
    "    else:\n",
    "        return 0.9  # 上記以外の場合\n",
    "\n",
    "merged_data['脚色係数'] = merged_data['脚色'].apply(assign_leg_action_coefficient)\n",
    "\n",
    "# 追切指数を計算する関数\n",
    "def calculate_training_index(row):\n",
    "    base_score = row['総合偏差値スコア'] + row['総合加点スコア']\n",
    "    adjusted_score = base_score * row['騎乗者係数'] * row['脚色係数']\n",
    "    return adjusted_score\n",
    "\n",
    "# 追切指数の計算\n",
    "merged_data['追切指数'] = merged_data.apply(calculate_training_index, axis=1)\n",
    "\n",
    "# 非有限値を置き換える\n",
    "merged_data['追切指数'] = merged_data['追切指数'].replace([np.inf, -np.inf], np.nan)  # 無限値をNaNに置換\n",
    "merged_data['追切指数'] = merged_data['追切指数'].fillna(1)  # NaNを1に置換\n",
    "\n",
    "# 整数化とクリップ処理\n",
    "merged_data['追切指数'] = merged_data['追切指数'].round(0).clip(lower=1, upper=99).astype(int)\n",
    "\n",
    "merged_data = merged_data[['レースID(新)','追切指数']]\n",
    "\n",
    "output_path1 = f'D:/Keiba/Importdata/30_Traning_Score/Traning_Score_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "merged_data.to_csv(output_path1, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path1}に保存しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 成績データファイルから追切指数を出力するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/Importdata/30_Traning_Score/Traning_Score_all_20241215.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# 追切CSVファイルのパスを選択\n",
    "file_path = filedialog.askopenfilename(title=\"追切CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"追切CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# 追切CSVファイルを開く\n",
    "traning_df = pd.read_csv(file_path, low_memory=False,encoding='cp932')\n",
    "\n",
    "traning_df = traning_df.copy()\n",
    "\n",
    "# 予想コメントのカラムを「|」で分割\n",
    "split_columns = traning_df['予想コメント'].str.split('|', expand=True)\n",
    "traning_df['日付'] = split_columns[0]\n",
    "traning_df['コース'] = split_columns[1]\n",
    "traning_df['馬場状態'] = split_columns[2]\n",
    "traning_df['騎乗者'] = split_columns[3]\n",
    "traning_df['タイム'] = split_columns[4]\n",
    "traning_df['周回位置'] = split_columns[5]\n",
    "traning_df['脚色'] = split_columns[6]\n",
    "\n",
    "replace_map = {\n",
    "    '南Ｗ': '美Ｗ',\n",
    "    '南Ｄ': '美ダ',\n",
    "    '南ダ': '美ダ',\n",
    "    '南芝': '美芝'\n",
    "}\n",
    "traning_df['コース'] = traning_df['コース'].replace(replace_map)\n",
    "\n",
    "# 7Fから1Fのカラムを np.nan で初期化\n",
    "distance_columns = ['7F', '6F', '5F', '4F', '3F', '2F', '1F']\n",
    "for col in distance_columns:\n",
    "    traning_df[col] = np.nan  # 初期化\n",
    "\n",
    "# 補正タイム用のカラムを追加\n",
    "for col in distance_columns:\n",
    "    traning_df[f'補正_{col}'] = np.nan  # 初期化\n",
    "\n",
    "# 空文字列を NaN に変換\n",
    "traning_df.replace(\"\", pd.NA, inplace=True)\n",
    "\n",
    "# 'コース', '馬場状態', '騎乗者' 列に欠損値がある行を削除（追切データが存在しないレコードを削除）\n",
    "traning_df = traning_df.dropna(subset=['コース', '馬場状態', '騎乗者'])\n",
    "\n",
    "# 各行のタイム情報を適切カラムに配置する処理\n",
    "for index, row in traning_df.iterrows():\n",
    "    times = row['タイム']\n",
    "    if pd.isna(times):\n",
    "        continue\n",
    "\n",
    "    # タイムリストを取得\n",
    "    time_list = times.split('-')\n",
    "    time_length = len(time_list)\n",
    "\n",
    "    # タイムを後ろから順に適切なカラムに配置\n",
    "    for i in range(time_length):\n",
    "        # 数値に変換できるかチェック\n",
    "        try:\n",
    "            traning_df.at[index, distance_columns[-(time_length - i)]] = float(time_list[i])\n",
    "        except ValueError:\n",
    "            # 数値に変換できない場合は NaN を代入\n",
    "            traning_df.at[index, distance_columns[-(time_length - i)]] = np.nan\n",
    "\n",
    "# 周り位置を数値型に変換\n",
    "traning_df['周回位置'] = pd.to_numeric(traning_df['周回位置'], errors='coerce')\n",
    "\n",
    "# タイム補正処理\n",
    "for index, row in traning_df.iterrows():\n",
    "    if not pd.isna(row['周回位置']):\n",
    "        # 補正値を計算\n",
    "        correction_value = (9 - row['周回位置']) * 0.1\n",
    "\n",
    "        # 最も左に存在するタイムを探す\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "\n",
    "            # 全体時計に補正値を加算\n",
    "            traning_df.at[index, f'補正_{leftmost_col}'] = round(row[leftmost_col] + correction_value, 1)\n",
    "\n",
    "            # 残り区間タイムに均等割り振り\n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        traning_df.at[index, f'補正_{col}'] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            # 周回位置があるがタイムが存在しない場合（通常は発生しない想定）\n",
    "            continue\n",
    "    else:\n",
    "        # 周り位置がない場合、元のタイムを補正タイムに転記\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                traning_df.at[index, f'補正_{col}'] = row[col]\n",
    "\n",
    "# 出力に必要なカラムを選択\n",
    "format_df = traning_df[['レースID(新)', '場所', '芝・ダ', '距離', '芝(内・外)','競走種別', 'クラスコード',\n",
    "                '調教師','調教師コード','コース', '馬場状態', '騎乗者','補正_7F', '補正_6F', '補正_5F', '補正_4F', '補正_3F', '補正_2F', '補正_1F' ,\n",
    "                '周回位置', '脚色']].copy()\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# クラスコードの分類関数\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 114:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 競争種別とクラスコードを書き換え\n",
    "format_df['競走種別'] = format_df['競走種別'].apply(categorize_race_type)\n",
    "format_df['クラスコード'] = format_df['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "# タイム関連のカラム\n",
    "time_columns = ['補正_7F', '補正_6F', '補正_5F', '補正_4F', '補正_3F', '補正_2F', '補正_1F']\n",
    "\n",
    "# タイム列を数値型に変換（必要に応じてNaNを処理）\n",
    "format_df[time_columns] = format_df[time_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# マージするためにデータフレームのカラムをリネーム\n",
    "##format_df = format_df.rename(columns={'芝ダ': '芝・ダ','外回り': '芝(内・外)','競走種別C': '競走種別','クラスC': 'クラスコード'})\n",
    "\n",
    "# 基準タイムファイルを読み込む\n",
    "standardtime_filepath1 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Standard_Traningdata_*.csv'), key=str)\n",
    "standard_time_data1 = pd.read_csv(standardtime_filepath1, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath2 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/41_course_median_Traningdata_*.csv'), key=str)\n",
    "standard_time_data2 = pd.read_csv(standardtime_filepath2, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath3 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/43_class_median_Traningdata_*.csv'), key=str)\n",
    "standard_time_data3 = pd.read_csv(standardtime_filepath3, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath4 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/44_trainer_median_Traningdata_*.csv'), key=str)\n",
    "standard_time_data4 = pd.read_csv(standardtime_filepath4, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath5 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Top20_Traningdata_*.csv'), key=str)\n",
    "standard_time_data5 = pd.read_csv(standardtime_filepath5, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath6 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Top10_Traningdata_*.csv'), key=str)\n",
    "standard_time_data6 = pd.read_csv(standardtime_filepath6, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath7 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/41_course_top20_Traningdata_*.csv'), key=str)\n",
    "standard_time_data7 = pd.read_csv(standardtime_filepath7, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath8 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/41_course_top10_Traningdata_*.csv'), key=str)\n",
    "standard_time_data8 = pd.read_csv(standardtime_filepath8, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath9 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/43_class_top20_Traningdata_*.csv'), key=str)\n",
    "standard_time_data9 = pd.read_csv(standardtime_filepath9, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath10 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/43_class_top10_Traningdata_*.csv'), key=str)\n",
    "standard_time_data10 = pd.read_csv(standardtime_filepath10, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath11 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/44_trainer_top20_Traningdata_*.csv'), key=str)\n",
    "standard_time_data11 = pd.read_csv(standardtime_filepath11, encoding='utf-8')\n",
    "\n",
    "standardtime_filepath12 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/44_trainer_top10_Traningdata_*.csv'), key=str)\n",
    "standard_time_data12 = pd.read_csv(standardtime_filepath12, encoding='utf-8')\n",
    "\n",
    "# マージ条件\n",
    "merge_keys1 = ['コース']\n",
    "merge_keys2 = ['コース', '馬場状態']\n",
    "merge_keys3 = ['競走種別','クラスコード','コース','馬場状態']\n",
    "merge_keys4 = ['調教師コード','コース','馬場状態']\n",
    "\n",
    "# 出馬表データと基準タイムファイル1を結合\n",
    "merged_data = pd.merge(\n",
    "    format_df,\n",
    "    standard_time_data1,\n",
    "    on=merge_keys1,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 偏差値を計算する関数\n",
    "def calculate_deviation(value, mean, std_dev):\n",
    "    if pd.isna(value) or pd.isna(mean) or pd.isna(std_dev) or std_dev == 0:\n",
    "        return np.nan  # 計算できない場合はNaNを返す\n",
    "    return 50 + 10 * (mean - value) / std_dev\n",
    "\n",
    "# 偏差値を計算して新しいカラムを作成\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'\n",
    "    mean_col = col\n",
    "    std_dev_col = f'標準偏差_{col}'\n",
    "    deviation_col = f'偏差値_{col}'\n",
    "    merged_data[deviation_col] = merged_data.apply(\n",
    "        lambda row: calculate_deviation(row[time_col], row[mean_col], row[std_dev_col]), axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル2との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,  # 1つ目の基準タイムとの結合結果\n",
    "    standard_time_data2,\n",
    "    on=merge_keys2,  # マージ条件\n",
    "    how='left',\n",
    "    suffixes=['','_file2']\n",
    ")\n",
    "\n",
    "# 2つ目の基準タイムを基準に偏差値を計算\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 元データの補正タイム\n",
    "    mean_col = f'補正_{col}_file2'  # 基準タイム2の平均タイム\n",
    "    std_dev_col = f'標準偏差_補正_{col}'  # 基準タイム2の標準偏差\n",
    "    deviation_col = f'偏差値_{col}_file2'\n",
    "    merged_data[deviation_col] = merged_data.apply(\n",
    "        lambda row: calculate_deviation(row[time_col], row[mean_col], row[std_dev_col]), axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル3との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data3,\n",
    "    on=merge_keys3,\n",
    "    how='left',\n",
    "    suffixes=('', '_file3')\n",
    ")\n",
    "\n",
    "# 3つ目の基準タイムを基準に偏差値を計算\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 元データの補正タイム\n",
    "    mean_col = f'補正_{col}_file3'  # 基準タイム3の平均タイム\n",
    "    std_dev_col = f'標準偏差_補正_{col}'  # 基準タイム3の標準偏差\n",
    "    deviation_col = f'偏差値_{col}_file3'\n",
    "    merged_data[deviation_col] = merged_data.apply(\n",
    "        lambda row: calculate_deviation(row[time_col], row[mean_col], row[std_dev_col]), axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル4との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data4,\n",
    "    on=merge_keys4,\n",
    "    how='left',\n",
    "    suffixes=('', '_file4')\n",
    ")\n",
    "\n",
    "# 4つ目の基準タイムを基準に偏差値を計算\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 元データの補正タイム\n",
    "    mean_col = f'補正_{col}_file4'  # 基準タイム4の平均タイム\n",
    "    std_dev_col = f'標準偏差_補正_{col}'  # 基準タイム4の標準偏差\n",
    "    deviation_col = f'偏差値_{col}_file4'\n",
    "    merged_data[deviation_col] = merged_data.apply(\n",
    "        lambda row: calculate_deviation(row[time_col], row[mean_col], row[std_dev_col]), axis=1\n",
    "    )\n",
    "\n",
    "# 総合偏差値を計算\n",
    "for col in ['5F', '4F', '3F', '2F', '1F']:\n",
    "    deviation_col1 = f'偏差値_{col}'  # 1つ目の基準タイム偏差値\n",
    "    deviation_col2 = f'偏差値_{col}_file2'  # 2つ目の基準タイム偏差値\n",
    "    deviation_col3 = f'偏差値_{col}_file3'  # 2つ目の基準タイム偏差値\n",
    "    deviation_col4 = f'偏差値_{col}_file4'  # 2つ目の基準タイム偏差値\n",
    "    overall_deviation_col = f'総合偏差値_{col}'  # 総合偏差値のカラム名\n",
    "    merged_data[overall_deviation_col] = merged_data[[deviation_col1, deviation_col2,deviation_col3,deviation_col4]].mean(axis=1)\n",
    "    \n",
    "# 加点を計算する関数\n",
    "def calculate_bonus(value, mean, is_saka, col):\n",
    "    \"\"\"\n",
    "    value: 補正タイム\n",
    "    mean: 基準タイム\n",
    "    is_saka: 坂路コースかどうか\n",
    "    col: 対象のハロンカラム（例: '4F', '2F', '1F'）\n",
    "    \"\"\"\n",
    "    if pd.isna(value) or pd.isna(mean):\n",
    "        return 0  # 比較できない場合は加点なし\n",
    "\n",
    "    # 坂路と周回コースで加点基準を分ける\n",
    "    if is_saka:\n",
    "        if col == '4F':\n",
    "            return 0.5 if value < mean else 0\n",
    "        elif col == '2F':\n",
    "            return 1.5 if value < mean else 0\n",
    "        elif col == '1F':\n",
    "            return 1.0 if value < mean else 0\n",
    "    else:\n",
    "        if col == '4F':\n",
    "            return 0.5 if value < mean else 0\n",
    "        elif col == '2F':\n",
    "            return 1.0 if value < mean else 0\n",
    "        elif col == '1F':\n",
    "            return 1.5 if value < mean else 0\n",
    "    return 0\n",
    "\n",
    "# 基準タイムファイル5との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data5,\n",
    "    on=merge_keys1,\n",
    "    how='left',\n",
    "    suffixes=('', '_file5')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file5'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'{col}_file5'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file5'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル6との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data6,\n",
    "    on=merge_keys1,\n",
    "    how='left',\n",
    "    suffixes=('', '_file6')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file6'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'{col}_file6'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file6'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル7との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data7,\n",
    "    on=merge_keys2,\n",
    "    how='left',\n",
    "    suffixes=('', '_file7')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file7'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file7'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file7'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル8との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data8,\n",
    "    on=merge_keys2,\n",
    "    how='left',\n",
    "    suffixes=('', '_file8')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file8'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file8'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file8'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル9との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data9,\n",
    "    on=merge_keys3,\n",
    "    how='left',\n",
    "    suffixes=('', '_file9')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file9'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file9'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file9'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル10との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data10,\n",
    "    on=merge_keys3,\n",
    "    how='left',\n",
    "    suffixes=('', '_file10')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file10'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file10'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file10'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル11との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data11,\n",
    "    on=merge_keys4,\n",
    "    how='left',\n",
    "    suffixes=('', '_file11')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file11'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file11'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file11'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 基準タイムファイル12との結合\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    standard_time_data12,\n",
    "    on=merge_keys4,\n",
    "    how='left',\n",
    "    suffixes=('', '_file12')\n",
    ")\n",
    "\n",
    "# 加点用のカラムを初期化\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    merged_data[f'加点_{col}_file12'] = 0  # 初期値を0に設定\n",
    "\n",
    "# '坂'を含むコースかどうかを判定し、加点を適用\n",
    "for col in ['4F', '2F', '1F']:\n",
    "    time_col = f'補正_{col}'  # 補正タイム\n",
    "    mean_col = f'補正_{col}_file12'  # 上位20%基準タイム\n",
    "    \n",
    "    # 加点計算を適用\n",
    "    merged_data[f'加点_{col}_file12'] = merged_data.apply(\n",
    "        lambda row: calculate_bonus(row[time_col], row[mean_col], '坂' in row['コース'] if not pd.isna(row['コース']) else False, col),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "# 総合スコアのカラムを動的に抽出\n",
    "score_columns1 = [col for col in merged_data.columns if col.startswith('総合偏差値_')]\n",
    "score_columns2 = [col for col in merged_data.columns if col.startswith('加点_')]\n",
    "\n",
    "# 加点スコアのカラムを合計して「総合加点スコア」を作成\n",
    "merged_data['総合偏差値スコア'] = merged_data[score_columns1].mean(axis=1)\n",
    "merged_data['総合加点スコア'] = merged_data[score_columns2].sum(axis=1)\n",
    "\n",
    "# '騎乗者係数'を追加\n",
    "def assign_rider_coefficient(rider):\n",
    "    if rider == '助手':\n",
    "        return 1\n",
    "    elif rider == '見習':\n",
    "        return 0.8\n",
    "    else:\n",
    "        return 0.9\n",
    "\n",
    "merged_data['騎乗者係数'] = merged_data['騎乗者'].apply(assign_rider_coefficient)\n",
    "\n",
    "# '脚色係数'を追加\n",
    "def assign_leg_action_coefficient(action):\n",
    "    if pd.isna(action):  # 欠損値を確認\n",
    "        return 0.9  # デフォルト値（他の場合と同じ処理）\n",
    "    elif action == '馬也':\n",
    "        return 1.1\n",
    "    elif 'Ｇ' in str(action):  # NaNを回避するためにstr変換\n",
    "        return 1.0\n",
    "    elif '強' in str(action):  # NaNを回避するためにstr変換\n",
    "        return 1.0\n",
    "    elif action == '一杯':\n",
    "        return 0.8\n",
    "    else:\n",
    "        return 0.9  # 上記以外の場合\n",
    "\n",
    "merged_data['脚色係数'] = merged_data['脚色'].apply(assign_leg_action_coefficient)\n",
    "\n",
    "# 追切指数を計算する関数\n",
    "def calculate_training_index(row):\n",
    "    base_score = row['総合偏差値スコア'] + row['総合加点スコア']\n",
    "    adjusted_score = base_score * row['騎乗者係数'] * row['脚色係数']\n",
    "    return adjusted_score\n",
    "\n",
    "# 追切指数の計算\n",
    "merged_data['追切指数'] = merged_data.apply(calculate_training_index, axis=1)\n",
    "\n",
    "# 非有限値を置き換える\n",
    "merged_data['追切指数'] = merged_data['追切指数'].replace([np.inf, -np.inf], np.nan)  # 無限値をNaNに置換\n",
    "merged_data['追切指数'] = merged_data['追切指数'].fillna(1)  # NaNを1に置換\n",
    "\n",
    "# 整数化とクリップ処理\n",
    "merged_data['追切指数'] = merged_data['追切指数'].round(0).clip(lower=1, upper=99).astype(int)\n",
    "\n",
    "# インポートデータ用に整形\n",
    "merged_data = merged_data[['レースID(新)','追切指数']]\n",
    "\n",
    "output_path1 = f'D:/Keiba/Importdata/30_Traning_Score/Traning_Score_all_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "merged_data.to_csv(output_path1, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path1}に保存しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スピード指数を出力するコード\n",
    "\n",
    "## 概要\n",
    "スピード指数を算出するためのコードを記録します。このスピード指数は競馬のレースごとに馬の成績を評価するための指標で、ペース補正、斤量補正、馬場指数、クラス補正など、複数の要素を組み合わせて算出します。\n",
    "\n",
    "### 処理の概要\n",
    "\n",
    "1. **CSVファイルの読み込み**\n",
    "    - `pandas`を使って成績データのCSVファイルを読み込みます。このデータはレースごとの馬の成績や走破タイムなどが含まれています。\n",
    "\n",
    "2. **データの前処理**\n",
    "\n",
    "    a. **出走取り消し・競争除外の馬を除外**\n",
    "    - 成績データから「外」「止」「消」の馬を除外します。\n",
    "\n",
    "    b. **走破タイムの秒数への変換**\n",
    "    - 走破タイム（`分.秒.10分の1秒`形式）を秒数（浮動小数点数）に変換する関数`convert_time_to_seconds`を使い、`走破タイム_秒`という新しいカラムに変換後の値を追加します。\n",
    "\n",
    "    c. **コーナーロスの計算**\n",
    "    - 各馬のコーナーでのロス距離を考慮した走破タイムの補正を行います。`calculate_corner_loss`関数を用いて、`コーナーロス`という新しいカラムにロス時間を計算して追加します。\n",
    "    - 調整後の走破タイムは`調整走破タイム`というカラムに記録されます。\n",
    "\n",
    "3. **クラスと競争種別の分類**\n",
    "    - 各レースにおける競争種別コードとクラスコードをもとに分類し、新たに`Race_Type_Category`と`Class_Code_Category`カラムを追加します。\n",
    "\n",
    "4. **基準タイムデータとのマージ**\n",
    "    - コースごとの基準タイムデータ（StandardTimes2）およびクラス別基準タイムデータ（StandardTimes3）を読み込み、対象の成績データとマージします。\n",
    "    - マージする際に、カラム名の整合性を取るためにリネーム処理を行います。\n",
    "\n",
    "5. **スローorハイ関数の計算**\n",
    "    - 新しいカラム`スローorハイ関数`を計算し、`Ave-3F`と`上り3F`の差を計算します。その結果を基に`スローorハイ関数範囲`を設定します。\n",
    "    - `スローorハイ関数範囲`はペース補正ファイルと統一するために、あらかじめ定義した範囲で値を設定します。\n",
    "\n",
    "6. **ペース補正ファイルとのマージ**\n",
    "    - ペース補正ファイル（PacecorrectionTimes1）を読み込み、ペース補正係数を対象の成績データに結合します。\n",
    "\n",
    "7. **各補正値の計算**\n",
    "\n",
    "    a. **タイム補正値の計算**\n",
    "    - `Top3_Finish_Time_standard`と`調整走破タイム`を基に、距離補正を考慮してタイム補正値を計算し、`タイム補正値`カラムに保存します。\n",
    "\n",
    "    b. **平均3Fタイム補正値の計算**\n",
    "    - `Top3_Average_3F`がNaNの場合、0に置き換えた上で、`Ave-3F`との差分を計算し、`Ave-3F補正値`として保存します。\n",
    "\n",
    "    c. **斤量補正値の計算**\n",
    "    - 斤量と基準斤量を用いて斤量補正を計算し、`斤量補正値`として保存します。\n",
    "\n",
    "    d. **クラス補正値の計算**\n",
    "    - `Top3_Finish_Time_standard`と`Top3_Finish_Time_class`の差を計算してクラス補正値を求めます。クラス補正値は範囲を-2から+2に収めるため、`np.clip`を使用して値を制限します。\n",
    "\n",
    "    e. **ペース補正値の計算**\n",
    "    - `スローorハイ関数`と`ペース補正係数`を乗算して、`ペース補正値`として保存します。`ペース補正係数`がNaNの場合は0に置き換えます。\n",
    "\n",
    "8. **スピード指数の計算**\n",
    "    - 各補正値を組み合わせて、最終的なスピード指数を算出します。\n",
    "    - 計算式は以下の通りです：\n",
    "    \n",
    "      ```\n",
    "      スピード指数 = タイム補正値 + Ave-3F補正値 + 馬場指数 + 斤量補正値 + クラス補正値 + ペース補正値 + 70\n",
    "      ```\n",
    "    - 計算後、`スピード指数`カラムに保存します。\n",
    "\n",
    "9. **結果の保存**\n",
    "    - 最終的に計算された`スピード指数`を含むデータを新たなCSVファイルとして保存します。\n",
    "    - ファイル名には日付が付与され、指定のディレクトリに保存されます。\n",
    "\n",
    "### 出力\n",
    "- 出力ファイルには以下のカラムが含まれます。\n",
    "  - レースID(新)\n",
    "  - スピード指数\n",
    "- 保存先：`D:/Keiba/Importdata/40_Speed_Score/SpeedScore_YYYYMMDD.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/Importdata/40_Speed_Score/SpeedScore_20241201.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# スピード指数用成績CSVファイルのパスを選択して読み込み\n",
    "file_path = filedialog.askopenfilename(title=\"スピード指数用成績CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"スピード指数用成績CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "df = pd.read_csv(file_path, low_memory=False, encoding='cp932')\n",
    "\n",
    "# 出走取り消しや競争除外（外、止、消）になった馬を除外\n",
    "df = df[~df['着順'].isin(['外', '止', '消'])]\n",
    "\n",
    "# 走破タイムを時間（秒）に変換する関数\n",
    "def convert_time_to_seconds(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return np.nan\n",
    "    # ドットで分割する (例: \"1.54.5\" → [\"1\", \"54\", \"5\"])\n",
    "    parts = time_str.split(\".\")\n",
    "    if len(parts) == 3:\n",
    "        try:\n",
    "            minutes, seconds, tenths = map(int, parts)\n",
    "            total_seconds = minutes * 60 + seconds + tenths * 0.1\n",
    "            return total_seconds\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 走破タイムを秒に変換\n",
    "df['走破タイム_秒'] = df['走破タイム'].apply(convert_time_to_seconds)\n",
    "\n",
    "# コーナーロスを計算する関数\n",
    "def calculate_corner_loss(row):\n",
    "    corner_positions = [\n",
    "        row.get('馬印4', 1) - 1,\n",
    "        row.get('馬印5', 1) - 1,\n",
    "        row.get('馬印6', 1) - 1,\n",
    "        row.get('馬印7', 1) - 1\n",
    "    ]\n",
    "    total_distance_loss = sum(corner_positions) * 1.5  # 総距離ロス（m）\n",
    "    finish_time_seconds = row['走破タイム_秒']\n",
    "    distance_m = row['距離']\n",
    "\n",
    "    if pd.isna(finish_time_seconds) or pd.isna(distance_m) or finish_time_seconds == 0:\n",
    "        return np.nan\n",
    "\n",
    "    avg_speed = distance_m / finish_time_seconds if finish_time_seconds > 0 else np.nan\n",
    "    corner_loss = total_distance_loss / avg_speed if avg_speed > 0 else 0\n",
    "    return round(corner_loss, 2)\n",
    "\n",
    "# 馬印4～7を数値に変換し、不正な値を1に設定\n",
    "for corner_col in ['馬印4', '馬印5', '馬印6', '馬印7']:\n",
    "    df[corner_col] = pd.to_numeric(df[corner_col], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "# コーナーロスを計算して新しいカラムに追加\n",
    "df['コーナーロス'] = df.apply(calculate_corner_loss, axis=1)\n",
    "\n",
    "# 調整走破タイムの計算\n",
    "df['調整走破タイム'] = df['走破タイム_秒'] - df['コーナーロス']\n",
    "\n",
    "# 馬場指数の計算\n",
    "df['馬場指数'] = df['レース印１'] / 10\n",
    "\n",
    "# 基準斤量の計算\n",
    "# 斤量を数値に変換する関数\n",
    "def extract_weight(weight_str):\n",
    "    match = re.search(r'\\d+', weight_str)\n",
    "    return int(match.group()) if match else np.nan\n",
    "\n",
    "# 斤量を数値に変換\n",
    "df['斤量'] = df['斤量'].apply(extract_weight)\n",
    "\n",
    "# 基準斤量の計算\n",
    "df['基準斤量'] = df['斤量'] - df['馬齢斤量差']\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# クラスコードの分類関数\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 114:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Target出力ファイルに競争種別とクラスコードの分類カラムを追加\n",
    "df['Race_Type_Category'] = df['競走種別'].apply(categorize_race_type)\n",
    "df['Class_Code_Category'] = df['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "# スローorハイ関数の範囲を定義\n",
    "ranges = [\n",
    "    (-np.inf, -4.6),\n",
    "    (-4.5, -3.6),\n",
    "    (-3.5, -2.6),\n",
    "    (-2.5, -1.6),\n",
    "    (-1.5, -0.6),\n",
    "    (-0.5, 0.5),\n",
    "    (0.6, 1.5),\n",
    "    (1.6, 2.5),\n",
    "    (2.6, 3.5),\n",
    "    (3.6, 4.5),\n",
    "    (4.6, np.inf)\n",
    "]\n",
    "\n",
    "# スローorハイ関数のラベルを定義 (ペース補正ファイルと統一する)\n",
    "labels = [\n",
    "    '-inf～-4.6', '-4.5～-3.6', '-3.5～-2.6', '-2.5～-1.6', '-1.5～-0.6',\n",
    "    '-0.5～0.5', '0.6～1.5', '1.6～2.5', '2.6～3.5', '3.6～4.5', '4.6～inf'\n",
    "]\n",
    "\n",
    "# Track_Condition の変換\n",
    "df['Track_Condition_Category'] = df['馬場状態'].apply(lambda x: '良・稍' if x in ['良', '稍'] else '重・不' if x in ['重', '不'] else np.nan)\n",
    "\n",
    "# スローorハイ関数を計算\n",
    "df['スローorハイ関数'] = df['Ave-3F'] - df['上り3F']\n",
    "\n",
    "# スローorハイ関数のラベルを設定\n",
    "df['スローorハイ関数範囲'] = pd.cut(df['スローorハイ関数'], bins=[r[0] for r in ranges] + [ranges[-1][1]], labels=labels, right=True)\n",
    "\n",
    "# ベースとなるデータフレーム\n",
    "index_df = df[['レースID(新)',\n",
    "            '場所',\n",
    "            '芝・ダ',\n",
    "            '距離',\n",
    "            'Race_Type_Category',\n",
    "            'Class_Code_Category',\n",
    "            'Track_Condition_Category',\n",
    "            '馬場指数',\n",
    "            '基準斤量',\n",
    "            '斤量',\n",
    "            '走破タイム_秒',\n",
    "            '調整走破タイム',\n",
    "            'Ave-3F',\n",
    "            '上り3F',\n",
    "            'スローorハイ関数',\n",
    "            'スローorハイ関数範囲'\n",
    "            ]]\n",
    "\n",
    "# コース基準タイムファイルのパスを取得（StandardTimes2_を含む最新ファイルを取得）\n",
    "standard_time_file_path1 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/00_StandardTimes3_*.csv'), key=str)\n",
    "\n",
    "# クラス別コース基準タイムファイルのパスを取得（StandardTimes3_を含む最新ファイルを取得）\n",
    "standard_time_file_path2 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/00_StandardTimes2_*.csv'), key=str)\n",
    "\n",
    "# ペース補正ファイルのパスを取得（10_PacecorrectionTimes1_を含む最新ファイルを取得）\n",
    "pace_setting_file_path = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/10_PacecorrectionTimes1_*.csv'), key=str)\n",
    "\n",
    "# コース基準タイムファイルの読み込み\n",
    "standard_times_df1 = pd.read_csv(standard_time_file_path1, low_memory=False)\n",
    "standard_times_df2 = pd.read_csv(standard_time_file_path2, low_memory=False)\n",
    "\n",
    "# ペース補正ファイルの読み込み\n",
    "pace_setting_df = pd.read_csv(pace_setting_file_path, low_memory=False)\n",
    "\n",
    "# マージのためのカラム名マッピング（基準タイムファイル/Target出力ファイル）\n",
    "column_mappings = {\n",
    "    'Location': '場所',\n",
    "    'Turf_Dirt': '芝・ダ',\n",
    "    'Distance': '距離',\n",
    "    'Track_Condition_Category': '馬場状態',\n",
    "    'Race_Type_Category':'競争種別',\n",
    "    'Class_Code_Category' : 'クラスコード'\n",
    "}\n",
    "\n",
    "\n",
    "# 指数データフレームのカラムリネーム\n",
    "index_df = index_df.rename(columns=column_mappings)\n",
    "\n",
    "# 各基準タイムファイルとマージするためのカラムリネーム\n",
    "standard_times_df1 = standard_times_df1.rename(columns=column_mappings)\n",
    "standard_times_df2 = standard_times_df2.rename(columns=column_mappings)\n",
    "\n",
    "# ペース補正データフレームのカラムリネーム\n",
    "pace_setting_df = pace_setting_df.rename(columns=column_mappings)\n",
    "\n",
    "# 基準タイムファイルをマージ\n",
    "merged_df = pd.merge(\n",
    "    index_df,\n",
    "    standard_times_df1[['場所', '芝・ダ', '距離', '馬場状態','Top3_Average_3F', 'Top3_Finish_Time','Distance_Index']],\n",
    "    on=['場所', '芝・ダ', '距離', '馬場状態'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# クラス別基準タイムファイルをマージ\n",
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    standard_times_df2[['場所', '芝・ダ', '距離', '馬場状態', '競争種別', 'クラスコード', 'Top3_Finish_Time']],\n",
    "    on=['場所', '芝・ダ', '距離', '馬場状態', '競争種別', 'クラスコード'],\n",
    "    how='left',\n",
    "    suffixes=('_standard', '_class')\n",
    ")\n",
    "\n",
    "# ペース補正ファイルをマージ\n",
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    pace_setting_df[['場所', '芝・ダ', '距離', 'スローorハイ関数範囲', 'ペース補正係数']],\n",
    "    on=['場所', '芝・ダ', '距離', 'スローorハイ関数範囲'],\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "# タイム補正値の計算\n",
    "merged_df['タイム補正値'] = (merged_df['Top3_Finish_Time_standard'] - merged_df['調整走破タイム']) * merged_df['Distance_Index']\n",
    "\n",
    "# 平均3Fタイム補正値の計算\n",
    "# 平均3FタイムがNaNの場合は0に置き換え\n",
    "merged_df['Top3_Average_3F'] = merged_df['Top3_Average_3F'].fillna(0)\n",
    "\n",
    "# 平均3Fタイム補正値の計算 (Top3_Average_3FがNaNの場合はAve-3F補正値を0にする)\n",
    "merged_df['Ave-3F補正値'] = np.where(\n",
    "    merged_df['Top3_Average_3F'] == 0,\n",
    "    0,\n",
    "    merged_df['Top3_Average_3F'] - merged_df['Ave-3F']\n",
    ")\n",
    "\n",
    "# 斤量補正値の計算\n",
    "merged_df['斤量補正値'] = (merged_df['斤量'] - merged_df['基準斤量']) / merged_df['Distance_Index']\n",
    "\n",
    "# クラス補正値の計算\n",
    "merged_df['クラス補正値'] = merged_df['Top3_Finish_Time_standard'] - merged_df['Top3_Finish_Time_class']\n",
    "\n",
    "# クラス補正値を -2 から +2 の範囲に収める\n",
    "merged_df['クラス補正値'] = np.clip(merged_df['クラス補正値'], -2, 2)\n",
    "\n",
    "# ペース補正値の計算\n",
    "# ペース補正係数がNaNの場合は0に置き換え\n",
    "merged_df['ペース補正係数'] = merged_df['ペース補正係数'].fillna(0)\n",
    "merged_df['ペース補正値'] = merged_df['スローorハイ関数'] * merged_df['ペース補正係数']\n",
    "\n",
    "# スピード指数の計算\n",
    "merged_df['スピード指数'] = round(merged_df['タイム補正値'] + merged_df['Ave-3F補正値'] + merged_df['馬場指数'] + merged_df['斤量補正値'] + merged_df['クラス補正値'] + merged_df['ペース補正値'] + 70,1)\n",
    "\n",
    "# スピード指数のデータフレーム\n",
    "speedindex_df = merged_df[['レースID(新)','スピード指数']]\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path = f'D:/Keiba/Importdata/40_Speed_Score/SpeedScore_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "speedindex_df.to_csv(output_path, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path}に保存しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# レースレベルを計算するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "レースレベル判定結果を D:/Keiba/Importdata/20_Race_Level/race_levels_20241207.csv に保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# 成績CSVファイルのパスを選択して読み込み\n",
    "file_path = filedialog.askopenfilename(title=\"[merged_update]成績CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"[merged_update]成績CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# レースレベル基準ファイルのパスを取得（RaceLevels_を含む最新ファイルを取得）\n",
    "racelevel_filepath = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/20_RaceLevels_*.csv'), key=str)\n",
    "\n",
    "race_df = pd.read_csv(file_path, low_memory=False)\n",
    "standard_df = pd.read_csv(racelevel_filepath, low_memory=False)\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# クラスコードの分類関数\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 114:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 成績ファイルに競争種別の分類カラムを追加\n",
    "race_df['Race_Type_Category'] = race_df['Race_Type'].apply(categorize_race_type)\n",
    "race_df['Class_Code_Category'] = race_df['Class_Code'].apply(categorize_class_code)\n",
    "\n",
    "# 上位3頭の値を平均化する\n",
    "race_df['Top3_Adjustment'] = race_df[['1st_Horse_Adjustment', '2nd_Horse_Adjustment', '3rd_Horse_Adjustment']].mean(axis=1)\n",
    "race_df['Top3_Adjustment9'] = race_df[['1st_Horse_Additional9', '2nd_Horse_Additional9', '3rd_Horse_Additional9']].mean(axis=1)\n",
    "race_df['Top3_Speed_Index'] = race_df[['1st_Horse_Speed_Index', '2nd_Horse_Speed_Index', '3rd_Horse_Speed_Index']].mean(axis=1)\n",
    "\n",
    "# 基準ファイルの重み付けと一致させる\n",
    "weights = {\n",
    "    'Top3_Adjustment': 0.2,\n",
    "    'Top3_Adjustment9': 0.4,\n",
    "    'Top3_Speed_Index': 0.4\n",
    "}\n",
    "\n",
    "# 重み付けを適用して平均スコアを計算\n",
    "race_df['Average_Score'] = (\n",
    "    race_df['Top3_Adjustment'] * weights['Top3_Adjustment'] +\n",
    "    race_df['Top3_Adjustment9'] * weights['Top3_Adjustment9'] +\n",
    "    race_df['Top3_Speed_Index'] * weights['Top3_Speed_Index']\n",
    ")\n",
    "\n",
    "# レース条件でデータをマージ\n",
    "merge_columns = ['Turf_Dirt', 'Distance', 'Race_Type_Category', 'Class_Code_Category']\n",
    "merged_df = pd.merge(race_df, standard_df, on=merge_columns, how='left')\n",
    "\n",
    "# 近似値照合ロジックを実装する関数\n",
    "def assign_race_level(row):\n",
    "    # Average_Scoreを取得\n",
    "    avg_score = row['Average_Score']\n",
    "    # A～Eの基準値を取得\n",
    "    thresholds = {\n",
    "        'A': row['A'],\n",
    "        'B': row['B'],\n",
    "        'C': row['C'],\n",
    "        'D': row['D'],\n",
    "        'E': row['E']\n",
    "    }\n",
    "\n",
    "    # 平均スコアと各基準値の差分を計算\n",
    "    differences = {key: abs(avg_score - value) for key, value in thresholds.items()}\n",
    "\n",
    "    # 最小の差分を持つランクを取得\n",
    "    closest_rank = min(differences, key=differences.get)\n",
    "\n",
    "    # 対応する表記を生成\n",
    "    rank_to_label = {'A': '05A', 'B': '07B', 'C': '01C', 'D': '00D', 'E': '03E'}\n",
    "    return rank_to_label[closest_rank]\n",
    "\n",
    "# Race_Levelカラムを追加\n",
    "merged_df['Race_Level'] = merged_df.apply(assign_race_level, axis=1)\n",
    "\n",
    "# 出力ディレクトリとファイル名の設定\n",
    "output_dir = r'D:/Keiba/Importdata/20_Race_Level'\n",
    "output_file = f'{output_dir}/race_levels_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "\n",
    "# 出力データフレームを選択\n",
    "output_df = merged_df[['Target_Race_ID', 'Race_Level']]\n",
    "\n",
    "# 出力処理\n",
    "output_df.to_csv(output_file, index=False, encoding='cp932')\n",
    "print(f\"レースレベル判定結果を {output_file} に保存しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 33ラップからペース判定を計算するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/Importdata/20_33Lap_Type/33Laps_Type_20241207.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# 成績CSVファイルを選択\n",
    "file_path = filedialog.askopenfilename(title=\"[merged_update]成績CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"[merged_update]成績CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# 33ラップ基準ファイルのパスを取得（Standard33Laps_を含む最新ファイルを取得）\n",
    "racelevel_filepath = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/30_Standard33Laps_*.csv'), key=str)\n",
    "\n",
    "race_df = pd.read_csv(file_path, low_memory=False)\n",
    "standard_df = pd.read_csv(racelevel_filepath, low_memory=False)\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Target出力ファイルに競争種別の分類カラムを追加\n",
    "race_df['Race_Type_Category'] = race_df['Race_Type'].apply(categorize_race_type)\n",
    "\n",
    "# 共通のカラムで結合\n",
    "merge_columns = ['Location', 'Turf_Dirt', 'Distance','Turf_Inside_Outside', 'Race_Type_Category']\n",
    "merged_df = pd.merge(race_df, standard_df, on=merge_columns, how='left')\n",
    "\n",
    "# カラム名の調整\n",
    "merged_df = merged_df.rename(columns={'33_Lap_x': '33_Lap', '33_Lap_y': '33_Lap-0'})\n",
    "\n",
    "# 各基準値との差分を計算\n",
    "merged_df['diff_33_Lap-2'] = abs(merged_df['33_Lap'] - merged_df['33_Lap-2'])\n",
    "merged_df['diff_33_Lap-1'] = abs(merged_df['33_Lap'] - merged_df['33_Lap-1'])\n",
    "merged_df['diff_33_Lap']   = abs(merged_df['33_Lap'] - merged_df['33_Lap-0'])\n",
    "merged_df['diff_33_Lap+1'] = abs(merged_df['33_Lap'] - merged_df['33_Lap+1'])\n",
    "merged_df['diff_33_Lap+2'] = abs(merged_df['33_Lap'] - merged_df['33_Lap+2'])\n",
    "\n",
    "def assign_label(row):\n",
    "    # 差分辞書\n",
    "    diffs = {\n",
    "        'diff_33_Lap-2': row['diff_33_Lap-2'],\n",
    "        'diff_33_Lap-1': row['diff_33_Lap-1'],\n",
    "        'diff_33_Lap':   row['diff_33_Lap'],\n",
    "        'diff_33_Lap+1': row['diff_33_Lap+1'],\n",
    "        'diff_33_Lap+2': row['diff_33_Lap+2']\n",
    "    }\n",
    "\n",
    "    # 最小差分キーを取得\n",
    "    min_key = min(diffs, key=diffs.get)\n",
    "\n",
    "    # キー→数値マッピング\n",
    "    mapping = {\n",
    "        'diff_33_Lap-2': -2,\n",
    "        'diff_33_Lap-1': -1,\n",
    "        'diff_33_Lap':   0,\n",
    "        'diff_33_Lap+1': 1,\n",
    "        'diff_33_Lap+2': 2\n",
    "    }\n",
    "\n",
    "    scale = mapping[min_key]\n",
    "    lap_value = row['33_Lap']\n",
    "\n",
    "    # 0スケールの場合\n",
    "    if scale == 0:\n",
    "        if lap_value < 0:\n",
    "            return '持0'\n",
    "        elif lap_value > 0:\n",
    "            return '瞬0'\n",
    "        else:\n",
    "            return '総'\n",
    "\n",
    "    # 0以外の場合\n",
    "    prefix = '瞬' if lap_value > 0 else '持'\n",
    "    if scale > 0:\n",
    "        suffix = f'+{scale}'\n",
    "    else:\n",
    "        suffix = f'{scale}'\n",
    "\n",
    "    return prefix + suffix\n",
    "\n",
    "merged_df['33_Lap_Type'] = merged_df.apply(assign_label, axis=1)\n",
    "\n",
    "# ラベル書き換え用のマッピング辞書\n",
    "label_mapping = {\n",
    "    '持-2': '0T持-2',\n",
    "    '持-1': '0T持-1',\n",
    "    '持0': '0U持0',\n",
    "    '持+1': '0V持+1',\n",
    "    '持+2': '0V持+2',\n",
    "    '瞬-2': '0S瞬-2',\n",
    "    '瞬-1': '0S瞬-1',\n",
    "    '瞬0': '0R瞬0',\n",
    "    '瞬+1': '0Q瞬+1',\n",
    "    '瞬+2': '0Q瞬+2',\n",
    "    '総': '02総'\n",
    "}\n",
    "\n",
    "# mapを用いてラベル書き換え\n",
    "merged_df['33_Lap_Type'] = merged_df['33_Lap_Type'].map(label_mapping)\n",
    "\n",
    "# 出力用のデータフレーム\n",
    "output_df = merged_df[['Target_Race_ID', '33_Lap_Type']]\n",
    "\n",
    "# CSVファイルで保存\n",
    "output_path = f'D:/Keiba/Importdata/20_33Lap_Type/33Laps_Type_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "output_df.to_csv(output_path, index=False, encoding='cp932')\n",
    "print(f\"結果を{output_path}に保存しました。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
