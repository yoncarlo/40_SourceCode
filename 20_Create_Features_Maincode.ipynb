{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 成績データファイルを作成する\n",
    "## 元の成績データファイルへ新しい成績データを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/マイドライブ/20_HOBBY/20_KEIBA/10_Data_Source/10_Export_Data/Result_Data/Original/ResultData_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_8332\\272507429.py:26: DtypeWarning: Columns (24,25,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master_df = pd.read_csv(master_filepath, encoding='cp932').copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理が完了しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "# 使用するファイルパスの指定\n",
    "basedir = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original'\n",
    "filename = 'ResultData_Master_2023.csv'\n",
    "\n",
    "master_filepath = os.path.join(basedir, filename)\n",
    "\n",
    "# ファイル選択ダイアログを表示するための準備\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "root.attributes('-topmost', True) # ダイアログを最前面に出す（隠れるのを防ぐため）\n",
    "\n",
    "merged_filepath = filedialog.askopenfilename(title=\"CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "print(merged_filepath)\n",
    "\n",
    "# ファイルが選択されなかった場合は終了\n",
    "if not merged_filepath:\n",
    "    print(\"ファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# CSVファイルを開く\n",
    "master_df = pd.read_csv(master_filepath, encoding='cp932').copy()\n",
    "merged_df = pd.read_csv(merged_filepath, encoding='cp932').copy()\n",
    "\n",
    "# 開いたファイルの列をリネームする\n",
    "# リネームする列名を定義\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid'\n",
    "}\n",
    "\n",
    "master_df.rename(columns=rename_map, inplace=True)\n",
    "merged_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# master_dfにmerged_dfを縦結合する\n",
    "combined_df = pd.concat([master_df, merged_df], ignore_index=True)\n",
    "\n",
    "# 重複行を削除する（全列が同じ行を削除）\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# master_dfを上書き保存する\n",
    "# ※保存は元のマスターに合わせて cp932 にしています\n",
    "combined_df.to_csv(master_filepath, index=False, encoding='cp932')\n",
    "\n",
    "print(\"処理が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\4066021823.py:9: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master_df = pd.read_csv(master_filepath, encoding='cp932')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# 使用するファイルパスの指定\n",
    "basedir = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original'\n",
    "filename = 'ResultData_Master_2023.csv'\n",
    "\n",
    "master_filepath = os.path.join(basedir, filename)\n",
    "\n",
    "master_df = pd.read_csv(master_filepath, encoding='cp932')\n",
    "\n",
    "# 開いたファイルの列をリネームする\n",
    "# リネームする列名を定義\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid'\n",
    "}\n",
    "\n",
    "master_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# csvファイル保存\n",
    "master_df.to_csv(master_filepath, index=False, encoding='cp932')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追切指数の作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追切指数基準タイムを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\2642273033.py:19: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(master_filepath, encoding='cp932').copy()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\2642273033.py:155: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  course_top20_mean = round(merged_df1.groupby(['コース', '馬場状態']).apply(calculate_top20times_mean), 1).reset_index()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\2642273033.py:156: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  course_top10_mean = round(merged_df1.groupby(['コース', '馬場状態']).apply(calculate_top10times_mean), 1).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了：基準タイムファイル（MAD版）を出力しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# =========================\n",
    "# 設定\n",
    "# =========================\n",
    "output_dir = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\\\'\n",
    "traning_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\50_Training_Comments\\Training_Comments_Master.csv'\n",
    "master_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original\\ResultData_Master_2023.csv'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# =========================\n",
    "# 読み込み\n",
    "# =========================\n",
    "df1 = pd.read_csv(traning_filepath, encoding='cp932').copy()\n",
    "df2 = pd.read_csv(master_filepath, encoding='cp932').copy()\n",
    "\n",
    "# =========================\n",
    "# 前処理\n",
    "# =========================\n",
    "def clean_training_data(df):\n",
    "    df = df.copy()\n",
    "    mask_invalid = df[\"日付\"].astype(str).str.contains(\"■|◇\", na=False)\n",
    "    df = df[~mask_invalid].copy()\n",
    "    \n",
    "    check_cols = [c for c in ['8F','7F','6F','5F(4F)','4F(3F)','3F(2F)'] if c in df.columns]\n",
    "    for c in check_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    \n",
    "    is_not_hill = ~df['コース'].astype(str).str.contains('坂', na=False)\n",
    "    has_10sec_like = np.column_stack([df[c].between(1.0, 19.9) for c in check_cols]).any(axis=1)\n",
    "    \n",
    "    drop_mask = is_not_hill & has_10sec_like\n",
    "    df = df[~drop_mask].copy()\n",
    "    return df\n",
    "\n",
    "df1 = clean_training_data(df1)\n",
    "\n",
    "replace_map = {'南Ｗ': '美Ｗ', '南Ｄ': '美ダ', '南ダ': '美ダ', '南芝': '美芝'}\n",
    "df1['コース'] = df1['コース'].replace(replace_map)\n",
    "df1['馬場状態'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1[\"回り位置\"] = pd.to_numeric(df1[\"回り位置\"], errors=\"coerce\")\n",
    "\n",
    "distance_columns = [col for col in [\"8F\", \"7F\", \"6F\", \"5F(4F)\", \"4F(3F)\", \"3F(2F)\", \"1F\"] if col in df1.columns]\n",
    "\n",
    "for col in distance_columns:\n",
    "    df1[f\"{col}_補\"] = np.nan\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    if not pd.isna(row[\"回り位置\"]):\n",
    "        correction_value = (9 - row[\"回り位置\"]) * 0.1\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "            df1.at[index, f\"{leftmost_col}_補\"] = round(row[leftmost_col] + correction_value, 1)\n",
    "            \n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        df1.at[index, f\"{col}_補\"] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                df1.at[index, f\"{col}_補\"] = row[col]\n",
    "\n",
    "# =========================\n",
    "# マージ\n",
    "# =========================\n",
    "merge_cols = ['target_horseid', 'トラックコード(JV)', '年齢限定(競走種別コード)', 'クラスコード', '入線順位']\n",
    "df2 = df2[merge_cols]\n",
    "\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11: return 'サラブレッド系2歳'\n",
    "    elif race_type == 12: return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13: return 'サラブレッド系3歳以上'\n",
    "    else: return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15: return '新馬・未勝利'\n",
    "    elif class_code == 23: return '1勝クラス'\n",
    "    elif class_code == 43: return '2勝クラス'\n",
    "    elif class_code == 67: return '3勝クラス'\n",
    "    elif class_code >= 114: return 'OP・重賞'\n",
    "    else: return np.nan\n",
    "\n",
    "df2['年齢限定(競走種別コード)'] = df2['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df2['クラスコード'] = df2['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "merged_df1 = pd.merge(df1, df2, on=\"target_horseid\", how=\"inner\")\n",
    "del df1, df2\n",
    "\n",
    "merged_df1 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "time_columns = ['8F_補', '7F_補', '6F_補', '5F(4F)_補', '4F(3F)_補', '3F(2F)_補', '1F_補']\n",
    "\n",
    "# =========================\n",
    "# 基準タイム・MAD計算\n",
    "# =========================\n",
    "\n",
    "# MAD（中央値絶対偏差）計算用関数\n",
    "def robust_mad(x):\n",
    "    return np.median(np.abs(x - np.median(x)))\n",
    "\n",
    "# 並び替え用の列リストを定義\n",
    "mad_columns = [f\"MAD_{c}\" for c in time_columns]\n",
    "\n",
    "# 1. コース・馬場状態ごとの集計 (Median + MAD)\n",
    "course_stats = merged_df1.groupby(['コース', '馬場状態'])[time_columns].agg(['median', robust_mad])\n",
    "\n",
    "new_cols_course = []\n",
    "for col, stat in course_stats.columns:\n",
    "    if stat == 'median':\n",
    "        new_cols_course.append(col)\n",
    "    else:\n",
    "        new_cols_course.append(f\"MAD_{col}\") \n",
    "course_stats.columns = new_cols_course\n",
    "course_stats = course_stats.reset_index().round(2) # 精度確保のため2桁\n",
    "\n",
    "# 列の並び替え\n",
    "course_stats = course_stats[['コース', '馬場状態'] + time_columns + mad_columns]\n",
    "\n",
    "# 2. コース・クラス・馬場状態ごとの集計 (Median + MAD)\n",
    "class_stats = merged_df1.groupby(['コース', 'クラスコード', '馬場状態'])[time_columns].agg(['median', robust_mad])\n",
    "\n",
    "new_cols_class = []\n",
    "for col, stat in class_stats.columns:\n",
    "    if stat == 'median':\n",
    "        new_cols_class.append(col)\n",
    "    else:\n",
    "        new_cols_class.append(f\"MAD_{col}\")\n",
    "class_stats.columns = new_cols_class\n",
    "class_stats = class_stats.reset_index().round(2)\n",
    "\n",
    "# 列の並び替え\n",
    "class_stats = class_stats[['コース', 'クラスコード', '馬場状態'] + time_columns + mad_columns]\n",
    "\n",
    "# 3. 上位20% / 10% の平均\n",
    "def calculate_top20times_mean(group):\n",
    "    top20_threshold = group[time_columns].quantile(0.2)\n",
    "    top20_data = group[time_columns][group[time_columns] <= top20_threshold]\n",
    "    return top20_data.mean()\n",
    "\n",
    "def calculate_top10times_mean(group):\n",
    "    top10_threshold = group[time_columns].quantile(0.1)\n",
    "    top10_data = group[time_columns][group[time_columns] <= top10_threshold]\n",
    "    return top10_data.mean()\n",
    "\n",
    "course_top20_mean = round(merged_df1.groupby(['コース', '馬場状態']).apply(calculate_top20times_mean), 1).reset_index()\n",
    "course_top10_mean = round(merged_df1.groupby(['コース', '馬場状態']).apply(calculate_top10times_mean), 1).reset_index()\n",
    "\n",
    "# =========================\n",
    "# 出力\n",
    "# =========================\n",
    "course_stats.to_csv(f\"{output_dir}traning_std_course.csv\", index=False, encoding=\"cp932\")\n",
    "class_stats.to_csv(f\"{output_dir}traning_std_class.csv\", index=False, encoding=\"cp932\")\n",
    "course_top20_mean.to_csv(f\"{output_dir}traning_std_course_top20.csv\", index=False, encoding=\"cp932\")\n",
    "course_top10_mean.to_csv(f\"{output_dir}traning_std_course_top10.csv\", index=False, encoding=\"cp932\")\n",
    "\n",
    "del merged_df1, course_stats, class_stats, course_top20_mean, course_top10_mean\n",
    "\n",
    "print(\"完了：基準タイムファイル（MAD版）を出力しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追切指数を算出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\1744245144.py:24: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(master_filepath,  encoding='cp932').copy()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\1744245144.py:240: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, merged_unique], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了：追切指数（MAD・ロバスト偏差値版）を出力しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# 読み込みファイルパス\n",
    "# =========================\n",
    "traning_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\50_Training_Comments\\Training_Comments_Master.csv'\n",
    "master_filepath  = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original\\ResultData_Master_2023.csv'\n",
    "\n",
    "# 基準ファイル\n",
    "p_course_median  = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course.csv'\n",
    "p_class_median   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_class.csv'\n",
    "p_course_top20   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course_top20.csv'\n",
    "p_course_top10   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course_top10.csv'\n",
    "\n",
    "# 出力\n",
    "output_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\Training_Score_Master.csv'\n",
    "output_dir       = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\\\'\n",
    "\n",
    "# =========================\n",
    "# 読み込み & 前処理\n",
    "# =========================\n",
    "df1 = pd.read_csv(traning_filepath, encoding='cp932').copy()\n",
    "df2 = pd.read_csv(master_filepath,  encoding='cp932').copy()\n",
    "\n",
    "def clean_training_data(df):\n",
    "    df = df.copy()\n",
    "    mask_invalid = df[\"日付\"].astype(str).str.contains(\"■|◇\", na=False)\n",
    "    df = df[~mask_invalid].copy()\n",
    "    check_cols = [c for c in ['8F','7F','6F','5F(4F)','4F(3F)','3F(2F)'] if c in df.columns]\n",
    "    for c in check_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    is_not_hill = ~df['コース'].astype(str).str.contains('坂', na=False)\n",
    "    has_10sec_like = np.column_stack([df[c].between(10.0, 19.9) for c in check_cols]).any(axis=1)\n",
    "    drop_mask = is_not_hill & has_10sec_like\n",
    "    df = df[~drop_mask].copy()\n",
    "    return df\n",
    "\n",
    "df1 = clean_training_data(df1)\n",
    "\n",
    "replace_map = {'南Ｗ': '美Ｗ', '南Ｄ': '美ダ', '南ダ': '美ダ', '南芝': '美芝'}\n",
    "df1['コース'] = df1['コース'].replace(replace_map)\n",
    "df1['馬場状態'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1[\"回り位置\"] = pd.to_numeric(df1[\"回り位置\"], errors=\"coerce\")\n",
    "\n",
    "distance_columns = [col for col in [\"8F\", \"7F\", \"6F\", \"5F(4F)\", \"4F(3F)\", \"3F(2F)\", \"1F\"] if col in df1.columns]\n",
    "for col in distance_columns:\n",
    "    df1[f\"{col}_補\"] = np.nan\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    if not pd.isna(row[\"回り位置\"]):\n",
    "        correction_value = (9 - row[\"回り位置\"]) * 0.1\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "            df1.at[index, f\"{leftmost_col}_補\"] = round(row[leftmost_col] + correction_value, 1)\n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        df1.at[index, f\"{col}_補\"] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                df1.at[index, f\"{col}_補\"] = row[col]\n",
    "\n",
    "time_columns = [f\"{c}_補\" for c in distance_columns]\n",
    "\n",
    "# =========================\n",
    "# 成績マージ\n",
    "# =========================\n",
    "merge_cols = ['target_horseid', 'トラックコード(JV)', '年齢限定(競走種別コード)', 'クラスコード']\n",
    "df2 = df2[merge_cols]\n",
    "\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11: return 'サラブレッド系2歳'\n",
    "    elif race_type == 12: return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13: return 'サラブレッド系3歳以上'\n",
    "    else: return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15: return '新馬・未勝利'\n",
    "    elif class_code == 23: return '1勝クラス'\n",
    "    elif class_code == 43: return '2勝クラス'\n",
    "    elif class_code == 67: return '3勝クラス'\n",
    "    elif class_code >= 114: return 'OP・重賞'\n",
    "    else: return np.nan\n",
    "\n",
    "df2['年齢限定(競走種別コード)'] = df2['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df2['クラスコード'] = df2['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "merged_df1 = pd.merge(df1, df2, on='target_horseid', how='inner').copy()\n",
    "merged_df1['is_saka'] = merged_df1['コース'].astype(str).str.contains('坂', na=False)\n",
    "\n",
    "# =========================\n",
    "# 基準テーブル読み込み（MAD対応）\n",
    "# =========================\n",
    "def load_and_tag(path, suffix, has_std):\n",
    "    t = pd.read_csv(path, encoding='cp932').copy()\n",
    "    rename_map = {}\n",
    "    for c in time_columns:\n",
    "        if c in t.columns:\n",
    "            rename_map[c] = f\"{c}_{suffix}\"\n",
    "        \n",
    "        # 標準偏差ではなくMADを探す\n",
    "        madc = f\"MAD_{c}\"\n",
    "        if has_std and (madc in t.columns):\n",
    "            rename_map[madc] = f\"MAD_{c}_{suffix}\"\n",
    "    return t.rename(columns=rename_map)\n",
    "\n",
    "df3 = load_and_tag(p_course_median, 'course', True)\n",
    "df4 = load_and_tag(p_class_median,  'class',  True)\n",
    "df5 = load_and_tag(p_course_top20, 'course_20', False)\n",
    "df6 = load_and_tag(p_course_top10, 'course_10', False)\n",
    "\n",
    "key_course = ['コース','馬場状態']\n",
    "key_class  = ['年齢限定(競走種別コード)','クラスコード','コース','馬場状態']\n",
    "\n",
    "def smerge(left, right, keys):\n",
    "    exist_keys = [k for k in keys if (k in left.columns and k in right.columns)]\n",
    "    return pd.merge(left, right, on=exist_keys, how='left')\n",
    "\n",
    "merged_df1 = smerge(merged_df1, df3, key_course)\n",
    "merged_df1 = smerge(merged_df1, df4, key_class)\n",
    "merged_df1 = smerge(merged_df1, df5, key_course)\n",
    "merged_df1 = smerge(merged_df1, df6, key_course)\n",
    "\n",
    "# =========================\n",
    "# 偏差値（ロバスト偏差値計算：MAD使用）\n",
    "# =========================\n",
    "def dev_vec(v, m, mad):\n",
    "    # MADを正規分布の標準偏差相当に変換する定数 1.4826\n",
    "    sigma_est = mad * 1.4826\n",
    "    \n",
    "    ok = (~pd.isna(v)) & (~pd.isna(m)) & (~pd.isna(mad)) & (sigma_est != 0)\n",
    "    \n",
    "    # タイムは小さい方が良いので (Median - Value)\n",
    "    # sigma_est が 0 (全員同じタイム等) の場合は偏差値50とする\n",
    "    return np.where(ok, 50 + 10 * (m - v) / sigma_est, 50)\n",
    "\n",
    "bases_for_dev = ['course', 'class']\n",
    "\n",
    "for c in time_columns:\n",
    "    dev_cols = []\n",
    "    for b in bases_for_dev:\n",
    "        mean_col = f\"{c}_{b}\"\n",
    "        mad_col  = f\"MAD_{c}_{b}\"\n",
    "        colname = f\"偏差値_{c}_{b}\"\n",
    "        \n",
    "        # MADが存在する場合のみ計算\n",
    "        if mad_col in merged_df1.columns:\n",
    "            merged_df1[colname] = dev_vec(merged_df1[c], merged_df1[mean_col], merged_df1[mad_col])\n",
    "            dev_cols.append(colname)\n",
    "\n",
    "    if dev_cols:\n",
    "        merged_df1[f\"偏差値_統合_{c}\"] = merged_df1[dev_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "# 統合偏差値が存在する列のみでスコア計算\n",
    "valid_dev_cols = [f\"偏差値_統合_{c}\" for c in time_columns if f\"偏差値_統合_{c}\" in merged_df1.columns]\n",
    "if valid_dev_cols:\n",
    "    merged_df1['総合偏差値スコア'] = merged_df1[valid_dev_cols].mean(axis=1, skipna=True)\n",
    "else:\n",
    "    merged_df1['総合偏差値スコア'] = 50.0\n",
    "\n",
    "# =========================\n",
    "# 加点（変更なし）\n",
    "# =========================\n",
    "bonus_targets = {'4F': '4F(3F)_補', '2F': '3F(2F)_補', '1F': '1F_補'}\n",
    "\n",
    "def calculate_bonus(value, mean, is_saka, col_short):\n",
    "    if pd.isna(value) or pd.isna(mean): return 0.0\n",
    "    if is_saka:\n",
    "        if col_short == '4F': return 0.5 if value < mean else 0.0\n",
    "        if col_short == '2F': return 1.5 if value < mean else 0.0\n",
    "        if col_short == '1F': return 1.0 if value < mean else 0.0\n",
    "    else:\n",
    "        if col_short == '4F': return 0.5 if value < mean else 0.0\n",
    "        if col_short == '2F': return 1.0 if value < mean else 0.0\n",
    "        if col_short == '1F': return 1.5 if value < mean else 0.0\n",
    "    return 0.0\n",
    "\n",
    "th_sfx_list = ['course_20','course_10']\n",
    "bonus_cols = []\n",
    "for col_short, base_col in bonus_targets.items():\n",
    "    for sfx in th_sfx_list:\n",
    "        th_col = f\"{base_col}_{sfx}\"\n",
    "        if th_col in merged_df1.columns:\n",
    "            out_col = f\"加点_{col_short}_{sfx}\"\n",
    "            merged_df1[out_col] = merged_df1.apply(\n",
    "                lambda r: calculate_bonus(\n",
    "                    r.get(base_col, np.nan), r.get(th_col, np.nan),\n",
    "                    bool(r.get('is_saka', False)), col_short\n",
    "                ), axis=1\n",
    "            )\n",
    "            bonus_cols.append(out_col)\n",
    "\n",
    "merged_df1['総合加点スコア'] = merged_df1[bonus_cols].sum(axis=1, skipna=True) if bonus_cols else 0.0\n",
    "\n",
    "# =========================\n",
    "# 係数・最終指数\n",
    "# =========================\n",
    "def rider_coef(x):\n",
    "    s = '' if pd.isna(x) else str(x)\n",
    "    if '助手' in s: return 1.0\n",
    "    if '見習' in s: return 0.8\n",
    "    return 0.9\n",
    "\n",
    "def leg_coef(x):\n",
    "    s = '' if pd.isna(x) else str(x)\n",
    "    if '馬なり' in s: return 1.1\n",
    "    if ('Ｇ' in s) or ('G' in s) or ('強' in s): return 1.0\n",
    "    if '一杯' in s: return 0.8\n",
    "    if 'ヨレ' in s: return 0.7\n",
    "    if 'バテ' in s: return 0.6\n",
    "    return 0.9\n",
    "\n",
    "merged_df1['騎乗者係数'] = merged_df1['乗り役'].apply(rider_coef)\n",
    "merged_df1['脚色係数']   = merged_df1['脚色'].apply(leg_coef)\n",
    "\n",
    "merged_df1['追切指数'] = (\n",
    "    (merged_df1['総合偏差値スコア'].fillna(50) + merged_df1['総合加点スコア'].fillna(0.0))\n",
    "    * merged_df1['騎乗者係数'].fillna(0.9)\n",
    "    * merged_df1['脚色係数'].fillna(0.9)\n",
    ")\n",
    "\n",
    "merged_df1['追切指数'] = merged_df1['追切指数'].replace([np.inf, -np.inf], np.nan).fillna(1).round(1)\n",
    "\n",
    "# 重複排除\n",
    "merged_unique = merged_df1.loc[merged_df1.groupby('target_horseid')['追切指数'].idxmax()].reset_index(drop=True).copy()\n",
    "merged_unique = merged_unique[['target_horseid','追切指数']].copy()\n",
    "\n",
    "del df1,df2,df3,df4,df5,df6,merged_df1\n",
    "\n",
    "# 保存処理\n",
    "combined_df = pd.read_csv(output_filepath1, encoding='cp932').copy()\n",
    "combined_df = pd.concat([combined_df, merged_unique], ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates(subset='target_horseid', keep='last')\n",
    "combined_df.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "\n",
    "combined_df['year'] = pd.to_datetime(\n",
    "    combined_df['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y', errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "for year, dfy in combined_df.groupby('year'):\n",
    "    dfy.drop(columns='year').to_csv(f'{output_dir}Training_Score_Master_{year}.csv', index=False, encoding='cp932')\n",
    "\n",
    "del combined_df\n",
    "\n",
    "print(\"完了：追切指数（MAD・ロバスト偏差値版）を出力しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基準タイムファイルを出力するコード\n",
    "\n",
    "## ・スピード指数の算出に使うコース別の基準タイムファイルを出力する\n",
    "- 1着馬および1着馬〜3着馬の基準タイム、およびその他タイム系データを格納する\n",
    "- ファイルは2つ出力するが、スピード指数の算出には`00_StandardTimes2_yyyymmdd.csv`を用いる\n",
    "\n",
    "### 処理の概要\n",
    "- 成績CSVファイルを読み込み、コース・距離・競争種別コード・クラスコード・馬場状態でレースデータをグループ化する\n",
    "- 各グループの中央値を基準タイムファイル1とする\n",
    "- 各グループの中で1勝クラス・2勝クラスのデータの平均をとり、それを基準タイムファイル2とする\n",
    "\n",
    "### ステップ\n",
    "1. **CSVファイルの読み込み**\n",
    "   - `pandas`を使って、ある期間の1着馬から3着馬の成績が記録されたCSVファイルを読み込む\n",
    "\n",
    "2. **カテゴリの追加**\n",
    "   - `競争種別コード`と`クラスコード`をもとにレースタイプやクラスカテゴリを新たに分類し、カテゴリカラムを追加\n",
    "   - 馬場状態（良・稍／重・不良）に基づき馬場状態カテゴリを追加\n",
    "\n",
    "3. **タイム系カラムの計算**\n",
    "   - 1着馬から3着馬の走破タイムや3Fの平均を計算して新しいカラムとして追加\n",
    "\n",
    "4. **グループ化して中央値を計算**\n",
    "   - 「場所」、「芝・ダート」、「距離」、「馬場状態」、「競争種別カテゴリ」、「クラスカテゴリ」でグループ化\n",
    "   - 各グループごとのタイム系カラムの中央値を計算し、基準タイムファイル1として保存\n",
    "\n",
    "5. **クラス別フィルタリングと再計算**\n",
    "   - 基準タイムファイル1から「良・稍」と「重・不良」でデータをフィルタリング\n",
    "   - 各フィルタで1勝クラスと2勝クラスの中央値を取得し、その平均をとって基準タイムファイル2とする\n",
    "\n",
    "6. **出力ファイルの生成**\n",
    "   - `00_StandardTimes1_yyyymmdd.csv`（基準タイムファイル1）と`00_StandardTimes2_yyyymmdd.csv`（基準タイムファイル2）を出力\n",
    "   - スピード指数の算出には`00_StandardTimes2_yyyymmdd.csv`を使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:68: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(master_file_path, encoding='cp932')\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:728: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(remove_outliers)\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:1728: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_df1['year'] = pd.to_datetime(\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:1734: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_df2['year'] = pd.to_datetime(\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:1740: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_df3['year'] = pd.to_datetime(\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:1746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_df4['year'] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "#---ステップ１：成績データから基準タイムファイルを作成\n",
    "# ファイルパスの指定\n",
    "# 成績データファイルのパス\n",
    "master_file_path = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original\\ResultData_Master_2023.csv'\n",
    "\n",
    "# 成績データにマージするデータファイルのパス\n",
    "# 初角位置ファイルのパス\n",
    "merge_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\70_First_Corner_Position\\First_Corner_Position_Master.csv'\n",
    "# 2角位置ファイルのパス\n",
    "merge_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\80_Second_Corner_Position\\Second_Corner_Position_Master.csv'\n",
    "# 3角位置ファイルのパス\n",
    "merge_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\90_Third_Corner_Position\\Third_Corner_Position_Master.csv'\n",
    "# 4角位置ファイルのパス\n",
    "merge_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\100_Fourth_Corner_Position\\Fourth_Corner_Position_Master.csv'\n",
    "# 上り位置ファイルのパス\n",
    "merge_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\110_Spurt_Position\\Spurt_Position_Master.csv'\n",
    "# 馬場指数ファイルのパス\n",
    "merge_filepath6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\60_Track_Condition\\Track_Condition_Master.csv'\n",
    "# 前半3Fタイムファイルのパス\n",
    "merge_filepath7 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\120_First3F_Lap\\First3F_Lap_Master.csv'\n",
    "# 追切指数ファイルのパス\n",
    "merge_filepath8 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\Training_Score_Master.csv'\n",
    "\n",
    "# 保存先パス\n",
    "# 保存先のファイルパス\n",
    "# 加工後の成績データファイルの保存先パス\n",
    "output_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2024_tmp.csv'\n",
    "\n",
    "# 基準ファイル系\n",
    "# 基準タイムファイル1の保存先パス\n",
    "output_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\StdTime1.csv'\n",
    "# 基準タイムファイル2の保存先パス\n",
    "output_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\StdTime2.csv'\n",
    "# ペース係数ファイルの保存先パス\n",
    "output_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\PaceTime.csv'\n",
    "# 基準33ラップファイルの保存先パス\n",
    "output_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\33Lap.csv'\n",
    "# レースレベル基準ファイルのパス\n",
    "output_filepath6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\RaceLevel.csv'\n",
    "\n",
    "# 馬タイプ分類のファイルパス\n",
    "output_filepath7 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\220_Horse_Type\\Horse_Type_Master.csv'\n",
    "\n",
    "# 指数系\n",
    "# テン指数のディレクトリ\n",
    "output_dir1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\150_First_Score\\\\'\n",
    "# 上り指数のディレクトリ\n",
    "output_dir2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\160_Spurt_Score\\\\'\n",
    "# スピード指数のディレクトリ\n",
    "output_dir3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\170_Speed_Score\\\\'\n",
    "# 総合指数のディレクトリ\n",
    "output_dir4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\180_Total_Score\\\\'\n",
    "# 33ラップ判定のディレクトリ\n",
    "output_dir5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\140_33Lap_Category\\\\'\n",
    "# レースレベル判定のディレクトリ\n",
    "output_dir6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\190_Race_Level\\\\'\n",
    "\n",
    "# 列の並び定義ファイルパス\n",
    "header_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\50_SourceCode\\ResultData_Header.csv'\n",
    "\n",
    "# 成績データファイルとマージファイルの読み込み\n",
    "df1 = pd.read_csv(master_file_path, encoding='cp932')\n",
    "df2 = pd.read_csv(merge_filepath1, encoding='cp932')\n",
    "df3 = pd.read_csv(merge_filepath2, encoding='cp932')\n",
    "df4 = pd.read_csv(merge_filepath3, encoding='cp932')\n",
    "df5 = pd.read_csv(merge_filepath4, encoding='cp932')\n",
    "df6 = pd.read_csv(merge_filepath5, encoding='cp932')\n",
    "df7 = pd.read_csv(merge_filepath6, encoding='cp932')\n",
    "df8 = pd.read_csv(merge_filepath7, encoding='cp932')\n",
    "df9 = pd.read_csv(merge_filepath8, encoding='cp932')\n",
    "\n",
    "#　マージファイルで使用する列だけを定義\n",
    "df2 = df2[['target_horseid','初角サイドポジション']]\n",
    "df3 = df3[['target_horseid','2角サイドポジション']]\n",
    "df4 = df4[['target_horseid','3角サイドポジション']]\n",
    "df5 = df5[['target_horseid','4角サイドポジション']]\n",
    "df6 = df6[['target_horseid','4角位置']]\n",
    "df7 = df7[['target_raceid','馬場指数']]\n",
    "df8 = df8[['target_horseid','前半3F']]\n",
    "df9 = df9[['target_horseid','追切指数']]\n",
    "\n",
    "# カラムの整理\n",
    "# 成績データファイルの列名を変更\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid',\n",
    "    '上り3F': 'レース上り3F',\n",
    "    '上り4F': 'レース上り4F',\n",
    "    '上り5F': 'レース上り5F',\n",
    "    '外部指数1':'レイティング',\n",
    "    '外部指数順1':'レイティング順位',\n",
    "    '外部指数2':'ZI指数',\n",
    "    '外部指数順2':'ZI指数順位',\n",
    "    '外部指数3':'追切指数',\n",
    "    '外部指数順3':'追切指数順位',\n",
    "    '上り3F.1':'上り3F'\n",
    "}\n",
    "\n",
    "# df1の列名に対してrename_mapを適用\n",
    "df1 = df1.rename(columns=rename_map)\n",
    "\n",
    "# キーの型を揃える（数字/ゼロ埋めブレ防止）\n",
    "for c in ['target_horseid', 'target_raceid']:\n",
    "    if c in df1: df1[c] = df1[c].astype(str)\n",
    "for d in [df2, df3, df4, df5, df6, df7, df8, df9]:\n",
    "    for c in ['target_horseid', 'target_raceid']:\n",
    "        if c in d: d[c] = d[c].astype(str)\n",
    "\n",
    "#　種牡馬名のspace削除\n",
    "df1['種牡馬'] = df1['種牡馬'].astype(str).str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# ラベル化する列を追加\n",
    "# コースラベル\n",
    "insert_pos = df1.columns.get_loc('コースグループ名1') + 1\n",
    "df1.insert(insert_pos, 'コースラベル', df1['場所'].astype(str) + '_' + df1['芝・ダート'].astype(str) + '_' + df1['距離'].astype(str) + '_' + df1['トラックコード(JV)'].astype(str))\n",
    "\n",
    "# 父×母の父タイプ名\n",
    "insert_pos = df1.columns.get_loc('母の父タイプ名') + 1\n",
    "df1.insert(insert_pos, '父×母の父タイプ名', df1['種牡馬'].astype(str) + '×' + df1['母の父タイプ名'].astype(str))\n",
    "\n",
    "# 父タイプ名×母の父タイプ名\n",
    "insert_pos = df1.columns.get_loc('父×母の父タイプ名') + 1\n",
    "df1.insert(insert_pos, '父タイプ名×母の父タイプ名', df1['種牡馬タイプ名'].astype(str) + '×' + df1['母の父タイプ名'].astype(str))\n",
    "\n",
    "# 生産者×馬主\n",
    "insert_pos = df1.columns.get_loc('騎手') + 1\n",
    "df1.insert(insert_pos, '生産者×馬主', df1['生産者'].astype(str) + '×' + df1['馬主'].astype(str))\n",
    "\n",
    "# 生産者×調教師\n",
    "insert_pos = df1.columns.get_loc('生産者×馬主') + 1\n",
    "df1.insert(insert_pos, '生産者×調教師', df1['生産者'].astype(str) + '×' + df1['調教師'].astype(str))\n",
    "\n",
    "# 生産者×騎手\n",
    "insert_pos = df1.columns.get_loc('生産者×調教師') + 1\n",
    "df1.insert(insert_pos, '生産者×騎手', df1['生産者'].astype(str) + '×' + df1['騎手'].astype(str))\n",
    "\n",
    "# 馬主×調教師\n",
    "insert_pos = df1.columns.get_loc('生産者×騎手') + 1\n",
    "df1.insert(insert_pos, '馬主×調教師', df1['馬主'].astype(str) + '×' + df1['調教師'].astype(str))\n",
    "\n",
    "# 馬主×騎手\n",
    "insert_pos = df1.columns.get_loc('馬主×調教師') + 1\n",
    "df1.insert(insert_pos, '馬主×騎手', df1['馬主'].astype(str) + '×' + df1['騎手'].astype(str))\n",
    "\n",
    "# 調教師×騎手\n",
    "insert_pos = df1.columns.get_loc('馬主×騎手') + 1\n",
    "df1.insert(insert_pos, '調教師×騎手', df1['調教師'].astype(str) + '×' + df1['騎手'].astype(str))\n",
    "\n",
    "# 調教師×コースラベル\n",
    "insert_pos = df1.columns.get_loc('調教師×騎手') + 1\n",
    "df1.insert(insert_pos, '調教師×コースラベル', df1['調教師'].astype(str) + '×' + df1['コースラベル'].astype(str))\n",
    "\n",
    "# 騎手×コースラベル\n",
    "insert_pos = df1.columns.get_loc('調教師×コースラベル') + 1\n",
    "df1.insert(insert_pos, '騎手×コースラベル', df1['騎手'].astype(str) + '×' + df1['コースラベル'].astype(str))\n",
    "\n",
    "# 配当金額の列を作成する\n",
    "# 列から取り出す金額の数を定義\n",
    "target_cols = {\n",
    "    '単勝配当表記': ('単勝', 1),\n",
    "    '複勝配当表記': ('複勝', 3),\n",
    "    '枠連配当表記': ('枠連', 1),\n",
    "    '馬連配当表記': ('馬連', 1),\n",
    "    'ワイド配当表記': ('ワイド', 3),\n",
    "    '馬単配当表記': ('馬単', 1),\n",
    "    '３連複配当表記': ('３連複', 1),\n",
    "    '３連単配当表記': ('３連単', 1),\n",
    "}\n",
    "\n",
    "# 金額を取り出す正規表現パターン\n",
    "pattern = re.compile(r'[\\\\¥]\\s*([0-9,]+)(?=\\s*(?:\\(|/|$))')\n",
    "\n",
    "def pick_amounts(text, take=1):\n",
    "    if pd.isna(text):\n",
    "        return [np.nan]*take\n",
    "    s = str(text)\n",
    "    found = pattern.findall(s)\n",
    "    nums = []\n",
    "    for x in found:\n",
    "        try:\n",
    "            nums.append(int(x.replace(',', '')))\n",
    "        except:\n",
    "            # 変な値が来てもスルー\n",
    "            continue\n",
    "    # 必要な個数だけ先頭から取り、足りなければNaNで埋める\n",
    "    nums = nums[:take]\n",
    "    if len(nums) < take:\n",
    "        nums += [np.nan]*(take - len(nums))\n",
    "    return nums\n",
    "\n",
    "for src_col, (base_name, take) in target_cols.items():\n",
    "    if src_col not in df1.columns:\n",
    "        # その列が無い場合はスキップ\n",
    "        continue\n",
    "\n",
    "    # 値を取り出す\n",
    "    values = df1[src_col].apply(lambda x: pick_amounts(x, take))\n",
    "\n",
    "    # 1個だけなら「単勝」のように1列、3個なら「複勝1, 複勝2, 複勝3」の3列を作る\n",
    "    if take == 1:\n",
    "        col_name = base_name\n",
    "        df1[col_name] = values.apply(lambda v: v[0] if isinstance(v, list) else np.nan)\n",
    "        # Convert to integer, coercing errors to NaN\n",
    "        df1[col_name] = pd.to_numeric(df1[col_name], errors='coerce').astype('Int64')\n",
    "    else:\n",
    "        for i in range(take):\n",
    "            col_name = f'{base_name}{i+1}'\n",
    "            df1[col_name] = values.apply(lambda v: v[i] if isinstance(v, list) and len(v) > i else np.nan)\n",
    "            # Convert to integer, coercing errors to NaN\n",
    "            df1[col_name] = pd.to_numeric(df1[col_name], errors='coerce').astype('Int64')\n",
    "\n",
    "# 成績データファイルへ対象データをマージする\n",
    "# 初角位置のマージ\n",
    "df1 = pd.merge(df1, df2, on='target_horseid', how='left')\n",
    "# 2角位置のマージ\n",
    "df1 = pd.merge(df1, df3, on='target_horseid', how='left')\n",
    "# 3角位置のマージ\n",
    "df1 = pd.merge(df1, df4, on='target_horseid', how='left')\n",
    "# 4角位置のマージ\n",
    "df1 = pd.merge(df1, df5, on='target_horseid', how='left')\n",
    "# 上り位置のマージ\n",
    "df1 = pd.merge(df1, df6, on='target_horseid', how='left')\n",
    "# 馬場指数のマージ\n",
    "df1 = pd.merge(df1, df7, on='target_raceid', how='left')\n",
    "# 前半3Fのマージ\n",
    "df1 = pd.merge(df1, df8, on='target_horseid', how='left')\n",
    "# 追切指数の代入 とりあえずTrueで上書き\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df9[['target_horseid','追切指数']].dropna(subset=['追切指数']).set_index('target_horseid')\n",
    "left.update(right, overwrite=True)\n",
    "df1 = left.reset_index()\n",
    "\n",
    "# --- 関数群 ---\n",
    "def calculate_33_lap(df1):\n",
    "    \"\"\"距離ごとに33ラップを計算する\"\"\"\n",
    "    rap_33 = []\n",
    "    distance_to_lap_range = {\n",
    "        1000: (0, 3),\n",
    "        1200: (0, 3),\n",
    "        1300: (1, 4),\n",
    "        1400: (1, 4),\n",
    "        1500: (2, 5),\n",
    "        1600: (2, 5),\n",
    "        1700: (3, 6),\n",
    "        1800: (3, 6),\n",
    "        1900: (4, 7),\n",
    "        2000: (4, 7),\n",
    "        2100: (5, 8),\n",
    "        2200: (5, 8),\n",
    "        2300: (6, 9),\n",
    "        2400: (6, 9),\n",
    "        2500: (7, 10),\n",
    "        2600: (7, 10),\n",
    "        2700: (8, 11),\n",
    "        2800: (8, 11),\n",
    "        2900: (9, 12),\n",
    "        3000: (9, 12),\n",
    "        3100: (10, 13),\n",
    "        3200: (10, 13),\n",
    "        3300: (11, 14),\n",
    "        3400: (11, 14),\n",
    "        3500: (12, 15),\n",
    "        3600: (12, 15),\n",
    "    }\n",
    "    for _, row in df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_lap_range:\n",
    "            start, end = distance_to_lap_range[distance]\n",
    "            sum_6to4 = sum(lap_times[start:end])\n",
    "        elif distance == 1150:\n",
    "            sum_6to4 = round(lap_times[0] * 1.25, 1) + lap_times[1] + lap_times[2] if len(lap_times) >= 3 else None\n",
    "        else:\n",
    "            sum_6to4 = None\n",
    "        sum_3to1 = row['レース上り3F'] if 'レース上り3F' in row and not pd.isna(row['レース上り3F']) else None\n",
    "        rap_33_value = sum_6to4 - sum_3to1 if not pd.isna(sum_6to4) and not pd.isna(sum_3to1) else None\n",
    "        rap_33.append(rap_33_value)\n",
    "    df1['33ラップ'] = rap_33\n",
    "    return df1\n",
    "\n",
    "def calculate_middle_lap(df1):\n",
    "    \"\"\"距離ごとに中盤ラップ1・2を計算する\"\"\"\n",
    "    middle_lap1 = []\n",
    "    middle_lap2 = []\n",
    "    distance_to_mid_lap = {\n",
    "        1000: (2, 4, None, None),\n",
    "        1150: (2, 4, None, None),\n",
    "        1200: (2, 4, None, None),\n",
    "        1300: (2, 4, None, None),\n",
    "        1400: (2, 4, None, None),\n",
    "        1500: (3, 5, None, None),\n",
    "        1600: (3, 5, None, None),\n",
    "        1700: (3, 6, None, None),\n",
    "        1800: (3, 6, None, None),\n",
    "        1900: (3, 7, None, None),\n",
    "        2000: (3, 7, None, None),\n",
    "        2100: (3, 5, 5, 8),\n",
    "        2200: (3, 5, 5, 8),\n",
    "        2300: (3, 5, 5, 8),\n",
    "        2400: (3, 6, 6, 9),\n",
    "        2500: (3, 6, 6, 9),\n",
    "        2600: (3, 7, 7, 10),\n",
    "        3000: (3, 8, 8, 12),\n",
    "        3200: (3, 8, 8, 13),\n",
    "        3400: (3, 9, 9, 14),\n",
    "        3600: (3, 9, 9, 15),\n",
    "    }\n",
    "    for _, row in df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_mid_lap:\n",
    "            mid1_start, mid1_end, mid2_start, mid2_end = distance_to_mid_lap[distance]\n",
    "            mid1 = sum(lap_times[mid1_start:mid1_end]) if mid1_start is not None else None\n",
    "            mid2 = sum(lap_times[mid2_start:mid2_end]) if mid2_start is not None else None\n",
    "        else:\n",
    "            mid1 = None\n",
    "            mid2 = None\n",
    "        middle_lap1.append(mid1)\n",
    "        middle_lap2.append(mid2)\n",
    "    df1['中盤ラップ1'] = middle_lap1\n",
    "    df1['中盤ラップ2'] = middle_lap2\n",
    "    return df1\n",
    "\n",
    "def calculate_lap_features(df):\n",
    "    \"\"\"\n",
    "    Lap01～Lap25 を使って\n",
    "      ・最大加速（隣接ラップ差分の最小値）\n",
    "      ・ゴール前ラップ差（ラスト1F - ラスト2F）\n",
    "    を計算して df に列を追加する。\n",
    "    \"\"\"\n",
    "    lap_cols = [f'Lap{str(i).zfill(2)}' for i in range(1, 26)]\n",
    "\n",
    "    def _calc_row(row):\n",
    "        # その馬のラップ一覧（NaN は除外）\n",
    "        laps = []\n",
    "        for c in lap_cols:\n",
    "            if c in row.index and pd.notna(row[c]):\n",
    "                laps.append(row[c])\n",
    "\n",
    "        # ラップが1つ以下ならどっちも計算不能\n",
    "        if len(laps) < 2:\n",
    "            return pd.Series({'最大加速ラップ': np.nan, 'ゴール前ラップ差': np.nan})\n",
    "\n",
    "        laps = np.array(laps, dtype=float)\n",
    "\n",
    "        # 隣り合う差分（後ろ - 前）\n",
    "        diffs = np.diff(laps)   # 例：Lap02-Lap01, Lap03-Lap02, ...\n",
    "\n",
    "        # 最大加速 = 最もマイナスが大きい差分（＝最小値）\n",
    "        max_accel = diffs.min() if len(diffs) > 0 else np.nan\n",
    "\n",
    "        # 終盤ラップ差 = ラスト1F - ラスト2F\n",
    "        last_diff = laps[-1] - laps[-2] if len(laps) >= 2 else np.nan\n",
    "\n",
    "        return pd.Series({\n",
    "            '最大加速ラップ': max_accel if pd.notna(max_accel) else np.nan,\n",
    "            'ゴール前ラップ差': last_diff if pd.notna(last_diff) else np.nan\n",
    "        })\n",
    "\n",
    "    new_cols = df.apply(_calc_row, axis=1)\n",
    "    df['最大加速ラップ'] = new_cols['最大加速ラップ'].round(1)\n",
    "    df['ゴール前ラップ差'] = new_cols['ゴール前ラップ差'].round(1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_days_since_birth(df1):\n",
    "    \"\"\"生後日数を計算する\"\"\"\n",
    "    birth_days = []\n",
    "    for _, row in df1.iterrows():\n",
    "        race_date = datetime.strptime(row['日付S'], '%Y.%m.%d')\n",
    "        birth_str = row['誕生日'].replace(\" \", \"\").replace(\"日\", \"\").replace(\"-\", \"\")\n",
    "        birth_month, birth_day = map(int, birth_str.replace(\"月\", \" \").split())\n",
    "        birth_year = race_date.year - row['年齢']\n",
    "        try:\n",
    "            birth_date = datetime(birth_year, birth_month, birth_day)\n",
    "        except ValueError:\n",
    "            birth_date = datetime(birth_year, 2, 28)\n",
    "        days_old = (race_date - birth_date).days\n",
    "        birth_days.append(days_old)\n",
    "    df1['生後日数'] = birth_days\n",
    "    return df1\n",
    "\n",
    "def calculate_distance_diff(df1):\n",
    "    \"\"\"前走距離との差を計算する\"\"\"\n",
    "    df1['前走距離差'] = df1['距離'] - df1['前走距離']\n",
    "    return df1\n",
    "\n",
    "def calculate_firsthalf_diff(df1):\n",
    "    \"\"\"初角から4角位置の差分を計算\"\"\"\n",
    "    df1['初角_4角差'] = df1.apply(lambda row:\n",
    "        (row['通過1'] - row['通過4']) if pd.notna(row['通過1']) else \\\n",
    "        ((row['通過2'] - row['通過4']) if pd.notna(row['通過2']) else \\\n",
    "        ((row['通過3'] - row['通過4']) if pd.notna(row['通過3']) else np.nan))\n",
    "    , axis=1).fillna(0)\n",
    "    return df1\n",
    "\n",
    "def calculate_goal_diff(df1):\n",
    "    \"\"\"4角から入線順位の差分を計算\"\"\"\n",
    "    # 入線順位を一時的に数値化\n",
    "    rank_num = pd.to_numeric(df1['入線順位'], errors='coerce')\n",
    "\n",
    "    # 有効な順位（1以上）だけを判定するためのマスク\n",
    "    valid_mask = rank_num >= 1\n",
    "\n",
    "    # 出力列だけ作る\n",
    "    df1['4角_入線順位差'] = np.nan\n",
    "\n",
    "    # 有効な行だけ計算\n",
    "    df1.loc[valid_mask, '4角_入線順位差'] = (\n",
    "        pd.to_numeric(df1.loc[valid_mask, '通過4'], errors='coerce')\n",
    "        - rank_num[valid_mask]\n",
    "    )\n",
    "\n",
    "    return df1\n",
    "\n",
    "def calculate_sideposition(df1):\n",
    "    \"\"\"サイドポジションの平均を計算する\"\"\"\n",
    "    cols = ['初角サイドポジション', '2角サイドポジション', '3角サイドポジション', '4角サイドポジション']\n",
    "    df1['サイドポジション平均'] = df1[cols].mean(axis=1)\n",
    "    return df1\n",
    "\n",
    "def calculate_totalprize(df1):\n",
    "    \"\"\"獲得賞金を計算する\"\"\"\n",
    "    df1['獲得賞金'] = df1['賞金'].fillna(0) + df1['付加賞金'].fillna(0)\n",
    "    return df1\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "    \"\"\"タイム表記を秒数に変換\"\"\"\n",
    "    try:\n",
    "        parts = time_str.split(\".\")\n",
    "        if len(parts) == 3:\n",
    "            minutes, seconds, tenths = map(int, parts)\n",
    "            total_seconds = minutes * 60 + seconds + tenths * 0.1\n",
    "        else:\n",
    "            return np.nan\n",
    "        return total_seconds\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def remove_plus_sign(value):\n",
    "    \"\"\"数値データから `+` を削除して変換\"\"\"\n",
    "    try:\n",
    "        return float(str(value).replace(\"+\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def extract_weight(value):\n",
    "    \"\"\"斤量の数値部分だけを抽出\"\"\"\n",
    "    try:\n",
    "        match = re.search(r'\\d+', str(value))\n",
    "        return int(match.group()) if match else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_corner_loss(row):\n",
    "    \"\"\"コーナーロスを計算\"\"\"\n",
    "    corner_positions = [\n",
    "        row.get('初角サイドポジション', 1) - 1,\n",
    "        row.get('2角サイドポジション', 1) - 1,\n",
    "        row.get('3角サイドポジション', 1) - 1,\n",
    "        row.get('4角サイドポジション', 1) - 1\n",
    "    ]\n",
    "    total_distance_loss = sum(corner_positions) * 1.5  # m単位\n",
    "    finish_time_seconds = row['タイムS']\n",
    "    distance_m = row['距離']\n",
    "    if pd.isna(finish_time_seconds) or pd.isna(distance_m) or finish_time_seconds == 0:\n",
    "        return np.nan\n",
    "    avg_speed = distance_m / finish_time_seconds if finish_time_seconds > 0 else np.nan\n",
    "    corner_loss = total_distance_loss / avg_speed if avg_speed > 0 else 0\n",
    "    return round(corner_loss, 2)\n",
    "\n",
    "# 各列の整形\n",
    "# 対象の列を数値変換\n",
    "df1['馬場指数'] = df1['馬場指数'].astype(str).str.extract(r'(-?\\d+)')[0].astype('Int64')\n",
    "df1['レイティング'] = pd.to_numeric(df1['レイティング'], errors='coerce')\n",
    "df1['体重'] = pd.to_numeric(df1['体重'], errors='coerce')\n",
    "df1['Ave-3F'] = pd.to_numeric(df1['Ave-3F'], errors='coerce')\n",
    "df1['上り3F'] = pd.to_numeric(df1['上り3F'], errors='coerce')\n",
    "\n",
    "# 対象の列から記号を除去\n",
    "for col in ['前後3F差', '前後4F差', '前後5F差', '増減']:\n",
    "    df1[col] = df1[col].apply(remove_plus_sign)\n",
    "\n",
    "df1['斤量'] = df1['斤量'].apply(extract_weight)\n",
    "\n",
    "# タイムを秒数に変換\n",
    "df1['タイムS'] = df1['タイムS'].apply(convert_time_to_seconds)\n",
    "df1['-3Fタイム'] = df1['-3Fタイム'].apply(convert_time_to_seconds)\n",
    "\n",
    "# 決め手列を変換(マップにない場合はNanにする)\n",
    "lq_mapping = {\n",
    "    '中団': '差し',\n",
    "    '後方': '追込',\n",
    "}\n",
    "\n",
    "s = df1['決め手'].astype('string').str.strip()\n",
    "df1['決め手'] = s.map(lq_mapping)\n",
    "\n",
    "# 各種計算関数を順次実行\n",
    "# 33ラップの計算\n",
    "df1 = calculate_33_lap(df1)\n",
    "# 中盤ラップ1・2の計算\n",
    "df1 = calculate_middle_lap(df1)\n",
    "# 最大加速ラップ・ゴール前ラップ差の計算\n",
    "df1 = calculate_lap_features(df1)\n",
    "# 生後日数の計算\n",
    "df1 = calculate_days_since_birth(df1)\n",
    "# 前走距離差の計算\n",
    "df1 = calculate_distance_diff(df1)\n",
    "# 初角から4角通過順位差の計算\n",
    "df1 = calculate_firsthalf_diff(df1)\n",
    "# 4角から入線順位差の計算\n",
    "df1 = calculate_goal_diff(df1)\n",
    "# サイドポジション平均値の計算\n",
    "df1 = calculate_sideposition(df1)\n",
    "# 獲得賞金の計算\n",
    "df1 = calculate_totalprize(df1)\n",
    "# 基準斤量の計算\n",
    "df1['基準斤量'] = df1['斤量'] - df1['馬齢斤量差']\n",
    "# RPCI差の計算\n",
    "df1['RPCI差'] = df1['PCI'] - df1['レースPCI']\n",
    "# コーナーロスの計算\n",
    "df1['コーナーロス'] = df1.apply(calculate_corner_loss, axis=1)\n",
    "# 補正走破タイムの計算\n",
    "df1['補正走破タイム'] = df1['タイムS'] - df1['コーナーロス']\n",
    "# スローorハイ関数の計算\n",
    "df1['スローorハイ関数'] = df1['Ave-3F'] - df1['上り3F']\n",
    "\n",
    "# マージ用の列作成処理\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 115:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 範囲定義\n",
    "ranges = [ (-np.inf, -4.6), (-4.6, -3.6), (-3.6, -2.6), (-2.6, -1.6), (-1.6, -0.6), (-0.6, 0.6), (0.6, 1.6), (1.6, 2.6), (2.6, 3.6), (3.6, 4.6), (4.6, np.inf) ]\n",
    "\n",
    "# 区間ラベル\n",
    "def assign_range(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        if i < len(ranges) - 1:\n",
    "            if lower <= value < upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "        else:\n",
    "            # 最終区間（4.6～inf）は右も含める\n",
    "            if lower <= value <= upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "    return np.nan  # 念のため\n",
    "\n",
    "# 馬場分類・競走種別・クラス分類・スローor関数範囲の列を作成する\n",
    "df1['馬場分類'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1['競走種別'] = df1['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df1['クラス分類'] = df1['クラスコード'].apply(categorize_class_code)\n",
    "df1['スローorハイ関数範囲'] = df1['スローorハイ関数'].apply(assign_range)\n",
    "\n",
    "# --- 集計設定 ---\n",
    "agg_cols1 = {\n",
    "    'レースPCI': 'median',\n",
    "    'PCI3': 'median',\n",
    "    '通過3F': 'median',\n",
    "    '通過4F': 'median',\n",
    "    '通過5F': 'median',\n",
    "    'レース上り3F': 'median',\n",
    "    'レース上り4F': 'median',\n",
    "    'レース上り5F': 'median',\n",
    "    '中盤ラップ1': 'median',\n",
    "    '中盤ラップ2': 'median',\n",
    "    '33ラップ': 'median',\n",
    "    '最大加速ラップ': 'median',\n",
    "    'ゴール前ラップ差': 'median',\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング順位': 'median',\n",
    "    'ZI指数': 'median',\n",
    "    'ZI指数順位': 'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    'PCI': 'median',\n",
    "    'RPCI差': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '補正タイム': 'median',\n",
    "    '補9': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '初角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "agg_cols2 = {\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング順位': 'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    'ZI指数': 'median',\n",
    "    'ZI指数順位': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    'PCI': 'median',\n",
    "    'RPCI差': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '補正タイム': 'median',\n",
    "    '補9': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '初角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "# --- 基準タイム算出処理1 ---\n",
    "\n",
    "# 1勝クラス・2勝クラスのみ対象\n",
    "base_df1 = df1[df1['クラスコード'].isin([23, 43])].copy()\n",
    "\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops1 = base_df1[base_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st1 = base_df1[base_df1['入線順位'] == 1].copy()\n",
    "\n",
    "# クラス分類の統一\n",
    "df_tops1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "df_1st1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "\n",
    "# グループ化キー\n",
    "group_cols1 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)','馬場分類', 'クラス分類']\n",
    "\n",
    "# --- 集計処理 ---\n",
    "base_time_tops1 = df_tops1.groupby(group_cols1, dropna=False).agg(agg_cols1).reset_index()\n",
    "base_time_1st1 = df_1st1.groupby(group_cols1, dropna=False).agg(agg_cols2).reset_index()\n",
    "base_time_1st1 = base_time_1st1.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "\n",
    "# --- 結合 ---\n",
    "base_time_df1 = pd.merge(base_time_tops1, base_time_1st1, on=group_cols1, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df1['距離係数'] = (1 / base_time_df1['タイムS']) * 100\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "\n",
    "df_tops2 = df1[df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st2 = df1[df1['入線順位'] == 1].copy()\n",
    "\n",
    "# グループ化キー\n",
    "group_cols2 = ['場所', '芝・ダート', '距離','トラックコード(JV)', '競走種別', 'クラス分類', '馬場分類']\n",
    "\n",
    "base_time_tops2 = df_tops2.groupby(group_cols2).agg(agg_cols1).reset_index()\n",
    "base_time_1st2 = df_1st2.groupby(group_cols2).agg(agg_cols2).reset_index()\n",
    "base_time_1st2 = base_time_1st2.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "base_time_df2 = pd.merge(base_time_tops2, base_time_1st2, on=group_cols2, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df2['距離係数'] = (1 / base_time_df2['タイムS']) * 100\n",
    "\n",
    "# --- ペース係数算出処理 ---\n",
    "\n",
    "# 外れ値除外（IQR）\n",
    "def remove_outliers(group):\n",
    "    Q1 = group['タイムS'].quantile(0.25)\n",
    "    Q3 = group['タイムS'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return group[(group['タイムS'] >= lower_bound) & (group['タイムS'] <= upper_bound)]\n",
    "\n",
    "# グルーピング＆IQR除外\n",
    "pace_df = (\n",
    "    df1.groupby(['場所', '芝・ダート', '距離','トラックコード(JV)'])\n",
    "       .apply(remove_outliers)\n",
    "       .reset_index(drop=True)\n",
    "       .copy()\n",
    ")\n",
    "\n",
    "# 区間別の中央値（タイムS & スローorハイ関数）\n",
    "pace_medians_df = pace_df.groupby(\n",
    "    ['場所', '芝・ダート', '距離','トラックコード(JV)', 'スローorハイ関数範囲']\n",
    ").agg({\n",
    "    'タイムS': 'median',\n",
    "    'スローorハイ関数': 'median'\n",
    "}).reset_index()\n",
    "\n",
    "# --- ベースライン作成 ---\n",
    "# 優先：-0.6～0.6（中庸帯）\n",
    "# 代用：0.6～1.6 / -1.6～-0.6 の平均 → どちらか片方だけでも可\n",
    "baseline_medians = {}\n",
    "for (location, turf_dirt, distance,track_code), group_df in pace_medians_df.groupby(['場所', '芝・ダート', '距離','トラックコード(JV)']):\n",
    "    baseline_row = group_df[group_df['スローorハイ関数範囲'] == '-0.6～0.6']\n",
    "    if not baseline_row.empty:\n",
    "        baseline_median = float(baseline_row['タイムS'].iloc[0])\n",
    "    else:\n",
    "        range_negative = group_df[group_df['スローorハイ関数範囲'] == '-1.6～-0.6']\n",
    "        range_positive = group_df[group_df['スローorハイ関数範囲'] == '0.6～1.6']\n",
    "        if not range_negative.empty and not range_positive.empty:\n",
    "            baseline_median = (float(range_negative['タイムS'].median()) +\n",
    "                               float(range_positive['タイムS'].median())) / 2.0\n",
    "        elif not range_negative.empty:\n",
    "            baseline_median = float(range_negative['タイムS'].median())\n",
    "        elif not range_positive.empty:\n",
    "            baseline_median = float(range_positive['タイムS'].median())\n",
    "        else:\n",
    "            baseline_median = np.nan\n",
    "    baseline_medians[(location, turf_dirt, distance,track_code)] = baseline_median\n",
    "\n",
    "# ベースラインとの差（スローorハイ関数差指数）\n",
    "def calculate_difference(row):\n",
    "    key = (row['場所'], row['芝・ダート'], row['距離'],row['トラックコード(JV)'])\n",
    "    baseline_time = baseline_medians.get(key, np.nan)\n",
    "    return row['タイムS'] - baseline_time if not pd.isna(baseline_time) else np.nan\n",
    "\n",
    "pace_medians_df['スローorハイ関数差指数'] = pace_medians_df.apply(calculate_difference, axis=1)\n",
    "\n",
    "# 係数計算（0除算・NaN安全＋クリップ）\n",
    "def calculate_pace_adjustment_coefficient(row):\n",
    "    val = row['スローorハイ関数']\n",
    "    diff = row['スローorハイ関数差指数']\n",
    "    if pd.notna(val) and val != 0 and pd.notna(diff):\n",
    "        coefficient = round(diff / val, 2)\n",
    "        return float(np.clip(coefficient, -3, 3))\n",
    "    return 0.0\n",
    "\n",
    "pace_medians_df['ペース補正係数'] = pace_medians_df.apply(calculate_pace_adjustment_coefficient, axis=1)\n",
    "\n",
    "# --- 基準33ラップ算出処理 ---\n",
    "\n",
    "lap33_df = (\n",
    "    df1\n",
    "      .dropna(subset=['33ラップ'])  # まず欠損を除外\n",
    "      .groupby(['場所', '芝・ダート', '距離', 'トラックコード(JV)'], dropna=False)['33ラップ']\n",
    "      .agg(['mean', 'std'])  # mean と std を同時に集計\n",
    "      .reset_index()\n",
    ").copy()\n",
    "\n",
    "# 近似Zスコア用の基準値を計算\n",
    "lap33_df['33ラップ±0'] = lap33_df['mean'].round(2)\n",
    "lap33_df['33ラップ+1'] = (lap33_df['mean'] + lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ-1'] = (lap33_df['mean'] - lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ+2'] = (lap33_df['mean'] + 2 * lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ-2'] = (lap33_df['mean'] - 2 * lap33_df['std']).round(2)\n",
    "\n",
    "# 必要なカラムだけ残す\n",
    "lap33_df = lap33_df[\n",
    "    ['場所', '芝・ダート', '距離', 'トラックコード(JV)',\n",
    "     '33ラップ-2', '33ラップ-1', '33ラップ±0', '33ラップ+1', '33ラップ+2',\n",
    "     'mean', 'std']\n",
    "]\n",
    "\n",
    "#---ステップ２：成績データへ指数の追加\n",
    "# 共通関数：参照側DFのキー以外の列にサフィックスを付ける\n",
    "def prepare_ref_df(df_ref, merge_keys, suffix):\n",
    "    \"\"\"\n",
    "    マージ用の参照DFの列名に suffix を付ける（キー列以外すべて）\n",
    "    \"\"\"\n",
    "    df_ref = df_ref.copy()\n",
    "    rename_map = {\n",
    "        c: f\"{c}{suffix}\"\n",
    "        for c in df_ref.columns\n",
    "        if c not in merge_keys\n",
    "    }\n",
    "    df_ref = df_ref.rename(columns=rename_map)\n",
    "    return df_ref\n",
    "\n",
    "# マージキー\n",
    "merge_key1 = ['場所','芝・ダート','距離','トラックコード(JV)','馬場分類']\n",
    "merge_key2 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類','馬場分類']\n",
    "merge_key3 = ['場所','芝・ダート','距離','トラックコード(JV)','スローorハイ関数範囲']\n",
    "merge_key4 = ['場所','芝・ダート','距離','トラックコード(JV)']\n",
    "\n",
    "# 参照側の列名にsuffixを付与\n",
    "ref_df1 = prepare_ref_df(base_time_df1, merge_key1, '_stdtime1').copy()\n",
    "ref_df2 = prepare_ref_df(base_time_df2, merge_key2, '_stdtime2').copy()\n",
    "ref_df3 = prepare_ref_df(pace_medians_df, merge_key3, '_paceindex').copy()\n",
    "ref_df4 = prepare_ref_df(lap33_df, merge_key4, '_33lap').copy()\n",
    "\n",
    "# df1へその他データフレームをマージ\n",
    "merged_df1 = pd.merge(df1, ref_df1, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, ref_df2, on=merge_key2, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, ref_df3, on=merge_key3, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, ref_df4, on=merge_key4, how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del df1, ref_df1, ref_df2, ref_df3, ref_df4\n",
    "\n",
    "# 各指数算出の前処理\n",
    "# 基準タイム/距離係数のベース列を作る（Std1優先、なければStd2）\n",
    "base_time = merged_df1['タイムS_stdtime1'].fillna(merged_df1['タイムS_stdtime2'])\n",
    "dist_coef = merged_df1['距離係数_stdtime1'].fillna(merged_df1['距離係数_stdtime2'])\n",
    "\n",
    "# 基準タイム差（秒）：基準タイム - 補正走破タイム\n",
    "base_time_diff = base_time - merged_df1['補正走破タイム']\n",
    "\n",
    "# 基準タイム差×距離係数\n",
    "speed_core = base_time_diff * dist_coef\n",
    "\n",
    "# 平均3F補正値\n",
    "ave3f_base = merged_df1['Ave-3F_stdtime1'].fillna(merged_df1['Ave-3F_stdtime2'])\n",
    "revi_Ave3F = ave3f_base - merged_df1['Ave-3F']\n",
    "\n",
    "# 斤量補正値\n",
    "revi_weight = merged_df1['斤量'] - merged_df1['基準斤量']\n",
    "\n",
    "# クラス補正値（Std1が存在する行だけ有効。Std2代用行では0）\n",
    "# ※ Std1が無い = その条件の1・2勝基準が作れない想定なので、クラス補正は入れない\n",
    "revi_class = (merged_df1['タイムS_stdtime1'] - merged_df1['タイムS_stdtime2']).where(\n",
    "    merged_df1['タイムS_stdtime1'].notna(), 0\n",
    ")\n",
    "\n",
    "# ペース補正値\n",
    "revi_pace = merged_df1['スローorハイ関数'] * merged_df1['ペース補正係数_paceindex']\n",
    "\n",
    "# 馬場指数秒数換算\n",
    "merged_df1['馬場補正値'] = merged_df1['馬場指数'] / 10\n",
    "\n",
    "# 初角位置\n",
    "merged_df1['初角位置'] = (\n",
    "    merged_df1['通過1']\n",
    "      .fillna(merged_df1['通過2'])\n",
    "      .fillna(merged_df1['通過3'])\n",
    "      .fillna(merged_df1['通過4'])\n",
    ")\n",
    "\n",
    "# テン指数の計算\n",
    "merged_df1['テン指数'] = round((\n",
    "(merged_df1['前半3F_stdtime1'].fillna(merged_df1['前半3F_stdtime2']) - merged_df1['前半3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数'] - merged_df1['初角位置'] + 1) / merged_df1['頭数']) # 初角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# 上り指数の計算\n",
    "merged_df1['上り指数'] = round((\n",
    "(merged_df1['上り3F_stdtime1'].fillna(merged_df1['上り3F_stdtime2']) - merged_df1['上り3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数']) - merged_df1['入線順位'] + 1) / merged_df1['頭数'] # 着順評価\n",
    "+ (merged_df1['通過4'] - merged_df1['入線順位']) / merged_df1['頭数'] # ポジション押し上げ力評価\n",
    "+ (merged_df1['頭数'] - merged_df1['通過4'] + 1) / merged_df1['頭数'] # 4角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# スピード指数の計算 ---\n",
    "merged_df1['スピード指数'] = (\n",
    "    (\n",
    "        speed_core\n",
    "        + merged_df1['馬場補正値'].fillna(0)\n",
    "        + revi_Ave3F.fillna(0)\n",
    "        + revi_weight.fillna(0)\n",
    "        + revi_class.fillna(0)\n",
    "        + revi_pace.fillna(0)\n",
    "        + 100\n",
    "    )\n",
    "    .round(1)\n",
    "    .where(speed_core.notna() & (speed_core != 0))\n",
    ")\n",
    "\n",
    "# 総合指数の計算\n",
    "merged_df1['総合指数'] = merged_df1[['スピード指数', '補正タイム', '補9']].mean(axis=1).round(1)\n",
    "\n",
    "# 総合指数の代表値(1着～3着)をdf1へ追加\n",
    "central_score_df1 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "central_score_df1 = central_score_df1.groupby('target_raceid' ,as_index = False)['総合指数'].mean()\n",
    "central_score_df1.rename(columns={'総合指数': 'Top3総合指数'}, inplace=True)\n",
    "central_score_df1['Top3総合指数'] = round(central_score_df1['Top3総合指数'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df1, on='target_raceid', how='left',suffixes=('', '_centralscore1')).copy()\n",
    "\n",
    "# レイティングの平均値を成績データへ追加\n",
    "merged_df1['レイティング'] = pd.to_numeric(merged_df1['レイティング'], errors='coerce')\n",
    "central_score_df2 = merged_df1.groupby('target_raceid' ,as_index = False)['レイティング'].mean().copy()\n",
    "central_score_df2.rename(columns={'レイティング': 'レイティング平均値'}, inplace=True)\n",
    "central_score_df2['レイティング平均値'] = round(central_score_df2['レイティング平均値'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df2, on='target_raceid', how='left' ,suffixes=('', '_centralscore2')).copy()\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del central_score_df1, central_score_df2\n",
    "\n",
    "# 各指数の偏差値を計算\n",
    "def deviation_in_race(series):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    if pd.isna(std) or std == 0:\n",
    "        return pd.Series(np.nan, index=series.index)\n",
    "    return ((series - mean) / std * 10 + 50)\n",
    "\n",
    "# レース内偏差値\n",
    "merged_df1['レイティング偏差値'] = (merged_df1.groupby('target_raceid')['レイティング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['ZI指数偏差値'] = (merged_df1.groupby('target_raceid')['ZI指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['追切指数偏差値'] = (merged_df1.groupby('target_raceid')['追切指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['マイニング偏差値'] = (merged_df1.groupby('target_raceid')['マイニング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['対戦型マイニング偏差値'] = (merged_df1.groupby('target_raceid')['対戦型マイニング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['前半3F偏差値'] = merged_df1.groupby('target_raceid')['前半3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['上り3F偏差値'] = merged_df1.groupby('target_raceid')['上り3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['Ave-3F偏差値'] = merged_df1.groupby('target_raceid')['Ave-3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['テン指数偏差値'] = (merged_df1.groupby('target_raceid')['テン指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['上り指数偏差値'] = (merged_df1.groupby('target_raceid')['上り指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['スピード指数偏差値'] = (merged_df1.groupby('target_raceid')['スピード指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['総合指数偏差値'] = (merged_df1.groupby('target_raceid')['総合指数'].transform(deviation_in_race).round(1))\n",
    "\n",
    "# レース内順位（dense）\n",
    "merged_df1['前半3F順位'] = (merged_df1.groupby('target_raceid')['前半3F'].rank(ascending=True, method='dense').astype('Int64'))\n",
    "merged_df1['テン指数順位'] = (merged_df1.groupby('target_raceid')['テン指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['上り指数順位'] = (merged_df1.groupby('target_raceid')['上り指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['Ave-3F順位'] = (merged_df1.groupby('target_raceid')['Ave-3F'].rank(ascending=True, method='dense').astype('Int64'))\n",
    "merged_df1['スピード指数順位'] = (merged_df1.groupby('target_raceid')['スピード指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['総合指数順位'] = (merged_df1.groupby('target_raceid')['総合指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "\n",
    "# 順位分布の計算\n",
    "merged_df1['レイティング順位分布'] = (merged_df1['レイティング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['ZI指数順位分布'] = (merged_df1['ZI指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['追切指数順位分布'] = (merged_df1['追切指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['マイニング順位分布'] = (merged_df1['マイニング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['対戦型マイニング順位分布'] = (merged_df1['対戦型マイニング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['前半3F順位分布'] = (merged_df1['前半3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['テン指数順位分布'] = (merged_df1['テン指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['上り3F順位分布'] = (merged_df1['上り3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['上り指数順位分布'] = (merged_df1['上り指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['Ave-3F順位分布'] = (merged_df1['Ave-3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['スピード指数順位分布'] = (merged_df1['スピード指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['総合指数順位分布'] = (merged_df1['総合指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "\n",
    "# 33ラップ判定用関数\n",
    "def assign_label(row):\n",
    "    lap_value = row['33ラップ']\n",
    "    if pd.isna(lap_value):\n",
    "        return np.nan\n",
    "\n",
    "    candidates = {\n",
    "        -2: row['33ラップ-2_33lap'],\n",
    "        -1: row['33ラップ-1_33lap'],\n",
    "         0: row['33ラップ±0_33lap'],\n",
    "         1: row['33ラップ+1_33lap'],\n",
    "         2: row['33ラップ+2_33lap'],\n",
    "    }\n",
    "\n",
    "    # 参照側が全部NaNなら判定不能\n",
    "    if all(pd.isna(v) for v in candidates.values()):\n",
    "        return np.nan\n",
    "\n",
    "    # 差分（絶対値）が最小のスケールを選ぶ\n",
    "    best_scale = min(\n",
    "        candidates.keys(),\n",
    "        key=lambda k: abs(lap_value - candidates[k]) if pd.notna(candidates[k]) else np.inf\n",
    "    )\n",
    "\n",
    "    # 0スケール\n",
    "    if best_scale == 0:\n",
    "        if lap_value < 0:\n",
    "            return '持0'\n",
    "        elif lap_value > 0:\n",
    "            return '瞬0'\n",
    "        else:\n",
    "            return '総'\n",
    "\n",
    "    prefix = '瞬' if lap_value > 0 else '持'\n",
    "    suffix = f'+{best_scale}' if best_scale > 0 else f'{best_scale}'\n",
    "    return prefix + suffix\n",
    "\n",
    "# 33ラップを判定\n",
    "merged_df1['33ラップ判定'] = merged_df1.apply(assign_label, axis=1)\n",
    "\n",
    "# レースタイプラベル列の追加\n",
    "insert_pos = merged_df1.columns.get_loc('33ラップ判定') + 1\n",
    "\n",
    "# '33ラップ判定' の値 → レースタイプ の対応表\n",
    "race_type_map = {\n",
    "    # 瞬発力戦\n",
    "    '瞬+2': '瞬発力戦',\n",
    "    '瞬+1': '瞬発力戦',\n",
    "    '瞬0':  '瞬発力戦',\n",
    "\n",
    "    # 総合力戦\n",
    "    '瞬-1': '総合力戦',\n",
    "    '瞬-2': '総合力戦',\n",
    "    '総':   '総合力戦',\n",
    "    '持-1': '総合力戦',\n",
    "    '持-2': '総合力戦',\n",
    "\n",
    "    # 持久力戦\n",
    "    '持+2': '持久力戦',\n",
    "    '持+1': '持久力戦',\n",
    "    '持+0': '持久力戦',\n",
    "}\n",
    "\n",
    "ref = merged_df1['33ラップ判定']\n",
    "merged_df1.insert(insert_pos, 'レースタイプ', ref.map(race_type_map))\n",
    "\n",
    "# ラベル書き換え用のマッピング辞書\n",
    "label_mapping = {\n",
    "    '持-2': '0T持-2',\n",
    "    '持-1': '0T持-1',\n",
    "    '持0': '0U持0',\n",
    "    '持+1': '0V持+1',\n",
    "    '持+2': '0V持+2',\n",
    "    '瞬-2': '0S瞬-2',\n",
    "    '瞬-1': '0S瞬-1',\n",
    "    '瞬0': '0R瞬0',\n",
    "    '瞬+1': '0Q瞬+1',\n",
    "    '瞬+2': '0Q瞬+2',\n",
    "    '総': '02総'\n",
    "}\n",
    "\n",
    "# 書き換え\n",
    "merged_df1['レース印２'] = merged_df1['33ラップ判定'].replace(label_mapping)\n",
    "\n",
    "# レース強度指数の計算\n",
    "first_load  = merged_df1['通過3F_stdtime1'].fillna(merged_df1['通過3F_stdtime2']) - merged_df1['通過3F']\n",
    "\n",
    "middle_diff1 = merged_df1['中盤ラップ1_stdtime1'].fillna(merged_df1['中盤ラップ1_stdtime2']) - merged_df1['中盤ラップ1']\n",
    "middle_diff2 = merged_df1['中盤ラップ2_stdtime1'].fillna(merged_df1['中盤ラップ2_stdtime2']) - merged_df1['中盤ラップ2']\n",
    "\n",
    "middle_load = pd.concat([middle_diff1, middle_diff2], axis=1).mean(axis=1, skipna=True)\n",
    "\n",
    "last_load   = merged_df1['レース上り3F_stdtime1'].fillna(merged_df1['レース上り3F_stdtime2']) - merged_df1['レース上り3F']\n",
    "spurt_load  = merged_df1['最大加速ラップ_stdtime1'].fillna(merged_df1['最大加速ラップ_stdtime2']) - merged_df1['最大加速ラップ']\n",
    "goal_load   = merged_df1['ゴール前ラップ差_stdtime1'].fillna(merged_df1['ゴール前ラップ差_stdtime2']) - merged_df1['ゴール前ラップ差']\n",
    "\n",
    "merged_df1['レース強度指数'] = (\n",
    "    100\n",
    "    + first_load.fillna(0)\n",
    "    + middle_load.fillna(0)\n",
    "    + last_load.fillna(0)\n",
    "    + spurt_load.fillna(0)\n",
    "    + goal_load.fillna(0)\n",
    "    + merged_df1['馬場補正値'].fillna(0)\n",
    ")\n",
    "\n",
    "# サフィックス付き列を削除\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_1着','_stdtime1', '_stdtime2', '_paceindex', '_33lap', '_centralscore1', '_centralscore2')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "merged_df1 = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "#---ステップ３：基準タイムファイル１・２の再集計\n",
    "# --- 集計設定 ---\n",
    "agg_cols3 = {\n",
    "    'レースPCI': 'median',\n",
    "    'PCI3': 'median',\n",
    "    '通過3F': 'median',\n",
    "    '通過4F': 'median',\n",
    "    '通過5F': 'median',\n",
    "    'レース上り3F': 'median',\n",
    "    'レース上り4F': 'median',\n",
    "    'レース上り5F': 'median',\n",
    "    '中盤ラップ1': 'median',\n",
    "    '中盤ラップ2': 'median',\n",
    "    '33ラップ': 'median',\n",
    "    '最大加速ラップ': 'median',\n",
    "    'ゴール前ラップ差': 'median',\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング偏差値': 'median',\n",
    "    'レイティング順位': 'median',\n",
    "    'レイティング順位分布':'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数偏差値': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    '追切指数順位分布': 'median',\n",
    "    'ZI指数': 'median',\n",
    "    'ZI指数順位': 'median',\n",
    "    'ZI指数偏差値': 'median',\n",
    "    'ZI指数順位分布': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング偏差値': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    'マイニング順位分布': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング偏差値': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    '対戦型マイニング順位分布': 'median',\n",
    "    'PCI': 'median',\n",
    "    'RPCI差': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '前半3F偏差値': 'median',\n",
    "    '前半3F順位': 'median',\n",
    "    '前半3F順位分布': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F偏差値': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    '上り3F順位分布': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    'Ave-3F偏差値': 'median',\n",
    "    'Ave-3F順位': 'median',\n",
    "    'Ave-3F順位分布': 'median',\n",
    "    '-3F差': 'median',\n",
    "    'テン指数': 'median',\n",
    "    'テン指数偏差値': 'median',\n",
    "    'テン指数順位': 'median',\n",
    "    'テン指数順位分布': 'median',\n",
    "    '上り指数': 'median',\n",
    "    '上り指数偏差値': 'median',\n",
    "    '上り指数順位': 'median',\n",
    "    '上り指数順位分布': 'median',\n",
    "    '補正タイム': 'median',\n",
    "    '補9': 'median',\n",
    "    'スピード指数': 'median',\n",
    "    'スピード指数偏差値': 'median',\n",
    "    'スピード指数順位': 'median',\n",
    "    'スピード指数順位分布': 'median',\n",
    "    '総合指数': 'median',\n",
    "    '総合指数偏差値': 'median',\n",
    "    '総合指数順位': 'median',\n",
    "    '総合指数順位分布': 'median',\n",
    "    'レース強度指数': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '初角位置': 'median',\n",
    "    '初角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "agg_cols4 = {\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング偏差値': 'median',\n",
    "    'レイティング順位': 'median',\n",
    "    'レイティング順位分布':'median',\n",
    "    'ZI指数': 'median',\n",
    "    'ZI指数順位': 'median',\n",
    "    'ZI指数偏差値': 'median',\n",
    "    'ZI指数順位分布': 'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    '追切指数偏差値': 'median',\n",
    "    '追切指数順位分布': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング偏差値': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    'マイニング順位分布': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング偏差値': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    '対戦型マイニング順位分布': 'median',\n",
    "    'PCI': 'median',\n",
    "    'RPCI差': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '前半3F偏差値': 'median',\n",
    "    '前半3F順位': 'median',\n",
    "    '前半3F順位分布': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F偏差値': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    '上り3F順位分布': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    'Ave-3F偏差値': 'median',\n",
    "    'Ave-3F順位': 'median',\n",
    "    'Ave-3F順位分布': 'median',\n",
    "    '-3F差': 'median',\n",
    "    'テン指数': 'median',\n",
    "    'テン指数偏差値': 'median',\n",
    "    'テン指数順位': 'median',\n",
    "    'テン指数順位分布': 'median',\n",
    "    '上り指数': 'median',\n",
    "    '上り指数偏差値': 'median',\n",
    "    '上り指数順位': 'median',\n",
    "    '上り指数順位分布': 'median',\n",
    "    'スピード指数': 'median',\n",
    "    'スピード指数偏差値': 'median',\n",
    "    'スピード指数順位': 'median',\n",
    "    'スピード指数順位分布': 'median',\n",
    "    '補正タイム': 'median',\n",
    "    '補9': 'median',\n",
    "    '総合指数': 'median',\n",
    "    '総合指数偏差値': 'median',\n",
    "    '総合指数順位': 'median',\n",
    "    '総合指数順位分布': 'median',\n",
    "    'レース強度指数': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '初角位置': 'median',\n",
    "    '初角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "# 1勝クラス・2勝クラスのみ対象\n",
    "base_df1 = merged_df1[merged_df1['クラスコード'].isin([23, 43])].copy()\n",
    "\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops1 = base_df1[base_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st1 = base_df1[base_df1['入線順位'] == 1].copy()\n",
    "\n",
    "# クラス分類の統一\n",
    "df_tops1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "df_1st1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "\n",
    "# --- 集計処理 ---\n",
    "base_time_tops1 = df_tops1.groupby(group_cols1, dropna=False).agg(agg_cols3).reset_index()\n",
    "base_time_1st1 = df_1st1.groupby(group_cols1, dropna=False).agg(agg_cols4).reset_index()\n",
    "base_time_1st1 = base_time_1st1.rename(columns={col: f\"{col}_1着\" for col in agg_cols4.keys()})\n",
    "\n",
    "# --- 結合 ---\n",
    "base_time_df1 = pd.merge(base_time_tops1, base_time_1st1, on=group_cols1, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df1['距離係数'] = (1 / base_time_df1['タイムS']) * 100\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "df_tops2 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st2 = merged_df1[merged_df1['入線順位'] == 1].copy()\n",
    "\n",
    "base_time_tops2 = df_tops2.groupby(group_cols2).agg(agg_cols3).reset_index()\n",
    "base_time_1st2 = df_1st2.groupby(group_cols2).agg(agg_cols4).reset_index()\n",
    "base_time_1st2 = base_time_1st2.rename(columns={col: f\"{col}_1着\" for col in agg_cols4.keys()})\n",
    "base_time_df2 = pd.merge(base_time_tops2, base_time_1st2, on=group_cols2, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df2['距離係数'] = (1 / base_time_df2['タイムS']) * 100\n",
    "\n",
    "#---ステップ４：成績データへレースレベル指数の追加\n",
    "# 再集計した基準DFを suffix 付きで準備\n",
    "std1_pre = prepare_ref_df(base_time_df1, merge_key1, '_stdtime1_new')\n",
    "std2_pre = prepare_ref_df(base_time_df2, merge_key2, '_stdtime2_new')\n",
    "\n",
    "# merged_df1にマージ\n",
    "merged_df1 = pd.merge(merged_df1, std1_pre, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, std2_pre, on=merge_key2, how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del std1_pre, std2_pre\n",
    "\n",
    "# ベース値（Std2優先 → なければ Std1）\n",
    "rating_base = merged_df1['レイティング_stdtime2_new'].fillna(\n",
    "    merged_df1['レイティング_stdtime1_new']\n",
    ")\n",
    "speed_base = merged_df1['総合指数_stdtime2_new'].fillna(\n",
    "    merged_df1['総合指数_stdtime1_new']\n",
    ")\n",
    "strength_base = merged_df1['レース強度指数_stdtime2_new'].fillna(\n",
    "    merged_df1['レース強度指数_stdtime1_new']\n",
    ")\n",
    "\n",
    "# 差分（NaN は 0 扱い）\n",
    "rating_diff = (merged_df1['レイティング平均値'] - rating_base).fillna(0)\n",
    "speed_diff  = (merged_df1['Top3総合指数'] - speed_base).fillna(0)\n",
    "strength_diff = (merged_df1['レース強度指数'] - strength_base).fillna(0)\n",
    "\n",
    "# レースレベル指数\n",
    "merged_df1['レースレベル指数'] = (rating_diff + speed_diff + strength_diff + 100).round(1)\n",
    "\n",
    "#---ステップ５：各指数の差分を成績データへ追加\n",
    "# Top3総合指数と総合指数の差分を成績データへ追加\n",
    "merged_df1['Top3総合指数差分'] = merged_df1['総合指数'] - merged_df1['Top3総合指数']\n",
    "\n",
    "# レイティング平均値とレイティングの差分を追加\n",
    "merged_df1['平均レイティング差分'] = merged_df1['レイティング'] - merged_df1['レイティング平均値']\n",
    "\n",
    "# レース強度指数：基準タイム１差分\n",
    "merged_df1['レース強度指数上位差分']=merged_df1['レース強度指数']-merged_df1['レース強度指数_stdtime1_new'].fillna(merged_df1['レース強度指数_stdtime2_new'])\n",
    "\n",
    "# PCI3：基準タイム１差分\n",
    "merged_df1['PCI3差分']=merged_df1['PCI3']-merged_df1['PCI3_stdtime1_new'].fillna(merged_df1['PCI3_stdtime2_new'])\n",
    "\n",
    "# PCI：基準タイム１差分\n",
    "merged_df1['PCI上位差分']=merged_df1['PCI']-merged_df1['PCI_stdtime1_new'].fillna(merged_df1['PCI_stdtime2_new'])\n",
    "merged_df1['PCI勝馬差分']=merged_df1['PCI']-merged_df1['PCI_1着_stdtime1_new'].fillna(merged_df1['PCI_1着_stdtime2_new'])\n",
    "\n",
    "# 生後日数：基準タイム２差分\n",
    "merged_df1['生後日数上位差分']=merged_df1['生後日数']-merged_df1['生後日数_stdtime2_new'].fillna(merged_df1['生後日数_stdtime1_new'])\n",
    "merged_df1['生後日数勝馬差分']=merged_df1['生後日数']-merged_df1['生後日数_1着_stdtime2_new'].fillna(merged_df1['生後日数_1着_stdtime1_new'])\n",
    "\n",
    "# 馬体重：基準タイム２差分\n",
    "merged_df1['体重上位差分']=merged_df1['体重']-merged_df1['体重_stdtime2_new'].fillna(merged_df1['体重_stdtime1_new'])\n",
    "merged_df1['体重勝馬差分']=merged_df1['体重']-merged_df1['体重_1着_stdtime2_new'].fillna(merged_df1['体重_1着_stdtime1_new'])\n",
    "\n",
    "# 馬体重斤量比：基準タイム２差分\n",
    "merged_df1['斤量馬体重比上位差分']=merged_df1['斤量馬体重比']-merged_df1['斤量馬体重比_stdtime2_new'].fillna(merged_df1['斤量馬体重比_stdtime1_new'])\n",
    "merged_df1['斤量馬体重比勝馬差分']=merged_df1['斤量馬体重比']-merged_df1['斤量馬体重比_1着_stdtime2_new'].fillna(merged_df1['斤量馬体重比_1着_stdtime1_new'])\n",
    "\n",
    "# 前走距離：基準タイム１差分\n",
    "merged_df1['前走距離上位差分']=merged_df1['前走距離']-merged_df1['前走距離_stdtime1_new'].fillna(merged_df1['前走距離_stdtime2_new'])\n",
    "merged_df1['前走距離勝馬差分']=merged_df1['前走距離']-merged_df1['前走距離_1着_stdtime1_new'].fillna(merged_df1['前走距離_1着_stdtime2_new'])\n",
    "\n",
    "# 前走距離差：基準タイム１差分\n",
    "merged_df1['前走距離差上位差分']=merged_df1['前走距離差']-merged_df1['前走距離差_stdtime1_new'].fillna(merged_df1['前走距離差_stdtime2_new'])\n",
    "merged_df1['前走距離差勝馬差分']=merged_df1['前走距離差']-merged_df1['前走距離差_1着_stdtime1_new'].fillna(merged_df1['前走距離差_1着_stdtime2_new'])\n",
    "\n",
    "# レイティング：基準タイム１差分\n",
    "merged_df1['レイティング上位差分']=merged_df1['レイティング']-merged_df1['レイティング_stdtime1_new'].fillna(merged_df1['レイティング_stdtime2_new'])\n",
    "merged_df1['レイティング勝馬差分']=merged_df1['レイティング']-merged_df1['レイティング_1着_stdtime1_new'].fillna(merged_df1['レイティング_1着_stdtime2_new'])\n",
    "\n",
    "# レイティング偏差値：基準タイム１差分\n",
    "merged_df1['レイティング偏差値上位差分']=merged_df1['レイティング偏差値']-merged_df1['レイティング偏差値_stdtime1_new'].fillna(merged_df1['レイティング偏差値_stdtime2_new'])\n",
    "merged_df1['レイティング偏差値勝馬差分']=merged_df1['レイティング偏差値']-merged_df1['レイティング偏差値_1着_stdtime1_new'].fillna(merged_df1['レイティング偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# レイティング順位分布：基準タイム１差分\n",
    "merged_df1['レイティング順位分布上位差分']=merged_df1['レイティング順位分布']-merged_df1['レイティング順位分布_stdtime1_new'].fillna(merged_df1['レイティング順位分布_stdtime2_new'])\n",
    "merged_df1['レイティング順位分布勝馬差分']=merged_df1['レイティング順位分布']-merged_df1['レイティング順位分布_1着_stdtime1_new'].fillna(merged_df1['レイティング順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# ZI指数：基準タイム１差分\n",
    "merged_df1['ZI指数上位差分']=merged_df1['ZI指数']-merged_df1['ZI指数_stdtime1_new'].fillna(merged_df1['ZI指数_stdtime2_new'])\n",
    "merged_df1['ZI指数勝馬差分']=merged_df1['ZI指数']-merged_df1['ZI指数_1着_stdtime1_new'].fillna(merged_df1['ZI指数_1着_stdtime2_new'])\n",
    "\n",
    "# ZI指数偏差値：基準タイム１差分\n",
    "merged_df1['ZI指数偏差値上位差分']=merged_df1['ZI指数偏差値']-merged_df1['ZI指数偏差値_stdtime1_new'].fillna(merged_df1['ZI指数偏差値_stdtime2_new'])\n",
    "merged_df1['ZI指数偏差値勝馬差分']=merged_df1['ZI指数偏差値']-merged_df1['ZI指数偏差値_1着_stdtime1_new'].fillna(merged_df1['ZI指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# ZI指数順位分布：基準タイム１差分\n",
    "merged_df1['ZI指数順位分布上位差分']=merged_df1['ZI指数順位分布']-merged_df1['ZI指数順位分布_stdtime1_new'].fillna(merged_df1['ZI指数順位分布_stdtime2_new'])\n",
    "merged_df1['ZI指数順位分布勝馬差分']=merged_df1['ZI指数順位分布']-merged_df1['ZI指数順位分布_1着_stdtime1_new'].fillna(merged_df1['ZI指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 追切指数：基準タイム１差分\n",
    "merged_df1['追切指数上位差分']=merged_df1['追切指数']-merged_df1['追切指数_stdtime1_new'].fillna(merged_df1['追切指数_stdtime2_new'])\n",
    "merged_df1['追切指数勝馬差分']=merged_df1['追切指数']-merged_df1['追切指数_1着_stdtime1_new'].fillna(merged_df1['追切指数_1着_stdtime2_new'])\n",
    "\n",
    "# 追切指数偏差値：基準タイム１差分\n",
    "merged_df1['追切指数偏差値上位差分']=merged_df1['追切指数偏差値']-merged_df1['追切指数偏差値_stdtime1_new'].fillna(merged_df1['追切指数偏差値_stdtime2_new'])\n",
    "merged_df1['追切指数偏差値勝馬差分']=merged_df1['追切指数偏差値']-merged_df1['追切指数偏差値_1着_stdtime1_new'].fillna(merged_df1['追切指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 追切指数順位分布：基準タイム１差分\n",
    "merged_df1['追切指数順位分布上位差分']=merged_df1['追切指数順位分布']-merged_df1['追切指数順位分布_stdtime1_new'].fillna(merged_df1['追切指数順位分布_stdtime2_new'])\n",
    "merged_df1['追切指数順位分布勝馬差分']=merged_df1['追切指数順位分布']-merged_df1['追切指数順位分布_1着_stdtime1_new'].fillna(merged_df1['追切指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# マイニング：基準タイム１差分\n",
    "merged_df1['マイニング上位差分']=merged_df1['マイニング']-merged_df1['マイニング_stdtime1_new'].fillna(merged_df1['マイニング_stdtime2_new'])\n",
    "merged_df1['マイニング勝馬差分']=merged_df1['マイニング']-merged_df1['マイニング_1着_stdtime1_new'].fillna(merged_df1['マイニング_1着_stdtime2_new'])\n",
    "\n",
    "# マイニング偏差値：基準タイム１差分\n",
    "merged_df1['マイニング偏差値上位差分']=merged_df1['マイニング偏差値']-merged_df1['マイニング偏差値_stdtime1_new'].fillna(merged_df1['マイニング偏差値_stdtime2_new'])\n",
    "merged_df1['マイニング偏差値勝馬差分']=merged_df1['マイニング偏差値']-merged_df1['マイニング偏差値_1着_stdtime1_new'].fillna(merged_df1['マイニング偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# マイニング順位分布：基準タイム１差分\n",
    "merged_df1['マイニング順位分布上位差分']=merged_df1['マイニング順位分布']-merged_df1['マイニング順位分布_stdtime1_new'].fillna(merged_df1['マイニング順位分布_stdtime2_new'])\n",
    "merged_df1['マイニング順位分布勝馬差分']=merged_df1['マイニング順位分布']-merged_df1['マイニング順位分布_1着_stdtime1_new'].fillna(merged_df1['マイニング順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 対戦型マイニング：基準タイム１差分\n",
    "merged_df1['対戦型マイニング上位差分']=merged_df1['対戦型マイニング']-merged_df1['対戦型マイニング_stdtime1_new'].fillna(merged_df1['対戦型マイニング_stdtime2_new'])\n",
    "merged_df1['対戦型マイニング勝馬差分']=merged_df1['対戦型マイニング']-merged_df1['対戦型マイニング_1着_stdtime1_new'].fillna(merged_df1['対戦型マイニング_1着_stdtime2_new'])\n",
    "\n",
    "# 対戦型マイニング偏差値：基準タイム１差分\n",
    "merged_df1['対戦型マイニング偏差値上位差分']=merged_df1['対戦型マイニング偏差値']-merged_df1['対戦型マイニング偏差値_stdtime1_new'].fillna(merged_df1['対戦型マイニング偏差値_stdtime2_new'])\n",
    "merged_df1['対戦型マイニング偏差値勝馬差分']=merged_df1['対戦型マイニング偏差値']-merged_df1['対戦型マイニング偏差値_1着_stdtime1_new'].fillna(merged_df1['対戦型マイニング偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 対戦型マイニング順位分布：基準タイム１差分\n",
    "merged_df1['対戦型マイニング順位分布上位差分']=merged_df1['対戦型マイニング順位分布']-merged_df1['対戦型マイニング順位分布_stdtime1_new'].fillna(merged_df1['対戦型マイニング順位分布_stdtime2_new'])\n",
    "merged_df1['対戦型マイニング順位分布勝馬差分']=merged_df1['対戦型マイニング順位分布']-merged_df1['対戦型マイニング順位分布_1着_stdtime1_new'].fillna(merged_df1['対戦型マイニング順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# タイムS：基準タイム１差分\n",
    "merged_df1['タイムS上位差分']=merged_df1['タイムS']-merged_df1['タイムS_stdtime1_new'].fillna(merged_df1['タイムS_stdtime2_new'])\n",
    "merged_df1['タイムS勝馬差分']=merged_df1['タイムS']-merged_df1['タイムS_1着_stdtime1_new'].fillna(merged_df1['タイムS_1着_stdtime2_new'])\n",
    "\n",
    "# 補正走破タイム：基準タイム１差分\n",
    "merged_df1['補正走破タイム上位差分']=merged_df1['補正走破タイム']-merged_df1['補正走破タイム_stdtime1_new'].fillna(merged_df1['補正走破タイム_stdtime2_new'])\n",
    "merged_df1['補正走破タイム勝馬差分']=merged_df1['補正走破タイム']-merged_df1['補正走破タイム_1着_stdtime1_new'].fillna(merged_df1['補正走破タイム_1着_stdtime2_new'])\n",
    "\n",
    "# -3Fタイム：基準タイム１差分\n",
    "merged_df1['-3Fタイム上位差分']=merged_df1['-3Fタイム']-merged_df1['-3Fタイム_stdtime1_new'].fillna(merged_df1['-3Fタイム_stdtime2_new'])\n",
    "merged_df1['-3Fタイム勝馬差分']=merged_df1['-3Fタイム']-merged_df1['-3Fタイム_1着_stdtime1_new'].fillna(merged_df1['-3Fタイム_1着_stdtime2_new'])\n",
    "\n",
    "# 前半3F：基準タイム１差分\n",
    "merged_df1['前半3F上位差分']=merged_df1['前半3F']-merged_df1['前半3F_stdtime1_new'].fillna(merged_df1['前半3F_stdtime2_new'])\n",
    "merged_df1['前半3F勝馬差分']=merged_df1['前半3F']-merged_df1['前半3F_1着_stdtime1_new'].fillna(merged_df1['前半3F_1着_stdtime2_new'])\n",
    "\n",
    "# 前半3F偏差値：基準タイム１差分\n",
    "merged_df1['前半3F偏差値上位差分']=merged_df1['前半3F偏差値']-merged_df1['前半3F偏差値_stdtime1_new'].fillna(merged_df1['前半3F偏差値_stdtime2_new'])\n",
    "merged_df1['前半3F偏差値勝馬差分']=merged_df1['前半3F偏差値']-merged_df1['前半3F偏差値_1着_stdtime1_new'].fillna(merged_df1['前半3F偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 前半3F順位：基準タイム１差分\n",
    "merged_df1['前半3F順位上位差分']=merged_df1['前半3F順位']-merged_df1['前半3F順位_stdtime1_new'].fillna(merged_df1['前半3F順位_stdtime2_new'])\n",
    "merged_df1['前半3F順位勝馬差分']=merged_df1['前半3F順位']-merged_df1['前半3F順位_1着_stdtime1_new'].fillna(merged_df1['前半3F順位_1着_stdtime2_new'])\n",
    "\n",
    "# 前半3F順位分布：基準タイム１差分\n",
    "merged_df1['前半3F順位分布上位差分']=merged_df1['前半3F順位分布']-merged_df1['前半3F順位分布_stdtime1_new'].fillna(merged_df1['前半3F順位分布_stdtime2_new'])\n",
    "merged_df1['前半3F順位分布勝馬差分']=merged_df1['前半3F順位分布']-merged_df1['前半3F順位分布_1着_stdtime1_new'].fillna(merged_df1['前半3F順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 上り3F：基準タイム１差分\n",
    "merged_df1['上り3F上位差分']=merged_df1['上り3F']-merged_df1['上り3F_stdtime1_new'].fillna(merged_df1['上り3F_stdtime2_new'])\n",
    "merged_df1['上り3F勝馬差分']=merged_df1['上り3F']-merged_df1['上り3F_1着_stdtime1_new'].fillna(merged_df1['上り3F_1着_stdtime2_new'])\n",
    "\n",
    "# 上り3F偏差値：基準タイム１差分\n",
    "merged_df1['上り3F偏差値上位差分']=merged_df1['上り3F偏差値']-merged_df1['上り3F偏差値_stdtime1_new'].fillna(merged_df1['上り3F偏差値_stdtime2_new'])\n",
    "merged_df1['上り3F偏差値勝馬差分']=merged_df1['上り3F偏差値']-merged_df1['上り3F偏差値_1着_stdtime1_new'].fillna(merged_df1['上り3F偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 上り3F順位：基準タイム１差分\n",
    "merged_df1['上り3F順位上位差分']=merged_df1['上り3F順位']-merged_df1['上り3F順位_stdtime1_new'].fillna(merged_df1['上り3F順位_stdtime2_new'])\n",
    "merged_df1['上り3F順位勝馬差分']=merged_df1['上り3F順位']-merged_df1['上り3F順位_1着_stdtime1_new'].fillna(merged_df1['上り3F順位_1着_stdtime2_new'])\n",
    "\n",
    "# 上り3F順位分布：基準タイム１差分\n",
    "merged_df1['上り3F順位分布上位差分']=merged_df1['上り3F順位分布']-merged_df1['上り3F順位分布_stdtime1_new'].fillna(merged_df1['上り3F順位分布_stdtime2_new'])\n",
    "merged_df1['上り3F順位分布勝馬差分']=merged_df1['上り3F順位分布']-merged_df1['上り3F順位分布_1着_stdtime1_new'].fillna(merged_df1['上り3F順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# Ave-3F：基準タイム１差分\n",
    "merged_df1['Ave-3F上位差分']=merged_df1['Ave-3F']-merged_df1['Ave-3F_stdtime1_new'].fillna(merged_df1['Ave-3F_stdtime2_new'])\n",
    "merged_df1['Ave-3F勝馬差分']=merged_df1['Ave-3F']-merged_df1['Ave-3F_1着_stdtime1_new'].fillna(merged_df1['Ave-3F_1着_stdtime2_new'])\n",
    "\n",
    "# Ave-3F偏差値：基準タイム１差分\n",
    "merged_df1['Ave-3F偏差値上位差分']=merged_df1['Ave-3F偏差値']-merged_df1['Ave-3F偏差値_stdtime1_new'].fillna(merged_df1['Ave-3F偏差値_stdtime2_new'])\n",
    "merged_df1['Ave-3F偏差値勝馬差分']=merged_df1['Ave-3F偏差値']-merged_df1['Ave-3F偏差値_1着_stdtime1_new'].fillna(merged_df1['Ave-3F偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# Ave-3F順位：基準タイム１差分\n",
    "merged_df1['Ave-3F順位上位差分']=merged_df1['Ave-3F順位']-merged_df1['Ave-3F順位_stdtime1_new'].fillna(merged_df1['Ave-3F順位_stdtime2_new'])\n",
    "merged_df1['Ave-3F順位勝馬差分']=merged_df1['Ave-3F順位']-merged_df1['Ave-3F順位_1着_stdtime1_new'].fillna(merged_df1['Ave-3F順位_1着_stdtime2_new'])\n",
    "\n",
    "# Ave-3F順位分布：基準タイム１差分\n",
    "merged_df1['Ave-3F順位分布上位差分']=merged_df1['Ave-3F順位分布']-merged_df1['Ave-3F順位分布_stdtime1_new'].fillna(merged_df1['Ave-3F順位分布_stdtime2_new'])\n",
    "merged_df1['Ave-3F順位分布勝馬差分']=merged_df1['Ave-3F順位分布']-merged_df1['Ave-3F順位分布_1着_stdtime1_new'].fillna(merged_df1['Ave-3F順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# -3F差：基準タイム１差分\n",
    "merged_df1['-3F差上位差分']=merged_df1['-3F差']-merged_df1['-3F差_stdtime1_new'].fillna(merged_df1['-3F差_stdtime2_new'])\n",
    "merged_df1['-3F差勝馬差分']=merged_df1['-3F差']-merged_df1['-3F差_1着_stdtime1_new'].fillna(merged_df1['-3F差_1着_stdtime2_new'])\n",
    "\n",
    "# テン指数：基準タイム１差分\n",
    "merged_df1['テン指数上位差分']=merged_df1['テン指数']-merged_df1['テン指数_stdtime1_new'].fillna(merged_df1['テン指数_stdtime2_new'])\n",
    "merged_df1['テン指数勝馬差分']=merged_df1['テン指数']-merged_df1['テン指数_1着_stdtime1_new'].fillna(merged_df1['テン指数_1着_stdtime2_new'])\n",
    "\n",
    "# テン指数偏差値：基準タイム１差分\n",
    "merged_df1['テン指数偏差値上位差分']=merged_df1['テン指数偏差値']-merged_df1['テン指数偏差値_stdtime1_new'].fillna(merged_df1['テン指数偏差値_stdtime2_new'])\n",
    "merged_df1['テン指数偏差値勝馬差分']=merged_df1['テン指数偏差値']-merged_df1['テン指数偏差値_1着_stdtime1_new'].fillna(merged_df1['テン指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# テン指数順位：基準タイム１差分\n",
    "merged_df1['テン指数順位上位差分']=merged_df1['テン指数順位']-merged_df1['テン指数順位_stdtime1_new'].fillna(merged_df1['テン指数順位_stdtime2_new'])\n",
    "merged_df1['テン指数順位勝馬差分']=merged_df1['テン指数順位']-merged_df1['テン指数順位_1着_stdtime1_new'].fillna(merged_df1['テン指数順位_1着_stdtime2_new'])\n",
    "\n",
    "# テン指数順位分布：基準タイム１差分\n",
    "merged_df1['テン指数順位分布上位差分']=merged_df1['テン指数順位分布']-merged_df1['テン指数順位分布_stdtime1_new'].fillna(merged_df1['テン指数順位分布_stdtime2_new'])\n",
    "merged_df1['テン指数順位分布勝馬差分']=merged_df1['テン指数順位分布']-merged_df1['テン指数順位分布_1着_stdtime1_new'].fillna(merged_df1['テン指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 上り指数：基準タイム１差分\n",
    "merged_df1['上り指数上位差分']=merged_df1['上り指数']-merged_df1['上り指数_stdtime1_new'].fillna(merged_df1['上り指数_stdtime2_new'])\n",
    "merged_df1['上り指数勝馬差分']=merged_df1['上り指数']-merged_df1['上り指数_1着_stdtime1_new'].fillna(merged_df1['上り指数_1着_stdtime2_new'])\n",
    "\n",
    "# 上り指数偏差値：基準タイム１差分\n",
    "merged_df1['上り指数偏差値上位差分']=merged_df1['上り指数偏差値']-merged_df1['上り指数偏差値_stdtime1_new'].fillna(merged_df1['上り指数偏差値_stdtime2_new'])\n",
    "merged_df1['上り指数偏差値勝馬差分']=merged_df1['上り指数偏差値']-merged_df1['上り指数偏差値_1着_stdtime1_new'].fillna(merged_df1['上り指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 上り指数順位：基準タイム１差分\n",
    "merged_df1['上り指数順位上位差分']=merged_df1['上り指数順位']-merged_df1['上り指数順位_stdtime1_new'].fillna(merged_df1['上り指数順位_stdtime2_new'])\n",
    "merged_df1['上り指数順位勝馬差分']=merged_df1['上り指数順位']-merged_df1['上り指数順位_1着_stdtime1_new'].fillna(merged_df1['上り指数順位_1着_stdtime2_new'])\n",
    "\n",
    "# 上り指数順位分布：基準タイム１差分\n",
    "merged_df1['上り指数順位分布上位差分']=merged_df1['上り指数順位分布']-merged_df1['上り指数順位分布_stdtime1_new'].fillna(merged_df1['上り指数順位分布_stdtime2_new'])\n",
    "merged_df1['上り指数順位分布勝馬差分']=merged_df1['上り指数順位分布']-merged_df1['上り指数順位分布_1着_stdtime1_new'].fillna(merged_df1['上り指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# スピード指数：基準タイム１差分\n",
    "merged_df1['スピード指数上位差分']=merged_df1['スピード指数']-merged_df1['スピード指数_stdtime1_new'].fillna(merged_df1['スピード指数_stdtime2_new'])\n",
    "merged_df1['スピード指数勝馬差分']=merged_df1['スピード指数']-merged_df1['スピード指数_1着_stdtime1_new'].fillna(merged_df1['スピード指数_1着_stdtime2_new'])\n",
    "\n",
    "# スピード指数偏差値：基準タイム１差分\n",
    "merged_df1['スピード指数偏差値上位差分']=merged_df1['スピード指数偏差値']-merged_df1['スピード指数偏差値_stdtime1_new'].fillna(merged_df1['スピード指数偏差値_stdtime2_new'])\n",
    "merged_df1['スピード指数偏差値勝馬差分']=merged_df1['スピード指数偏差値']-merged_df1['スピード指数偏差値_1着_stdtime1_new'].fillna(merged_df1['スピード指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# スピード指数順位：基準タイム１差分\n",
    "merged_df1['スピード指数順位上位差分']=merged_df1['スピード指数順位']-merged_df1['スピード指数順位_stdtime1_new'].fillna(merged_df1['スピード指数順位_stdtime2_new'])\n",
    "merged_df1['スピード指数順位勝馬差分']=merged_df1['スピード指数順位']-merged_df1['スピード指数順位_1着_stdtime1_new'].fillna(merged_df1['スピード指数順位_1着_stdtime2_new'])\n",
    "\n",
    "# スピード指数順位分布：基準タイム１差分\n",
    "merged_df1['スピード指数順位分布上位差分']=merged_df1['スピード指数順位分布']-merged_df1['スピード指数順位分布_stdtime1_new'].fillna(merged_df1['スピード指数順位分布_stdtime2_new'])\n",
    "merged_df1['スピード指数順位分布勝馬差分']=merged_df1['スピード指数順位分布']-merged_df1['スピード指数順位分布_1着_stdtime1_new'].fillna(merged_df1['スピード指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 総合指数：基準タイム１差分\n",
    "merged_df1['総合指数上位差分']=merged_df1['総合指数']-merged_df1['総合指数_stdtime1_new'].fillna(merged_df1['総合指数_stdtime2_new'])\n",
    "merged_df1['総合指数勝馬差分']=merged_df1['総合指数']-merged_df1['総合指数_1着_stdtime1_new'].fillna(merged_df1['総合指数_1着_stdtime2_new'])\n",
    "\n",
    "# 総合指数偏差値：基準タイム１差分\n",
    "merged_df1['総合指数偏差値上位差分']=merged_df1['総合指数偏差値']-merged_df1['総合指数偏差値_stdtime1_new'].fillna(merged_df1['総合指数偏差値_stdtime2_new'])\n",
    "merged_df1['総合指数偏差値勝馬差分']=merged_df1['総合指数偏差値']-merged_df1['総合指数偏差値_1着_stdtime1_new'].fillna(merged_df1['総合指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 総合指数順位：基準タイム１差分\n",
    "merged_df1['総合指数順位上位差分']=merged_df1['総合指数順位']-merged_df1['総合指数順位_stdtime1_new'].fillna(merged_df1['総合指数順位_stdtime2_new'])\n",
    "merged_df1['総合指数順位勝馬差分']=merged_df1['総合指数順位']-merged_df1['総合指数順位_1着_stdtime1_new'].fillna(merged_df1['総合指数順位_1着_stdtime2_new'])\n",
    "\n",
    "# 総合指数順位分布：基準タイム１差分\n",
    "merged_df1['総合指数順位分布上位差分']=merged_df1['総合指数順位分布']-merged_df1['総合指数順位分布_stdtime1_new'].fillna(merged_df1['総合指数順位分布_stdtime2_new'])\n",
    "merged_df1['総合指数順位分布勝馬差分']=merged_df1['総合指数順位分布']-merged_df1['総合指数順位分布_1着_stdtime1_new'].fillna(merged_df1['総合指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# PCI：基準タイム１差分\n",
    "merged_df1['PCI上位差分']=merged_df1['PCI']-merged_df1['PCI_stdtime1_new'].fillna(merged_df1['PCI_stdtime2_new'])\n",
    "merged_df1['PCI勝馬差分']=merged_df1['PCI']-merged_df1['PCI_1着_stdtime1_new'].fillna(merged_df1['PCI_1着_stdtime2_new'])\n",
    "\n",
    "# 初角_4角差：基準タイム１差分\n",
    "merged_df1['初角_4角差上位差分']=merged_df1['初角_4角差']-merged_df1['初角_4角差_stdtime1_new'].fillna(merged_df1['初角_4角差_stdtime2_new'])\n",
    "merged_df1['初角_4角差勝馬差分']=merged_df1['初角_4角差']-merged_df1['初角_4角差_1着_stdtime1_new'].fillna(merged_df1['初角_4角差_1着_stdtime2_new'])\n",
    "\n",
    "# 4角_入線順位差：基準タイム１差分\n",
    "merged_df1['4角_入線順位差上位差分']=merged_df1['4角_入線順位差']-merged_df1['4角_入線順位差_stdtime1_new'].fillna(merged_df1['4角_入線順位差_stdtime2_new'])\n",
    "merged_df1['4角_入線順位差勝馬差分']=merged_df1['4角_入線順位差']-merged_df1['4角_入線順位差_1着_stdtime1_new'].fillna(merged_df1['4角_入線順位差_1着_stdtime2_new'])\n",
    "\n",
    "#---ステップ６：レースレベル基準の作成\n",
    "# グループ化キー\n",
    "group_cols3 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類']\n",
    "\n",
    "# --- 基準レースレベル算出処理 ---\n",
    "racelevel_df = (\n",
    "    merged_df1\n",
    "      .dropna(subset=['レースレベル指数'])  # 欠損を除外\n",
    "      .groupby(group_cols3, dropna=False)['レースレベル指数']\n",
    "      .agg(['mean', 'std'])  # mean と std を同時に集計\n",
    "      .reset_index()\n",
    ").copy()\n",
    "\n",
    "# 近似Zスコア用の基準値を計算\n",
    "racelevel_df['RL±0'] = racelevel_df['mean'].round(2)\n",
    "racelevel_df['RL+1'] = (racelevel_df['mean'] + racelevel_df['std']).round(2)\n",
    "racelevel_df['RL-1'] = (racelevel_df['mean'] - racelevel_df['std']).round(2)\n",
    "racelevel_df['RL+2'] = (racelevel_df['mean'] + 2 * racelevel_df['std']).round(2)\n",
    "racelevel_df['RL-2'] = (racelevel_df['mean'] - 2 * racelevel_df['std']).round(2)\n",
    "\n",
    "# 必要なカラムだけ残す\n",
    "racelevel_df = racelevel_df[\n",
    "    group_cols3 + ['RL-2','RL-1','RL±0','RL+1','RL+2','mean','std']\n",
    "].copy()\n",
    "\n",
    "#---ステップ７：レースレベル判定\n",
    "# レースレベル基準のデータフレームにサフィックスを付ける\n",
    "merged_df2 = prepare_ref_df(racelevel_df, group_cols3, '_racelevel')\n",
    "\n",
    "merged_df1 = pd.merge(merged_df1, merged_df2, on=group_cols3, how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del merged_df2\n",
    "\n",
    "# 差分\n",
    "rl_m2 = (merged_df1['レースレベル指数'] - merged_df1['RL-2_racelevel']).abs()\n",
    "rl_m1 = (merged_df1['レースレベル指数'] - merged_df1['RL-1_racelevel']).abs()\n",
    "rl_0  = (merged_df1['レースレベル指数'] - merged_df1['RL±0_racelevel']).abs()\n",
    "rl_p1 = (merged_df1['レースレベル指数'] - merged_df1['RL+1_racelevel']).abs()\n",
    "rl_p2 = (merged_df1['レースレベル指数'] - merged_df1['RL+2_racelevel']).abs()\n",
    "\n",
    "# 5本を横に並べて「最小の列名」を取る（行ごと）\n",
    "diff_df = pd.concat([rl_m2, rl_m1, rl_0, rl_p1, rl_p2], axis=1)\n",
    "diff_df.columns = [-2, -1, 0, 1, 2]  # そのまま判定値にする\n",
    "\n",
    "# 「基準が無い行」判定（5本すべてNaN）\n",
    "no_ref = diff_df.isna().all(axis=1)\n",
    "\n",
    "# idxminを安定させるため NaN は無限大扱いにして最小を取る\n",
    "band = diff_df.fillna(np.inf).idxmin(axis=1)\n",
    "\n",
    "# レースレベル判定 列を追加\n",
    "insert_pos = merged_df1.columns.get_loc('レースレベル指数') + 1\n",
    "merged_df1.insert(insert_pos, 'レースレベル判定', band.where(~no_ref, np.nan).astype('Int64'))\n",
    "\n",
    "# レースレベル評価 列を追加\n",
    "band_to_grade = {2: 'A', 1: 'B', 0: 'C', -1: 'D', -2: 'E'}\n",
    "insert_pos = merged_df1.columns.get_loc('レースレベル判定') + 1\n",
    "merged_df1.insert(insert_pos, 'レースレベル評価', merged_df1['レースレベル判定'].map(band_to_grade))\n",
    "\n",
    "# レース印３ 列を追加\n",
    "rank_to_label = {'A': '05A', 'B': '07B', 'C': '01C', 'D': '00D', 'E': '03E'}\n",
    "merged_df1['レース印３'] = merged_df1['レースレベル評価'].replace(rank_to_label)\n",
    "\n",
    "# サフィックス付き列を削除\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_stdtime1_new','_stdtime2_new', '_racelevel')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "merged_df1 = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "#---ステップ８：馬の持久力/瞬発力タイプ判定\n",
    "# merged_df1 をコピーして、1着～3着だけにする\n",
    "group_cols4 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)','馬場分類']\n",
    "\n",
    "horsetype_df = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "\n",
    "horsetype_df= horsetype_df[['target_raceid', '血統登録番号','PCI3', 'PCI'] + group_cols4].copy()\n",
    "\n",
    "# 基準タイムファイル１から基準PCI3を取ってマージ\n",
    "std1_df = base_time_df1[group_cols4 + ['PCI3']].copy()\n",
    "std1_df = std1_df.rename(columns={'PCI3': 'PCI3_stdtime1'})\n",
    "\n",
    "horsetype_df = pd.merge(horsetype_df, std1_df, on=group_cols4, how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del std1_df\n",
    "\n",
    "# レース性質（基準比）と、馬のレース内差分を合算\n",
    "horsetype_df['基準PCI3差分'] = horsetype_df['PCI3'] - horsetype_df['PCI3_stdtime1']\n",
    "horsetype_df['レースPCI3差分'] = horsetype_df['PCI'] - horsetype_df['PCI3']\n",
    "horsetype_df['PCI判定スコア'] = horsetype_df['基準PCI3差分'] + horsetype_df['レースPCI3差分']\n",
    "\n",
    "# 馬ごとに PCI3差分 の中央値を取る\n",
    "horsetype_df = horsetype_df.groupby('血統登録番号', as_index=False)['PCI判定スコア'].median()\n",
    "\n",
    "# 'Ｃ' 列を追加して判定（マイナス=持、プラス=瞬）\n",
    "horsetype_df['Ｃ'] = ''\n",
    "horsetype_df.loc[horsetype_df['PCI判定スコア'] < 0, 'Ｃ'] = '0'\n",
    "horsetype_df.loc[horsetype_df['PCI判定スコア'] > 0, 'Ｃ'] = '1'\n",
    "\n",
    "# 成績データへ馬タイプを代入する\n",
    "c_map = horsetype_df.set_index('血統登録番号')['Ｃ']\n",
    "merged_df1['Ｃ'] = merged_df1['血統登録番号'].map(c_map)\n",
    "\n",
    "# 今日の日付を yymmdd で作る\n",
    "today_yymmdd = datetime.now().strftime(\"%y%m%d\")\n",
    "\n",
    "# 判定済み horsetype_df（= 血統登録番号 + Ｃ）に馬名を付ける\n",
    "horse_name_df = (\n",
    "    merged_df1[['血統登録番号', '馬名']]\n",
    "    .dropna(subset=['馬名'])\n",
    "    .drop_duplicates(subset=['血統登録番号'], keep='last')\n",
    ")\n",
    "\n",
    "checkhorse_df = pd.merge(horsetype_df, horse_name_df, on='血統登録番号', how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del horsetype_df\n",
    "del horse_name_df\n",
    "\n",
    "# ★「0/1が入った馬だけ」出力（中央値0や判定不能は除外）\n",
    "checkhorse_df = checkhorse_df[checkhorse_df['Ｃ'].isin(['0', '1'])].copy()\n",
    "\n",
    "# TARGET仕様の列名に変換\n",
    "checkhorse_df = checkhorse_df.rename(columns={'Ｃ': 'タイプ'})\n",
    "\n",
    "# 登録日\n",
    "checkhorse_df['登録日'] = today_yymmdd\n",
    "\n",
    "# 血統登録番号の整形（UX～なら zfill しない方が安全）\n",
    "checkhorse_df['血統登録番号'] = checkhorse_df['血統登録番号'].astype(str).str.strip()\n",
    "\n",
    "# 列順\n",
    "checkhorse_df = checkhorse_df[['馬名', 'タイプ', '登録日', '血統登録番号']]\n",
    "\n",
    "#---ステップ９：csvファイル保存\n",
    "# 成績データの列の並び替え\n",
    "header_df = pd.read_csv(header_filepath, header = None, encoding='cp932')\n",
    "column_list = header_df[0].tolist()\n",
    "merged_df1 = merged_df1[column_list]\n",
    "\n",
    "# csvファイル保存\n",
    "merged_df1.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "base_time_df1.to_csv(output_filepath2, index=False, encoding='cp932')\n",
    "base_time_df2.to_csv(output_filepath3, index=False, encoding='cp932')\n",
    "pace_medians_df.to_csv(output_filepath4, index=False, encoding='cp932')\n",
    "lap33_df.to_csv(output_filepath5, index=False, encoding='cp932')\n",
    "racelevel_df.to_csv(output_filepath6, index=False, encoding='cp932')\n",
    "checkhorse_df.to_csv(output_filepath7, index=False, encoding='cp932')\n",
    "\n",
    "# 各指数をインポート用ファイルに加工して保存\n",
    "# テン指数\n",
    "imp_df1 = merged_df1[['target_horseid','テン指数']]\n",
    "# 上り指数\n",
    "imp_df2 = merged_df1[['target_horseid','上り指数']]\n",
    "# スピード指数\n",
    "imp_df3 = merged_df1[['target_horseid','スピード指数']]\n",
    "# 総合指数\n",
    "imp_df4 = merged_df1[['target_horseid','総合指数']]\n",
    "# 33ラップ判定\n",
    "imp_df5 = merged_df1[['target_raceid','レース印２']].drop_duplicates('target_raceid')\n",
    "# レースレベル判定\n",
    "imp_df6 = merged_df1[['target_raceid','レース印３']].drop_duplicates('target_raceid')\n",
    "\n",
    "# 各指数のマスタをcsv保存\n",
    "imp_df1.to_csv(output_dir1 + 'First_Score_Master.csv', index=False, encoding='cp932')\n",
    "imp_df2.to_csv(output_dir2 + 'Spurt_Score_Master.csv', index=False, encoding='cp932')\n",
    "imp_df3.to_csv(output_dir3 + 'Speed_Score_Master.csv', index=False, encoding='cp932')\n",
    "imp_df4.to_csv(output_dir4 + 'Total_Score_Master.csv', index=False, encoding='cp932')\n",
    "imp_df5.to_csv(output_dir5 + '33Lap_Category_Master.csv', index=False, encoding='cp932')\n",
    "imp_df6.to_csv(output_dir6 + 'Race_Level_Master.csv', index=False, encoding='cp932')\n",
    "\n",
    "# 年度列を追加（target_raceid先頭4桁が年）\n",
    "imp_df1['year'] = pd.to_datetime(\n",
    "    imp_df1['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df2['year'] = pd.to_datetime(\n",
    "    imp_df2['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df3['year'] = pd.to_datetime(\n",
    "    imp_df3['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df4['year'] = pd.to_datetime(\n",
    "    imp_df4['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df5['year'] = pd.to_datetime(\n",
    "    imp_df5['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df6['year'] = pd.to_datetime(\n",
    "    imp_df6['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "# 年度別にファイル分割\n",
    "for year, df in imp_df1.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir1}First_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df2.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir2}Spurt_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df3.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir3}Speed_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df4.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir4}Total_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df5.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir5}33Lap_Category_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df6.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir6}Race_Level_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del merged_df1\n",
    "del base_time_df1\n",
    "del base_time_df2\n",
    "del pace_medians_df\n",
    "del lap33_df\n",
    "del racelevel_df\n",
    "del imp_df1\n",
    "del imp_df2\n",
    "del imp_df3\n",
    "del imp_df4\n",
    "del imp_df5\n",
    "del imp_df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追切指数を算出する\n",
    "## 2024年分の追切指数を2017~2023年分の基準データで算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\1771354911.py:43: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(master_filepath,  encoding='cp932').copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了：追切指数（MAD・ロバスト偏差値版）を出力しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "# =========================\n",
    "# 読み込みファイルパス\n",
    "# =========================\n",
    "master_filepath  = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original\\ResultData_2024.csv'\n",
    "\n",
    "# 基準ファイル\n",
    "p_course_median  = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course.csv'\n",
    "p_class_median   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_class.csv'\n",
    "p_course_top20   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course_top20.csv'\n",
    "p_course_top10   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course_top10.csv'\n",
    "\n",
    "# 出力\n",
    "output_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\Training_Score_Master.csv'\n",
    "output_dir       = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\\\'\n",
    "\n",
    "# =========================\n",
    "# ファイル選択\n",
    "# =========================\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "\n",
    "traning_filepath = filedialog.askopenfilename(\n",
    "    title=\"追切CSVファイルを選択してください\",\n",
    "    filetypes=[(\"CSV Files\", \"*.csv\")]\n",
    ")\n",
    "if not traning_filepath:\n",
    "    print(\"ファイルが選択されなかったため、処理を終了します。\")\n",
    "    raise SystemExit\n",
    "\n",
    "# =========================\n",
    "# 読み込み & 前処理\n",
    "# =========================\n",
    "df1 = pd.read_csv(traning_filepath, encoding='cp932').copy()\n",
    "df2 = pd.read_csv(master_filepath,  encoding='cp932').copy()\n",
    "\n",
    "def clean_training_data(df):\n",
    "    df = df.copy()\n",
    "    mask_invalid = df[\"日付\"].astype(str).str.contains(\"■|◇\", na=False)\n",
    "    df = df[~mask_invalid].copy()\n",
    "    check_cols = [c for c in ['8F','7F','6F','5F(4F)','4F(3F)','3F(2F)'] if c in df.columns]\n",
    "    for c in check_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    is_not_hill = ~df['コース'].astype(str).str.contains('坂', na=False)\n",
    "    has_10sec_like = np.column_stack([df[c].between(10.0, 19.9) for c in check_cols]).any(axis=1)\n",
    "    drop_mask = is_not_hill & has_10sec_like\n",
    "    df = df[~drop_mask].copy()\n",
    "    return df\n",
    "\n",
    "df1 = clean_training_data(df1)\n",
    "\n",
    "replace_map = {'南Ｗ': '美Ｗ', '南Ｄ': '美ダ', '南ダ': '美ダ', '南芝': '美芝'}\n",
    "df1['コース'] = df1['コース'].replace(replace_map)\n",
    "df1['馬場状態'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1[\"回り位置\"] = pd.to_numeric(df1[\"回り位置\"], errors=\"coerce\")\n",
    "\n",
    "distance_columns = [col for col in [\"8F\", \"7F\", \"6F\", \"5F(4F)\", \"4F(3F)\", \"3F(2F)\", \"1F\"] if col in df1.columns]\n",
    "for col in distance_columns:\n",
    "    df1[f\"{col}_補\"] = np.nan\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    if not pd.isna(row[\"回り位置\"]):\n",
    "        correction_value = (9 - row[\"回り位置\"]) * 0.1\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "            df1.at[index, f\"{leftmost_col}_補\"] = round(row[leftmost_col] + correction_value, 1)\n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        df1.at[index, f\"{col}_補\"] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                df1.at[index, f\"{col}_補\"] = row[col]\n",
    "\n",
    "time_columns = [f\"{c}_補\" for c in distance_columns]\n",
    "\n",
    "# =========================\n",
    "# 成績マージ\n",
    "# =========================\n",
    "# df2の列をリネームする\n",
    "# リネームする列名を定義\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid'\n",
    "}\n",
    "\n",
    "df2.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "merge_cols = ['target_horseid', 'トラックコード(JV)', '年齢限定(競走種別コード)', 'クラスコード']\n",
    "df2 = df2[merge_cols]\n",
    "\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11: return 'サラブレッド系2歳'\n",
    "    elif race_type == 12: return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13: return 'サラブレッド系3歳以上'\n",
    "    else: return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15: return '新馬・未勝利'\n",
    "    elif class_code == 23: return '1勝クラス'\n",
    "    elif class_code == 43: return '2勝クラス'\n",
    "    elif class_code == 67: return '3勝クラス'\n",
    "    elif class_code >= 114: return 'OP・重賞'\n",
    "    else: return np.nan\n",
    "\n",
    "df2['年齢限定(競走種別コード)'] = df2['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df2['クラスコード'] = df2['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "merged_df1 = pd.merge(df1, df2, on='target_horseid', how='inner').copy()\n",
    "merged_df1['is_saka'] = merged_df1['コース'].astype(str).str.contains('坂', na=False)\n",
    "\n",
    "# =========================\n",
    "# 基準テーブル読み込み（MAD対応）\n",
    "# =========================\n",
    "def load_and_tag(path, suffix, has_std):\n",
    "    t = pd.read_csv(path, encoding='cp932').copy()\n",
    "    rename_map = {}\n",
    "    for c in time_columns:\n",
    "        if c in t.columns:\n",
    "            rename_map[c] = f\"{c}_{suffix}\"\n",
    "        \n",
    "        # 標準偏差ではなくMADを探す\n",
    "        madc = f\"MAD_{c}\"\n",
    "        if has_std and (madc in t.columns):\n",
    "            rename_map[madc] = f\"MAD_{c}_{suffix}\"\n",
    "    return t.rename(columns=rename_map)\n",
    "\n",
    "df3 = load_and_tag(p_course_median, 'course', True)\n",
    "df4 = load_and_tag(p_class_median,  'class',  True)\n",
    "df5 = load_and_tag(p_course_top20, 'course_20', False)\n",
    "df6 = load_and_tag(p_course_top10, 'course_10', False)\n",
    "\n",
    "key_course = ['コース','馬場状態']\n",
    "key_class  = ['年齢限定(競走種別コード)','クラスコード','コース','馬場状態']\n",
    "\n",
    "def smerge(left, right, keys):\n",
    "    exist_keys = [k for k in keys if (k in left.columns and k in right.columns)]\n",
    "    return pd.merge(left, right, on=exist_keys, how='left')\n",
    "\n",
    "merged_df1 = smerge(merged_df1, df3, key_course)\n",
    "merged_df1 = smerge(merged_df1, df4, key_class)\n",
    "merged_df1 = smerge(merged_df1, df5, key_course)\n",
    "merged_df1 = smerge(merged_df1, df6, key_course)\n",
    "\n",
    "# =========================\n",
    "# 偏差値（ロバスト偏差値計算：MAD使用）\n",
    "# =========================\n",
    "def dev_vec(v, m, mad):\n",
    "    # MADを正規分布の標準偏差相当に変換する定数 1.4826\n",
    "    sigma_est = mad * 1.4826\n",
    "    \n",
    "    ok = (~pd.isna(v)) & (~pd.isna(m)) & (~pd.isna(mad)) & (sigma_est != 0)\n",
    "    \n",
    "    # タイムは小さい方が良いので (Median - Value)\n",
    "    # sigma_est が 0 (全員同じタイム等) の場合は偏差値50とする\n",
    "    return np.where(ok, 50 + 10 * (m - v) / sigma_est, 50)\n",
    "\n",
    "bases_for_dev = ['course', 'class']\n",
    "\n",
    "for c in time_columns:\n",
    "    dev_cols = []\n",
    "    for b in bases_for_dev:\n",
    "        mean_col = f\"{c}_{b}\"\n",
    "        mad_col  = f\"MAD_{c}_{b}\"\n",
    "        colname = f\"偏差値_{c}_{b}\"\n",
    "        \n",
    "        # MADが存在する場合のみ計算\n",
    "        if mad_col in merged_df1.columns:\n",
    "            merged_df1[colname] = dev_vec(merged_df1[c], merged_df1[mean_col], merged_df1[mad_col])\n",
    "            dev_cols.append(colname)\n",
    "\n",
    "    if dev_cols:\n",
    "        merged_df1[f\"偏差値_統合_{c}\"] = merged_df1[dev_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "# 統合偏差値が存在する列のみでスコア計算\n",
    "valid_dev_cols = [f\"偏差値_統合_{c}\" for c in time_columns if f\"偏差値_統合_{c}\" in merged_df1.columns]\n",
    "if valid_dev_cols:\n",
    "    merged_df1['総合偏差値スコア'] = merged_df1[valid_dev_cols].mean(axis=1, skipna=True)\n",
    "else:\n",
    "    merged_df1['総合偏差値スコア'] = 50.0\n",
    "\n",
    "# =========================\n",
    "# 加点（変更なし）\n",
    "# =========================\n",
    "bonus_targets = {'4F': '4F(3F)_補', '2F': '3F(2F)_補', '1F': '1F_補'}\n",
    "\n",
    "def calculate_bonus(value, mean, is_saka, col_short):\n",
    "    if pd.isna(value) or pd.isna(mean): return 0.0\n",
    "    if is_saka:\n",
    "        if col_short == '4F': return 0.5 if value < mean else 0.0\n",
    "        if col_short == '2F': return 1.5 if value < mean else 0.0\n",
    "        if col_short == '1F': return 1.0 if value < mean else 0.0\n",
    "    else:\n",
    "        if col_short == '4F': return 0.5 if value < mean else 0.0\n",
    "        if col_short == '2F': return 1.0 if value < mean else 0.0\n",
    "        if col_short == '1F': return 1.5 if value < mean else 0.0\n",
    "    return 0.0\n",
    "\n",
    "th_sfx_list = ['course_20','course_10']\n",
    "bonus_cols = []\n",
    "for col_short, base_col in bonus_targets.items():\n",
    "    for sfx in th_sfx_list:\n",
    "        th_col = f\"{base_col}_{sfx}\"\n",
    "        if th_col in merged_df1.columns:\n",
    "            out_col = f\"加点_{col_short}_{sfx}\"\n",
    "            merged_df1[out_col] = merged_df1.apply(\n",
    "                lambda r: calculate_bonus(\n",
    "                    r.get(base_col, np.nan), r.get(th_col, np.nan),\n",
    "                    bool(r.get('is_saka', False)), col_short\n",
    "                ), axis=1\n",
    "            )\n",
    "            bonus_cols.append(out_col)\n",
    "\n",
    "merged_df1['総合加点スコア'] = merged_df1[bonus_cols].sum(axis=1, skipna=True) if bonus_cols else 0.0\n",
    "\n",
    "# =========================\n",
    "# 係数・最終指数\n",
    "# =========================\n",
    "def rider_coef(x):\n",
    "    s = '' if pd.isna(x) else str(x)\n",
    "    if '助手' in s: return 1.0\n",
    "    if '見習' in s: return 0.8\n",
    "    return 0.9\n",
    "\n",
    "def leg_coef(x):\n",
    "    s = '' if pd.isna(x) else str(x)\n",
    "    if '馬なり' in s: return 1.1\n",
    "    if ('Ｇ' in s) or ('G' in s) or ('強' in s): return 1.0\n",
    "    if '一杯' in s: return 0.8\n",
    "    if 'ヨレ' in s: return 0.7\n",
    "    if 'バテ' in s: return 0.6\n",
    "    return 0.9\n",
    "\n",
    "merged_df1['騎乗者係数'] = merged_df1['乗り役'].apply(rider_coef)\n",
    "merged_df1['脚色係数']   = merged_df1['脚色'].apply(leg_coef)\n",
    "\n",
    "merged_df1['追切指数'] = (\n",
    "    (merged_df1['総合偏差値スコア'].fillna(50) + merged_df1['総合加点スコア'].fillna(0.0))\n",
    "    * merged_df1['騎乗者係数'].fillna(0.9)\n",
    "    * merged_df1['脚色係数'].fillna(0.9)\n",
    ")\n",
    "\n",
    "merged_df1['追切指数'] = merged_df1['追切指数'].replace([np.inf, -np.inf], np.nan).fillna(1).round(1)\n",
    "\n",
    "# 重複排除\n",
    "merged_unique = merged_df1.loc[merged_df1.groupby('target_horseid')['追切指数'].idxmax()].reset_index(drop=True).copy()\n",
    "merged_unique = merged_unique[['target_horseid','追切指数']].copy()\n",
    "\n",
    "del df1,df2,df3,df4,df5,df6,merged_df1\n",
    "\n",
    "# 保存処理\n",
    "combined_df = pd.read_csv(output_filepath1, encoding='cp932').copy()\n",
    "combined_df = pd.concat([combined_df, merged_unique], ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates(subset='target_horseid', keep='last')\n",
    "combined_df.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "\n",
    "combined_df['year'] = pd.to_datetime(\n",
    "    combined_df['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y', errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "for year, dfy in combined_df.groupby('year'):\n",
    "    dfy.drop(columns='year').to_csv(f'{output_dir}Training_Score_Master_{year}.csv', index=False, encoding='cp932')\n",
    "\n",
    "del combined_df\n",
    "\n",
    "print(\"完了：追切指数（MAD・ロバスト偏差値版）を出力しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 選択した成績データを加工してマスタファイルへマージ\n",
    "## 2024年分の成績データを2017~2023年の基準タイムファイルを参照して指数を追加\n",
    "## 2024年分の成績データをマスタファイルへマージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:89: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_df1 = pd.read_csv(merged_filepath, encoding='cp932').copy()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1092: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1.insert(insert_pos, 'レースタイプ', ref.map(race_type_map))\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1['レース強度指数'] = (\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1['レースレベル指数'] = (rating_diff + speed_diff + strength_diff + 100).round(1)\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1['レース強度指数上位差分']=merged_df1['レース強度指数']-merged_df1['レース強度指数_stdtime1'].fillna(merged_df1['レース強度指数_stdtime2'])\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1.insert(insert_pos, 'レースレベル判定', band.where(~no_ref, np.nan).astype('Int64'))\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1182: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1.insert(insert_pos, 'レースレベル評価', merged_df1['レースレベル判定'].map(band_to_grade))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "#---ステップ１：加工する成績データを指定\n",
    "# ファイルパスの指定\n",
    "# 成績データファイルのパス\n",
    "master_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2024_tmp.csv'\n",
    "\n",
    "# 成績データにマージするデータファイルのパス\n",
    "# 初角位置ファイルのパス\n",
    "merge_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\70_First_Corner_Position\\First_Corner_Position_Master.csv'\n",
    "# 2角位置ファイルのパス\n",
    "merge_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\80_Second_Corner_Position\\Second_Corner_Position_Master.csv'\n",
    "# 3角位置ファイルのパス\n",
    "merge_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\90_Third_Corner_Position\\Third_Corner_Position_Master.csv'\n",
    "# 4角位置ファイルのパス\n",
    "merge_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\100_Fourth_Corner_Position\\Fourth_Corner_Position_Master.csv'\n",
    "# 上り位置ファイルのパス\n",
    "merge_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\110_Spurt_Position\\Spurt_Position_Master.csv'\n",
    "# 馬場指数ファイルのパス\n",
    "merge_filepath6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\60_Track_Condition\\Track_Condition_Master.csv'\n",
    "# 前半3Fタイムファイルのパス\n",
    "merge_filepath7 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\120_First3F_Lap\\First3F_Lap_Master.csv'\n",
    "# 追切指数のファイルパス\n",
    "merge_filepath8 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\Training_Score_Master.csv'\n",
    "\n",
    "# 参照先のファイルパス\n",
    "# 基準タイムファイル1の保存先パス\n",
    "ref_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\StdTime1.csv'\n",
    "# 基準タイムファイル2の保存先パス\n",
    "ref_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\StdTime2.csv'\n",
    "# ペース係数ファイルの保存先パス\n",
    "ref_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\PaceTime.csv'\n",
    "# 基準33ラップファイルの保存先パス\n",
    "ref_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\33Lap.csv'\n",
    "# レースレベル基準ファイルのパス\n",
    "ref_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\RaceLevel.csv'\n",
    "\n",
    "# 保存先パス\n",
    "# テン指数の保存先\n",
    "output_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\150_First_Score\\First_Score_Master.csv'\n",
    "# 上り指数の保存先\n",
    "output_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\160_Spurt_Score\\Spurt_Score_Master.csv'\n",
    "# スピード指数の保存先\n",
    "output_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\170_Speed_Score\\Speed_Score_Master.csv'\n",
    "# 総合指数の保存先\n",
    "output_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\180_Total_Score\\Total_Score_Master.csv'\n",
    "# 33ラップ判定の保存先\n",
    "output_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\140_33Lap_Category\\33Lap_Category_Master.csv'\n",
    "# レースレベル判定の保存先\n",
    "output_filepath6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\190_Race_Level\\Race_Level_Master.csv'\n",
    "# 馬タイプ分類のファイルパス\n",
    "output_filepath7 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\220_Horse_Type\\Horse_Type_Master.csv'\n",
    "\n",
    "# テン指数のディレクトリ\n",
    "output_dir1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\150_First_Score\\\\'\n",
    "# 上り指数のディレクトリ\n",
    "output_dir2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\160_Spurt_Score\\\\'\n",
    "# スピード指数のディレクトリ\n",
    "output_dir3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\170_Speed_Score\\\\'\n",
    "# 総合指数のディレクトリ\n",
    "output_dir4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\180_Total_Score\\\\'\n",
    "# 33ラップ判定のディレクトリ\n",
    "output_dir5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\140_33Lap_Category\\\\'\n",
    "# レースレベル判定のディレクトリ\n",
    "output_dir6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\190_Race_Level\\\\'\n",
    "\n",
    "# 列の並び定義ファイルパス\n",
    "header_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\50_SourceCode\\ResultData_Header.csv'\n",
    "\n",
    "# ファイル選択ダイアログを表示\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "merged_filepath = filedialog.askopenfilename(title=\"CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "\n",
    "# ファイルが選択されなかった場合は終了\n",
    "if not merged_filepath:\n",
    "    print(\"ファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# ---ステップ２：マージする成績データの加工\n",
    "merged_df1 = pd.read_csv(merged_filepath, encoding='cp932').copy()\n",
    "\n",
    "merged_df2 = pd.read_csv(merge_filepath1, encoding='cp932').copy()\n",
    "merged_df3 = pd.read_csv(merge_filepath2, encoding='cp932').copy()\n",
    "merged_df4 = pd.read_csv(merge_filepath3, encoding='cp932').copy()\n",
    "merged_df5 = pd.read_csv(merge_filepath4, encoding='cp932').copy()\n",
    "merged_df6 = pd.read_csv(merge_filepath5, encoding='cp932').copy()\n",
    "merged_df7 = pd.read_csv(merge_filepath6, encoding='cp932').copy()\n",
    "merged_df8 = pd.read_csv(merge_filepath7, encoding='cp932').copy()\n",
    "merged_df9 = pd.read_csv(merge_filepath8, encoding='cp932').copy()\n",
    "\n",
    "#　マージファイルで使用する列だけを定義\n",
    "merged_df2 = merged_df2[['target_horseid','初角サイドポジション']]\n",
    "merged_df3 = merged_df3[['target_horseid','2角サイドポジション']]\n",
    "merged_df4 = merged_df4[['target_horseid','3角サイドポジション']]\n",
    "merged_df5 = merged_df5[['target_horseid','4角サイドポジション']]\n",
    "merged_df6 = merged_df6[['target_horseid','4角位置']]\n",
    "merged_df7 = merged_df7[['target_raceid','馬場指数']]\n",
    "merged_df8 = merged_df8[['target_horseid','前半3F']]\n",
    "merged_df9 = merged_df9[['target_horseid','追切指数']]\n",
    "\n",
    "# カラムの整理\n",
    "# 成績データファイルの列名を変更\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid',\n",
    "    '上り3F': 'レース上り3F',\n",
    "    '上り4F': 'レース上り4F',\n",
    "    '上り5F': 'レース上り5F',\n",
    "    '外部指数1':'レイティング',\n",
    "    '外部指数順1':'レイティング順位',\n",
    "    '外部指数2':'ZI指数',\n",
    "    '外部指数順2':'ZI指数順位',\n",
    "    '外部指数3':'追切指数',\n",
    "    '外部指数順3':'追切指数順位',\n",
    "    '上り3F.1':'上り3F'\n",
    "}\n",
    "\n",
    "# df1の列名に対してrename_mapを適用\n",
    "merged_df1 = merged_df1.rename(columns=rename_map)\n",
    "\n",
    "# キーの型を揃える（数字/ゼロ埋めブレ防止）\n",
    "for c in ['target_horseid', 'target_raceid']:\n",
    "    if c in merged_df1: merged_df1[c] = merged_df1[c].astype(str)\n",
    "for d in [merged_df2, merged_df3, merged_df4, merged_df5, merged_df6, merged_df7, merged_df8, merged_df9]:\n",
    "    for c in ['target_horseid', 'target_raceid']:\n",
    "        if c in d: d[c] = d[c].astype(str)\n",
    "\n",
    "#　種牡馬名のspace削除\n",
    "merged_df1['種牡馬'] = merged_df1['種牡馬'].astype(str).str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# ラベル化する列を追加\n",
    "# コースラベル\n",
    "insert_pos = merged_df1.columns.get_loc('コースグループ名1') + 1\n",
    "merged_df1.insert(insert_pos, 'コースラベル', merged_df1['場所'].astype(str) + '_' + merged_df1['芝・ダート'].astype(str) + '_' + merged_df1['トラックコード(JV)'].astype(str))\n",
    "\n",
    "# 父×母の父タイプ名\n",
    "insert_pos = merged_df1.columns.get_loc('母の父タイプ名') + 1\n",
    "merged_df1.insert(insert_pos, '父×母の父タイプ名', merged_df1['種牡馬'].astype(str) + '×' + merged_df1['母の父タイプ名'].astype(str))\n",
    "\n",
    "# 父タイプ名×母の父タイプ名\n",
    "insert_pos = merged_df1.columns.get_loc('父×母の父タイプ名') + 1\n",
    "merged_df1.insert(insert_pos, '父タイプ名×母の父タイプ名', merged_df1['種牡馬タイプ名'].astype(str) + '×' + merged_df1['母の父タイプ名'].astype(str))\n",
    "\n",
    "# 生産者×馬主\n",
    "insert_pos = merged_df1.columns.get_loc('騎手') + 1\n",
    "merged_df1.insert(insert_pos, '生産者×馬主', merged_df1['生産者'].astype(str) + '×' + merged_df1['馬主'].astype(str))\n",
    "\n",
    "# 生産者×調教師\n",
    "insert_pos = merged_df1.columns.get_loc('生産者×馬主') + 1\n",
    "merged_df1.insert(insert_pos, '生産者×調教師', merged_df1['生産者'].astype(str) + '×' + merged_df1['調教師'].astype(str))\n",
    "\n",
    "# 生産者×騎手\n",
    "insert_pos = merged_df1.columns.get_loc('生産者×調教師') + 1\n",
    "merged_df1.insert(insert_pos, '生産者×騎手', merged_df1['生産者'].astype(str) + '×' + merged_df1['騎手'].astype(str))\n",
    "\n",
    "# 馬主×調教師\n",
    "insert_pos = merged_df1.columns.get_loc('生産者×騎手') + 1\n",
    "merged_df1.insert(insert_pos, '馬主×調教師', merged_df1['馬主'].astype(str) + '×' + merged_df1['調教師'].astype(str))\n",
    "\n",
    "# 馬主×騎手\n",
    "insert_pos = merged_df1.columns.get_loc('馬主×調教師') + 1\n",
    "merged_df1.insert(insert_pos, '馬主×騎手', merged_df1['馬主'].astype(str) + '×' + merged_df1['騎手'].astype(str))\n",
    "\n",
    "# 調教師×騎手\n",
    "insert_pos = merged_df1.columns.get_loc('馬主×騎手') + 1\n",
    "merged_df1.insert(insert_pos, '調教師×騎手', merged_df1['調教師'].astype(str) + '×' + merged_df1['騎手'].astype(str))\n",
    "\n",
    "# 調教師×コースラベル\n",
    "insert_pos = merged_df1.columns.get_loc('調教師×騎手') + 1\n",
    "merged_df1.insert(insert_pos, '調教師×コースラベル', merged_df1['調教師'].astype(str) + '×' + merged_df1['コースラベル'].astype(str))\n",
    "\n",
    "# 騎手×コースラベル\n",
    "insert_pos = merged_df1.columns.get_loc('調教師×コースラベル') + 1\n",
    "merged_df1.insert(insert_pos, '騎手×コースラベル', merged_df1['騎手'].astype(str) + '×' + merged_df1['コースラベル'].astype(str))\n",
    "\n",
    "# 配当金額の列を作成する\n",
    "# 列から取り出す金額の数を定義\n",
    "target_cols = {\n",
    "    '単勝配当表記': ('単勝', 1),\n",
    "    '複勝配当表記': ('複勝', 3),\n",
    "    '枠連配当表記': ('枠連', 1),\n",
    "    '馬連配当表記': ('馬連', 1),\n",
    "    'ワイド配当表記': ('ワイド', 3),\n",
    "    '馬単配当表記': ('馬単', 1),\n",
    "    '３連複配当表記': ('３連複', 1),\n",
    "    '３連単配当表記': ('３連単', 1),\n",
    "}\n",
    "\n",
    "# 金額を取り出す正規表現パターン\n",
    "pattern = re.compile(r'[\\\\¥]\\s*([0-9,]+)(?=\\s*(?:\\(|/|$))')\n",
    "\n",
    "def pick_amounts(text, take=1):\n",
    "    if pd.isna(text):\n",
    "        return [np.nan]*take\n",
    "    s = str(text)\n",
    "    found = pattern.findall(s)\n",
    "    nums = []\n",
    "    for x in found:\n",
    "        try:\n",
    "            nums.append(int(x.replace(',', '')))\n",
    "        except:\n",
    "            # 変な値が来てもスルー\n",
    "            continue\n",
    "    # 必要な個数だけ先頭から取り、足りなければNaNで埋める\n",
    "    nums = nums[:take]\n",
    "    if len(nums) < take:\n",
    "        nums += [np.nan]*(take - len(nums))\n",
    "    return nums\n",
    "\n",
    "for src_col, (base_name, take) in target_cols.items():\n",
    "    if src_col not in merged_df1.columns:\n",
    "        # その列が無い場合はスキップ\n",
    "        continue\n",
    "\n",
    "    # 値を取り出す\n",
    "    values = merged_df1[src_col].apply(lambda x: pick_amounts(x, take))\n",
    "\n",
    "    # 1個だけなら「単勝」のように1列、3個なら「複勝1, 複勝2, 複勝3」の3列を作る\n",
    "    if take == 1:\n",
    "        col_name = base_name\n",
    "        merged_df1[col_name] = values.apply(lambda v: v[0] if isinstance(v, list) else np.nan)\n",
    "        # Convert to integer, coercing errors to NaN\n",
    "        merged_df1[col_name] = pd.to_numeric(merged_df1[col_name], errors='coerce').astype('Int64')\n",
    "    else:\n",
    "        for i in range(take):\n",
    "            col_name = f'{base_name}{i+1}'\n",
    "            merged_df1[col_name] = values.apply(lambda v: v[i] if isinstance(v, list) and len(v) > i else np.nan)\n",
    "            # Convert to integer, coercing errors to NaN\n",
    "            merged_df1[col_name] = pd.to_numeric(merged_df1[col_name], errors='coerce').astype('Int64')\n",
    "\n",
    "# 成績データファイルへ対象データをマージする\n",
    "# 初角位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df2, on='target_horseid', how='left')\n",
    "# 2角位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df3, on='target_horseid', how='left')\n",
    "# 3角位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df4, on='target_horseid', how='left')\n",
    "# 4角位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df5, on='target_horseid', how='left')\n",
    "# 上り位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df6, on='target_horseid', how='left')\n",
    "# 馬場指数のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df7, on='target_raceid', how='left')\n",
    "# 前半3Fのマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df8, on='target_horseid', how='left')\n",
    "# 追切指数の代入 とりあえずTrueで上書き\n",
    "left  = merged_df1.set_index('target_horseid')\n",
    "right = merged_df9[['target_horseid','追切指数']].dropna(subset=['追切指数']).set_index('target_horseid')\n",
    "left.update(right, overwrite=True)\n",
    "merged_df1 = left.reset_index()\n",
    "\n",
    "# 不要なデータフレームをクリア\n",
    "del merged_df2\n",
    "del merged_df3\n",
    "del merged_df4\n",
    "del merged_df5\n",
    "del merged_df6\n",
    "del merged_df7\n",
    "del merged_df8\n",
    "\n",
    "# --- 関数群 ---\n",
    "def calculate_33_lap(merged_df1):\n",
    "    \"\"\"距離ごとに33ラップを計算する\"\"\"\n",
    "    rap_33 = []\n",
    "    distance_to_lap_range = {\n",
    "        1000: (0, 3),\n",
    "        1200: (0, 3),\n",
    "        1300: (1, 4),\n",
    "        1400: (1, 4),\n",
    "        1500: (2, 5),\n",
    "        1600: (2, 5),\n",
    "        1700: (3, 6),\n",
    "        1800: (3, 6),\n",
    "        1900: (4, 7),\n",
    "        2000: (4, 7),\n",
    "        2100: (5, 8),\n",
    "        2200: (5, 8),\n",
    "        2300: (6, 9),\n",
    "        2400: (6, 9),\n",
    "        2500: (7, 10),\n",
    "        2600: (7, 10),\n",
    "        2700: (8, 11),\n",
    "        2800: (8, 11),\n",
    "        2900: (9, 12),\n",
    "        3000: (9, 12),\n",
    "        3100: (10, 13),\n",
    "        3200: (10, 13),\n",
    "        3300: (11, 14),\n",
    "        3400: (11, 14),\n",
    "        3500: (12, 15),\n",
    "        3600: (12, 15),\n",
    "    }\n",
    "    for _, row in merged_df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_lap_range:\n",
    "            start, end = distance_to_lap_range[distance]\n",
    "            sum_6to4 = sum(lap_times[start:end])\n",
    "        elif distance == 1150:\n",
    "            sum_6to4 = round(lap_times[0] * 1.25, 1) + lap_times[1] + lap_times[2] if len(lap_times) >= 3 else None\n",
    "        else:\n",
    "            sum_6to4 = None\n",
    "        sum_3to1 = row['レース上り3F'] if 'レース上り3F' in row and not pd.isna(row['レース上り3F']) else None\n",
    "        rap_33_value = sum_6to4 - sum_3to1 if not pd.isna(sum_6to4) and not pd.isna(sum_3to1) else None\n",
    "        rap_33.append(rap_33_value)\n",
    "    merged_df1['33ラップ'] = rap_33\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_middle_lap(merged_df1):\n",
    "    \"\"\"距離ごとに中盤ラップ1・2を計算する\"\"\"\n",
    "    middle_lap1 = []\n",
    "    middle_lap2 = []\n",
    "    distance_to_mid_lap = {\n",
    "        1000: (2, 4, None, None),\n",
    "        1150: (2, 4, None, None),\n",
    "        1200: (2, 4, None, None),\n",
    "        1300: (2, 4, None, None),\n",
    "        1400: (2, 4, None, None),\n",
    "        1500: (3, 5, None, None),\n",
    "        1600: (3, 5, None, None),\n",
    "        1700: (3, 6, None, None),\n",
    "        1800: (3, 6, None, None),\n",
    "        1900: (3, 7, None, None),\n",
    "        2000: (3, 7, None, None),\n",
    "        2100: (3, 5, 5, 8),\n",
    "        2200: (3, 5, 5, 8),\n",
    "        2300: (3, 5, 5, 8),\n",
    "        2400: (3, 6, 6, 9),\n",
    "        2500: (3, 6, 6, 9),\n",
    "        2600: (3, 7, 7, 10),\n",
    "        3000: (3, 8, 8, 12),\n",
    "        3200: (3, 8, 8, 13),\n",
    "        3400: (3, 9, 9, 14),\n",
    "        3600: (3, 9, 9, 15),\n",
    "    }\n",
    "    for _, row in merged_df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_mid_lap:\n",
    "            mid1_start, mid1_end, mid2_start, mid2_end = distance_to_mid_lap[distance]\n",
    "            mid1 = sum(lap_times[mid1_start:mid1_end]) if mid1_start is not None else None\n",
    "            mid2 = sum(lap_times[mid2_start:mid2_end]) if mid2_start is not None else None\n",
    "        else:\n",
    "            mid1 = None\n",
    "            mid2 = None\n",
    "        middle_lap1.append(mid1)\n",
    "        middle_lap2.append(mid2)\n",
    "    merged_df1['中盤ラップ1'] = middle_lap1\n",
    "    merged_df1['中盤ラップ2'] = middle_lap2\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_lap_features(df):\n",
    "    \"\"\"\n",
    "    Lap01～Lap25 を使って\n",
    "      ・最大加速（隣接ラップ差分の最小値）\n",
    "      ・ゴール前ラップ差（ラスト1F - ラスト2F）\n",
    "    を計算して df に列を追加する。\n",
    "    \"\"\"\n",
    "    lap_cols = [f'Lap{str(i).zfill(2)}' for i in range(1, 26)]\n",
    "\n",
    "    def _calc_row(row):\n",
    "        # その馬のラップ一覧（NaN は除外）\n",
    "        laps = []\n",
    "        for c in lap_cols:\n",
    "            if c in row.index and pd.notna(row[c]):\n",
    "                laps.append(row[c])\n",
    "\n",
    "        # ラップが1つ以下ならどっちも計算不能\n",
    "        if len(laps) < 2:\n",
    "            return pd.Series({'最大加速ラップ': np.nan, 'ゴール前ラップ差': np.nan})\n",
    "\n",
    "        laps = np.array(laps, dtype=float)\n",
    "\n",
    "        # 隣り合う差分（後ろ - 前）\n",
    "        diffs = np.diff(laps)   # 例：Lap02-Lap01, Lap03-Lap02, ...\n",
    "\n",
    "        # 最大加速 = 最もマイナスが大きい差分（＝最小値）\n",
    "        max_accel = diffs.min() if len(diffs) > 0 else np.nan\n",
    "\n",
    "        # 終盤ラップ差 = ラスト1F - ラスト2F\n",
    "        last_diff = laps[-1] - laps[-2] if len(laps) >= 2 else np.nan\n",
    "\n",
    "        return pd.Series({\n",
    "            '最大加速ラップ': max_accel if pd.notna(max_accel) else np.nan,\n",
    "            'ゴール前ラップ差': last_diff if pd.notna(last_diff) else np.nan\n",
    "        })\n",
    "\n",
    "    new_cols = df.apply(_calc_row, axis=1)\n",
    "    df['最大加速ラップ'] = new_cols['最大加速ラップ'].round(1)\n",
    "    df['ゴール前ラップ差'] = new_cols['ゴール前ラップ差'].round(1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_days_since_birth(merged_df1):\n",
    "    \"\"\"生後日数を計算する\"\"\"\n",
    "    birth_days = []\n",
    "    for _, row in merged_df1.iterrows():\n",
    "        race_date = datetime.strptime(row['日付S'], '%Y.%m.%d')\n",
    "        birth_str = row['誕生日'].replace(\" \", \"\").replace(\"日\", \"\").replace(\"-\", \"\")\n",
    "        birth_month, birth_day = map(int, birth_str.replace(\"月\", \" \").split())\n",
    "        birth_year = race_date.year - row['年齢']\n",
    "        try:\n",
    "            birth_date = datetime(birth_year, birth_month, birth_day)\n",
    "        except ValueError:\n",
    "            birth_date = datetime(birth_year, 2, 28)\n",
    "        days_old = (race_date - birth_date).days\n",
    "        birth_days.append(days_old)\n",
    "    merged_df1['生後日数'] = birth_days\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_distance_diff(merged_df1):\n",
    "    \"\"\"前走距離との差を計算する\"\"\"\n",
    "    merged_df1['前走距離差'] = merged_df1['距離'] - merged_df1['前走距離']\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_firsthalf_diff(merged_df1):\n",
    "    \"\"\"初角から4角位置の差分を計算\"\"\"\n",
    "    merged_df1['初角_4角差'] = merged_df1.apply(lambda row:\n",
    "        (row['通過1'] - row['通過4']) if pd.notna(row['通過1']) else \\\n",
    "        ((row['通過2'] - row['通過4']) if pd.notna(row['通過2']) else \\\n",
    "        ((row['通過3'] - row['通過4']) if pd.notna(row['通過3']) else np.nan))\n",
    "    , axis=1).fillna(0)\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_goal_diff(merged_df1):\n",
    "    \"\"\"4角から入線順位の差分を計算\"\"\"\n",
    "    # 入線順位を一時的に数値化\n",
    "    rank_num = pd.to_numeric(merged_df1['入線順位'], errors='coerce')\n",
    "\n",
    "    # 有効な順位（1以上）だけを判定するためのマスク\n",
    "    valid_mask = rank_num >= 1\n",
    "\n",
    "    # 出力列だけ作る\n",
    "    merged_df1['4角_入線順位差'] = np.nan\n",
    "\n",
    "    # 有効な行だけ計算\n",
    "    merged_df1.loc[valid_mask, '4角_入線順位差'] = (\n",
    "        pd.to_numeric(merged_df1.loc[valid_mask, '通過4'], errors='coerce')\n",
    "        - rank_num[valid_mask]\n",
    "    )\n",
    "\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_sideposition(merged_df1):\n",
    "    \"\"\"サイドポジションの平均を計算する\"\"\"\n",
    "    cols = ['初角サイドポジション', '2角サイドポジション', '3角サイドポジション', '4角サイドポジション']\n",
    "    merged_df1['サイドポジション平均'] = merged_df1[cols].mean(axis=1)\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_totalprize(merged_df1):\n",
    "    \"\"\"獲得賞金を計算する\"\"\"\n",
    "    merged_df1['獲得賞金'] = merged_df1['賞金'].fillna(0) + merged_df1['付加賞金'].fillna(0)\n",
    "    return merged_df1\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "    \"\"\"タイム表記を秒数に変換\"\"\"\n",
    "    try:\n",
    "        parts = time_str.split(\".\")\n",
    "        if len(parts) == 3:\n",
    "            minutes, seconds, tenths = map(int, parts)\n",
    "            total_seconds = minutes * 60 + seconds + tenths * 0.1\n",
    "        else:\n",
    "            return np.nan\n",
    "        return total_seconds\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def remove_plus_sign(value):\n",
    "    \"\"\"数値データから `+` を削除して変換\"\"\"\n",
    "    try:\n",
    "        return float(str(value).replace(\"+\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def extract_weight(value):\n",
    "    \"\"\"斤量の数値部分だけを抽出\"\"\"\n",
    "    try:\n",
    "        match = re.search(r'\\d+', str(value))\n",
    "        return int(match.group()) if match else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_corner_loss(row):\n",
    "    \"\"\"コーナーロスを計算\"\"\"\n",
    "    corner_positions = [\n",
    "        row.get('初角サイドポジション', 1) - 1,\n",
    "        row.get('2角サイドポジション', 1) - 1,\n",
    "        row.get('3角サイドポジション', 1) - 1,\n",
    "        row.get('4角サイドポジション', 1) - 1\n",
    "    ]\n",
    "    total_distance_loss = sum(corner_positions) * 1.5  # m単位\n",
    "    finish_time_seconds = row['タイムS']\n",
    "    distance_m = row['距離']\n",
    "    if pd.isna(finish_time_seconds) or pd.isna(distance_m) or finish_time_seconds == 0:\n",
    "        return np.nan\n",
    "    avg_speed = distance_m / finish_time_seconds if finish_time_seconds > 0 else np.nan\n",
    "    corner_loss = total_distance_loss / avg_speed if avg_speed > 0 else 0\n",
    "    return round(corner_loss, 2)\n",
    "\n",
    "# 各列の整形\n",
    "# 対象の列を数値変換\n",
    "merged_df1['馬場指数'] = merged_df1['馬場指数'].astype(str).str.extract(r'(-?\\d+)')[0].astype('Int64')\n",
    "merged_df1['レイティング'] = pd.to_numeric(merged_df1['レイティング'], errors='coerce')\n",
    "merged_df1['体重'] = pd.to_numeric(merged_df1['体重'], errors='coerce')\n",
    "merged_df1['Ave-3F'] = pd.to_numeric(merged_df1['Ave-3F'], errors='coerce')\n",
    "merged_df1['上り3F'] = pd.to_numeric(merged_df1['上り3F'], errors='coerce')\n",
    "\n",
    "# 対象の列から記号を除去\n",
    "for col in ['前後3F差', '前後4F差', '前後5F差', '増減']:\n",
    "    merged_df1[col] = merged_df1[col].apply(remove_plus_sign)\n",
    "\n",
    "merged_df1['斤量'] = merged_df1['斤量'].apply(extract_weight)\n",
    "\n",
    "# タイムを秒数に変換\n",
    "merged_df1['タイムS'] = merged_df1['タイムS'].apply(convert_time_to_seconds)\n",
    "merged_df1['-3Fタイム'] = merged_df1['-3Fタイム'].apply(convert_time_to_seconds)\n",
    "\n",
    "# 決め手列を変換(マップにない場合はNanにする)\n",
    "lq_mapping = {\n",
    "    '中団': '差し',\n",
    "    '後方': '追込',\n",
    "}\n",
    "\n",
    "s = merged_df1['決め手'].astype('string').str.strip()\n",
    "merged_df1['決め手'] = s.map(lq_mapping)\n",
    "\n",
    "# 各種計算関数を順次実行\n",
    "# 33ラップの計算\n",
    "merged_df1 = calculate_33_lap(merged_df1)\n",
    "# 中盤ラップ1・2の計算\n",
    "merged_df1 = calculate_middle_lap(merged_df1)\n",
    "# 最大加速ラップ・ゴール前ラップ差の計算\n",
    "merged_df1 = calculate_lap_features(merged_df1)\n",
    "# 生後日数の計算\n",
    "merged_df1 = calculate_days_since_birth(merged_df1)\n",
    "# 前走距離差の計算\n",
    "merged_df1 = calculate_distance_diff(merged_df1)\n",
    "# 初角から4角通過順位差の計算\n",
    "merged_df1 = calculate_firsthalf_diff(merged_df1)\n",
    "# 4角から入線順位差の計算\n",
    "merged_df1 = calculate_goal_diff(merged_df1)\n",
    "# サイドポジション平均値の計算\n",
    "merged_df1 = calculate_sideposition(merged_df1)\n",
    "# 獲得賞金の計算\n",
    "merged_df1 = calculate_totalprize(merged_df1)\n",
    "# 基準斤量の計算\n",
    "merged_df1['基準斤量'] = merged_df1['斤量'] - merged_df1['馬齢斤量差']\n",
    "# RPCI差の計算\n",
    "merged_df1['RPCI差'] = merged_df1['PCI'] - merged_df1['レースPCI']\n",
    "# コーナーロスの計算\n",
    "merged_df1['コーナーロス'] = merged_df1.apply(calculate_corner_loss, axis=1)\n",
    "# 補正走破タイムの計算\n",
    "merged_df1['補正走破タイム'] = merged_df1['タイムS'] - merged_df1['コーナーロス']\n",
    "# スローorハイ関数の計算\n",
    "merged_df1['スローorハイ関数'] = merged_df1['Ave-3F'] - merged_df1['上り3F']\n",
    "\n",
    "# マージ用の列作成処理\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 115:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 範囲定義\n",
    "ranges = [ (-np.inf, -4.6), (-4.6, -3.6), (-3.6, -2.6), (-2.6, -1.6), (-1.6, -0.6), (-0.6, 0.6), (0.6, 1.6), (1.6, 2.6), (2.6, 3.6), (3.6, 4.6), (4.6, np.inf) ]\n",
    "\n",
    "# 区間ラベル\n",
    "def assign_range(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        if i < len(ranges) - 1:\n",
    "            if lower <= value < upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "        else:\n",
    "            # 最終区間（4.6～inf）は右も含める\n",
    "            if lower <= value <= upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "    return np.nan  # 念のため\n",
    "\n",
    "# 馬場分類・競走種別・クラス分類・スローor関数範囲の列を作成する\n",
    "merged_df1['馬場分類'] = merged_df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "merged_df1['競走種別'] = merged_df1['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "merged_df1['クラス分類'] = merged_df1['クラスコード'].apply(categorize_class_code)\n",
    "merged_df1['スローorハイ関数範囲'] = merged_df1['スローorハイ関数'].apply(assign_range)\n",
    "\n",
    "# 共通関数：参照側DFのキー以外の列にサフィックスを付ける\n",
    "def prepare_ref_df(df_ref, merge_keys, suffix):\n",
    "    \"\"\"\n",
    "    マージ用の参照DFの列名に suffix を付ける（キー列以外すべて）\n",
    "    \"\"\"\n",
    "    df_ref = df_ref.copy()\n",
    "    rename_map = {\n",
    "        c: f\"{c}{suffix}\"\n",
    "        for c in df_ref.columns\n",
    "        if c not in merge_keys\n",
    "    }\n",
    "    df_ref = df_ref.rename(columns=rename_map)\n",
    "    return df_ref\n",
    "\n",
    "# マージキー\n",
    "merge_key1 = ['場所','芝・ダート','距離','トラックコード(JV)','馬場分類']\n",
    "merge_key2 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類','馬場分類']\n",
    "merge_key3 = ['場所','芝・ダート','距離','トラックコード(JV)','スローorハイ関数範囲']\n",
    "merge_key4 = ['場所','芝・ダート','距離','トラックコード(JV)']\n",
    "merge_key5 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類']\n",
    "\n",
    "# 基準タイム等データフレームの読み込み\n",
    "base_time_df1 = pd.read_csv(ref_filepath1, encoding='cp932')\n",
    "base_time_df2 = pd.read_csv(ref_filepath2, encoding='cp932')\n",
    "pace_medians_df = pd.read_csv(ref_filepath3, encoding='cp932')\n",
    "lap33_df = pd.read_csv(ref_filepath4, encoding='cp932')\n",
    "racelevel_df = pd.read_csv(ref_filepath5, encoding='cp932')\n",
    "\n",
    "# 参照側の列名にsuffixを付与\n",
    "base_time_df1 = prepare_ref_df(base_time_df1, merge_key1, '_stdtime1').copy()\n",
    "base_time_df2 = prepare_ref_df(base_time_df2, merge_key2, '_stdtime2').copy()\n",
    "pace_medians_df = prepare_ref_df(pace_medians_df, merge_key3, '_paceindex').copy()\n",
    "lap33_df = prepare_ref_df(lap33_df, merge_key4, '_33lap').copy()\n",
    "racelevel_df = prepare_ref_df(racelevel_df, merge_key5, '_racelevel').copy()\n",
    "\n",
    "# merged_df1へその他データフレームをマージ\n",
    "merged_df1 = pd.merge(merged_df1, base_time_df1, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, base_time_df2, on=merge_key2, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, pace_medians_df, on=merge_key3, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, lap33_df, on=merge_key4, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, racelevel_df, on=merge_key5, how='left')\n",
    "\n",
    "# ---ステップ３：成績データに指数追加\n",
    "# 各指数算出の前処理\n",
    "# 基準タイム/距離係数のベース列を作る（Std1優先、なければStd2）\n",
    "base_time = merged_df1['タイムS_stdtime1'].fillna(merged_df1['タイムS_stdtime2'])\n",
    "dist_coef = merged_df1['距離係数_stdtime1'].fillna(merged_df1['距離係数_stdtime2'])\n",
    "\n",
    "# 基準タイム差（秒）：基準タイム - 補正走破タイム\n",
    "base_time_diff = base_time - merged_df1['補正走破タイム']\n",
    "\n",
    "# 基準タイム差×距離係数\n",
    "speed_core = base_time_diff * dist_coef\n",
    "\n",
    "# 平均3F補正値\n",
    "ave3f_base = merged_df1['Ave-3F_stdtime1'].fillna(merged_df1['Ave-3F_stdtime2'])\n",
    "revi_Ave3F = ave3f_base - merged_df1['Ave-3F']\n",
    "\n",
    "# 斤量補正値\n",
    "revi_weight = merged_df1['斤量'] - merged_df1['基準斤量']\n",
    "\n",
    "# クラス補正値（Std1が存在する行だけ有効。Std2代用行では0）\n",
    "# ※ Std1が無い = その条件の1・2勝基準が作れない想定なので、クラス補正は入れない\n",
    "revi_class = (merged_df1['タイムS_stdtime1'] - merged_df1['タイムS_stdtime2']).where(\n",
    "    merged_df1['タイムS_stdtime1'].notna(), 0\n",
    ")\n",
    "\n",
    "# ペース補正値\n",
    "revi_pace = merged_df1['スローorハイ関数'] * merged_df1['ペース補正係数_paceindex']\n",
    "\n",
    "# 馬場指数秒数換算\n",
    "merged_df1['馬場補正値'] = merged_df1['馬場指数'] / 10\n",
    "\n",
    "# 初角位置\n",
    "merged_df1['初角位置'] = (\n",
    "    merged_df1['通過1']\n",
    "      .fillna(merged_df1['通過2'])\n",
    "      .fillna(merged_df1['通過3'])\n",
    "      .fillna(merged_df1['通過4'])\n",
    ")\n",
    "\n",
    "# テン指数の計算\n",
    "merged_df1['テン指数'] = round((\n",
    "(merged_df1['前半3F_stdtime1'].fillna(merged_df1['前半3F_stdtime2']) - merged_df1['前半3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数'] - merged_df1['初角位置'] + 1) / merged_df1['頭数']) # 初角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# 上り指数の計算\n",
    "merged_df1['上り指数'] = round((\n",
    "(merged_df1['上り3F_stdtime1'].fillna(merged_df1['上り3F_stdtime2']) - merged_df1['上り3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数']) - merged_df1['入線順位'] + 1) / merged_df1['頭数'] # 着順評価\n",
    "+ (merged_df1['通過4'] - merged_df1['入線順位']) / merged_df1['頭数'] # ポジション押し上げ力評価\n",
    "+ (merged_df1['頭数'] - merged_df1['通過4'] + 1) / merged_df1['頭数'] # 4角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# スピード指数の計算 ---\n",
    "merged_df1['スピード指数'] = (\n",
    "    (\n",
    "        speed_core\n",
    "        + merged_df1['馬場補正値'].fillna(0)\n",
    "        + revi_Ave3F.fillna(0)\n",
    "        + revi_weight.fillna(0)\n",
    "        + revi_class.fillna(0)\n",
    "        + revi_pace.fillna(0)\n",
    "        + 100\n",
    "    )\n",
    "    .round(1)\n",
    "    .where(speed_core.notna() & (speed_core != 0))\n",
    ")\n",
    "\n",
    "# 総合指数の計算\n",
    "merged_df1['総合指数'] = merged_df1[['スピード指数', '補正タイム', '補9']].mean(axis=1).round(1)\n",
    "\n",
    "# 総合指数の代表値(1着～3着)をdf1へ追加\n",
    "central_score_df1 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "central_score_df1 = central_score_df1.groupby('target_raceid' ,as_index = False)['総合指数'].mean()\n",
    "central_score_df1.rename(columns={'総合指数': 'Top3総合指数'}, inplace=True)\n",
    "central_score_df1['Top3総合指数'] = round(central_score_df1['Top3総合指数'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df1, on='target_raceid', how='left',suffixes=('', '_centralscore1')).copy()\n",
    "\n",
    "# レイティングの平均値を成績データへ追加\n",
    "merged_df1['レイティング'] = pd.to_numeric(merged_df1['レイティング'], errors='coerce')\n",
    "central_score_df2 = merged_df1.groupby('target_raceid' ,as_index = False)['レイティング'].mean().copy()\n",
    "central_score_df2.rename(columns={'レイティング': 'レイティング平均値'}, inplace=True)\n",
    "central_score_df2['レイティング平均値'] = round(central_score_df2['レイティング平均値'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df2, on='target_raceid', how='left' ,suffixes=('', '_centralscore2')).copy()\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del central_score_df1\n",
    "del central_score_df2\n",
    "\n",
    "# 各指数の偏差値を計算\n",
    "def deviation_in_race(series):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    if pd.isna(std) or std == 0:\n",
    "        return pd.Series(np.nan, index=series.index)\n",
    "    return ((series - mean) / std * 10 + 50)\n",
    "\n",
    "# レース内偏差値\n",
    "merged_df1['レイティング偏差値'] = (merged_df1.groupby('target_raceid')['レイティング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['ZI指数偏差値'] = (merged_df1.groupby('target_raceid')['ZI指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['追切指数偏差値'] = (merged_df1.groupby('target_raceid')['追切指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['マイニング偏差値'] = (merged_df1.groupby('target_raceid')['マイニング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['対戦型マイニング偏差値'] = (merged_df1.groupby('target_raceid')['対戦型マイニング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['前半3F偏差値'] = merged_df1.groupby('target_raceid')['前半3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['上り3F偏差値'] = merged_df1.groupby('target_raceid')['上り3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['Ave-3F偏差値'] = merged_df1.groupby('target_raceid')['Ave-3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['テン指数偏差値'] = (merged_df1.groupby('target_raceid')['テン指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['上り指数偏差値'] = (merged_df1.groupby('target_raceid')['上り指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['スピード指数偏差値'] = (merged_df1.groupby('target_raceid')['スピード指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['総合指数偏差値'] = (merged_df1.groupby('target_raceid')['総合指数'].transform(deviation_in_race).round(1))\n",
    "\n",
    "# レース内順位（dense）\n",
    "merged_df1['前半3F順位'] = (merged_df1.groupby('target_raceid')['前半3F'].rank(ascending=True, method='dense').astype('Int64'))\n",
    "merged_df1['テン指数順位'] = (merged_df1.groupby('target_raceid')['テン指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['上り指数順位'] = (merged_df1.groupby('target_raceid')['上り指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['Ave-3F順位'] = (merged_df1.groupby('target_raceid')['Ave-3F'].rank(ascending=True, method='dense').astype('Int64'))\n",
    "merged_df1['スピード指数順位'] = (merged_df1.groupby('target_raceid')['スピード指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['総合指数順位'] = (merged_df1.groupby('target_raceid')['総合指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "\n",
    "# 順位分布の計算\n",
    "merged_df1['レイティング順位分布'] = (merged_df1['レイティング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['ZI指数順位分布'] = (merged_df1['ZI指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['追切指数順位分布'] = (merged_df1['追切指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['マイニング順位分布'] = (merged_df1['マイニング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['対戦型マイニング順位分布'] = (merged_df1['対戦型マイニング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['前半3F順位分布'] = (merged_df1['前半3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['テン指数順位分布'] = (merged_df1['テン指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['上り3F順位分布'] = (merged_df1['上り3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['上り指数順位分布'] = (merged_df1['上り指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['Ave-3F順位分布'] = (merged_df1['Ave-3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['スピード指数順位分布'] = (merged_df1['スピード指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['総合指数順位分布'] = (merged_df1['総合指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "\n",
    "# ---ステップ４：基準タイムとの指数差追加\n",
    "# Top3総合指数と総合指数の差分を成績データへ追加\n",
    "merged_df1['Top3総合指数差分'] = merged_df1['総合指数'] - merged_df1['Top3総合指数']\n",
    "\n",
    "# レイティング平均値とレイティングの差分を追加\n",
    "merged_df1['平均レイティング差分'] = merged_df1['レイティング'] - merged_df1['レイティング平均値']\n",
    "\n",
    "# PCI3：基準タイム１差分\n",
    "merged_df1['PCI3差分']=merged_df1['PCI3']-merged_df1['PCI3_stdtime1'].fillna(merged_df1['PCI3_stdtime2'])\n",
    "\n",
    "# PCI：基準タイム１差分\n",
    "merged_df1['PCI上位差分']=merged_df1['PCI']-merged_df1['PCI_stdtime1'].fillna(merged_df1['PCI_stdtime2'])\n",
    "merged_df1['PCI勝馬差分']=merged_df1['PCI']-merged_df1['PCI_1着_stdtime1'].fillna(merged_df1['PCI_1着_stdtime2'])\n",
    "\n",
    "# 生後日数：基準タイム２差分\n",
    "merged_df1['生後日数上位差分']=merged_df1['生後日数']-merged_df1['生後日数_stdtime2'].fillna(merged_df1['生後日数_stdtime1'])\n",
    "merged_df1['生後日数勝馬差分']=merged_df1['生後日数']-merged_df1['生後日数_1着_stdtime2'].fillna(merged_df1['生後日数_1着_stdtime1'])\n",
    "\n",
    "# 馬体重：基準タイム２差分\n",
    "merged_df1['体重上位差分']=merged_df1['体重']-merged_df1['体重_stdtime2'].fillna(merged_df1['体重_stdtime1'])\n",
    "merged_df1['体重勝馬差分']=merged_df1['体重']-merged_df1['体重_1着_stdtime2'].fillna(merged_df1['体重_1着_stdtime1'])\n",
    "\n",
    "# 馬体重斤量比：基準タイム２差分\n",
    "merged_df1['斤量馬体重比上位差分']=merged_df1['斤量馬体重比']-merged_df1['斤量馬体重比_stdtime2'].fillna(merged_df1['斤量馬体重比_stdtime1'])\n",
    "merged_df1['斤量馬体重比勝馬差分']=merged_df1['斤量馬体重比']-merged_df1['斤量馬体重比_1着_stdtime2'].fillna(merged_df1['斤量馬体重比_1着_stdtime1'])\n",
    "\n",
    "# 前走距離：基準タイム１差分\n",
    "merged_df1['前走距離上位差分']=merged_df1['前走距離']-merged_df1['前走距離_stdtime1'].fillna(merged_df1['前走距離_stdtime2'])\n",
    "merged_df1['前走距離勝馬差分']=merged_df1['前走距離']-merged_df1['前走距離_1着_stdtime1'].fillna(merged_df1['前走距離_1着_stdtime2'])\n",
    "\n",
    "# 前走距離差：基準タイム１差分\n",
    "merged_df1['前走距離差上位差分']=merged_df1['前走距離差']-merged_df1['前走距離差_stdtime1'].fillna(merged_df1['前走距離差_stdtime2'])\n",
    "merged_df1['前走距離差勝馬差分']=merged_df1['前走距離差']-merged_df1['前走距離差_1着_stdtime1'].fillna(merged_df1['前走距離差_1着_stdtime2'])\n",
    "\n",
    "# レイティング：基準タイム１差分\n",
    "merged_df1['レイティング上位差分']=merged_df1['レイティング']-merged_df1['レイティング_stdtime1'].fillna(merged_df1['レイティング_stdtime2'])\n",
    "merged_df1['レイティング勝馬差分']=merged_df1['レイティング']-merged_df1['レイティング_1着_stdtime1'].fillna(merged_df1['レイティング_1着_stdtime2'])\n",
    "\n",
    "# レイティング偏差値：基準タイム１差分\n",
    "merged_df1['レイティング偏差値上位差分']=merged_df1['レイティング偏差値']-merged_df1['レイティング偏差値_stdtime1'].fillna(merged_df1['レイティング偏差値_stdtime2'])\n",
    "merged_df1['レイティング偏差値勝馬差分']=merged_df1['レイティング偏差値']-merged_df1['レイティング偏差値_1着_stdtime1'].fillna(merged_df1['レイティング偏差値_1着_stdtime2'])\n",
    "\n",
    "# レイティング順位分布：基準タイム１差分\n",
    "merged_df1['レイティング順位分布上位差分']=merged_df1['レイティング順位分布']-merged_df1['レイティング順位分布_stdtime1'].fillna(merged_df1['レイティング順位分布_stdtime2'])\n",
    "merged_df1['レイティング順位分布勝馬差分']=merged_df1['レイティング順位分布']-merged_df1['レイティング順位分布_1着_stdtime1'].fillna(merged_df1['レイティング順位分布_1着_stdtime2'])\n",
    "\n",
    "# ZI指数：基準タイム１差分\n",
    "merged_df1['ZI指数上位差分']=merged_df1['ZI指数']-merged_df1['ZI指数_stdtime1'].fillna(merged_df1['ZI指数_stdtime2'])\n",
    "merged_df1['ZI指数勝馬差分']=merged_df1['ZI指数']-merged_df1['ZI指数_1着_stdtime1'].fillna(merged_df1['ZI指数_1着_stdtime2'])\n",
    "\n",
    "# ZI指数偏差値：基準タイム１差分\n",
    "merged_df1['ZI指数偏差値上位差分']=merged_df1['ZI指数偏差値']-merged_df1['ZI指数偏差値_stdtime1'].fillna(merged_df1['ZI指数偏差値_stdtime2'])\n",
    "merged_df1['ZI指数偏差値勝馬差分']=merged_df1['ZI指数偏差値']-merged_df1['ZI指数偏差値_1着_stdtime1'].fillna(merged_df1['ZI指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# ZI指数順位分布：基準タイム１差分\n",
    "merged_df1['ZI指数順位分布上位差分']=merged_df1['ZI指数順位分布']-merged_df1['ZI指数順位分布_stdtime1'].fillna(merged_df1['ZI指数順位分布_stdtime2'])\n",
    "merged_df1['ZI指数順位分布勝馬差分']=merged_df1['ZI指数順位分布']-merged_df1['ZI指数順位分布_1着_stdtime1'].fillna(merged_df1['ZI指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# 追切指数：基準タイム１差分\n",
    "merged_df1['追切指数上位差分']=merged_df1['追切指数']-merged_df1['追切指数_stdtime1'].fillna(merged_df1['追切指数_stdtime2'])\n",
    "merged_df1['追切指数勝馬差分']=merged_df1['追切指数']-merged_df1['追切指数_1着_stdtime1'].fillna(merged_df1['追切指数_1着_stdtime2'])\n",
    "\n",
    "# 追切指数偏差値：基準タイム１差分\n",
    "merged_df1['追切指数偏差値上位差分']=merged_df1['追切指数偏差値']-merged_df1['追切指数偏差値_stdtime1'].fillna(merged_df1['追切指数偏差値_stdtime2'])\n",
    "merged_df1['追切指数偏差値勝馬差分']=merged_df1['追切指数偏差値']-merged_df1['追切指数偏差値_1着_stdtime1'].fillna(merged_df1['追切指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# 追切指数順位分布：基準タイム１差分\n",
    "merged_df1['追切指数順位分布上位差分']=merged_df1['追切指数順位分布']-merged_df1['追切指数順位分布_stdtime1'].fillna(merged_df1['追切指数順位分布_stdtime2'])\n",
    "merged_df1['追切指数順位分布勝馬差分']=merged_df1['追切指数順位分布']-merged_df1['追切指数順位分布_1着_stdtime1'].fillna(merged_df1['追切指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# マイニング：基準タイム１差分\n",
    "merged_df1['マイニング上位差分']=merged_df1['マイニング']-merged_df1['マイニング_stdtime1'].fillna(merged_df1['マイニング_stdtime2'])\n",
    "merged_df1['マイニング勝馬差分']=merged_df1['マイニング']-merged_df1['マイニング_1着_stdtime1'].fillna(merged_df1['マイニング_1着_stdtime2'])\n",
    "\n",
    "# マイニング偏差値：基準タイム１差分\n",
    "merged_df1['マイニング偏差値上位差分']=merged_df1['マイニング偏差値']-merged_df1['マイニング偏差値_stdtime1'].fillna(merged_df1['マイニング偏差値_stdtime2'])\n",
    "merged_df1['マイニング偏差値勝馬差分']=merged_df1['マイニング偏差値']-merged_df1['マイニング偏差値_1着_stdtime1'].fillna(merged_df1['マイニング偏差値_1着_stdtime2'])\n",
    "\n",
    "# マイニング順位分布：基準タイム１差分\n",
    "merged_df1['マイニング順位分布上位差分']=merged_df1['マイニング順位分布']-merged_df1['マイニング順位分布_stdtime1'].fillna(merged_df1['マイニング順位分布_stdtime2'])\n",
    "merged_df1['マイニング順位分布勝馬差分']=merged_df1['マイニング順位分布']-merged_df1['マイニング順位分布_1着_stdtime1'].fillna(merged_df1['マイニング順位分布_1着_stdtime2'])\n",
    "\n",
    "# 対戦型マイニング：基準タイム１差分\n",
    "merged_df1['対戦型マイニング上位差分']=merged_df1['対戦型マイニング']-merged_df1['対戦型マイニング_stdtime1'].fillna(merged_df1['対戦型マイニング_stdtime2'])\n",
    "merged_df1['対戦型マイニング勝馬差分']=merged_df1['対戦型マイニング']-merged_df1['対戦型マイニング_1着_stdtime1'].fillna(merged_df1['対戦型マイニング_1着_stdtime2'])\n",
    "\n",
    "# 対戦型マイニング偏差値：基準タイム１差分\n",
    "merged_df1['対戦型マイニング偏差値上位差分']=merged_df1['対戦型マイニング偏差値']-merged_df1['対戦型マイニング偏差値_stdtime1'].fillna(merged_df1['対戦型マイニング偏差値_stdtime2'])\n",
    "merged_df1['対戦型マイニング偏差値勝馬差分']=merged_df1['対戦型マイニング偏差値']-merged_df1['対戦型マイニング偏差値_1着_stdtime1'].fillna(merged_df1['対戦型マイニング偏差値_1着_stdtime2'])\n",
    "\n",
    "# 対戦型マイニング順位分布：基準タイム１差分\n",
    "merged_df1['対戦型マイニング順位分布上位差分']=merged_df1['対戦型マイニング順位分布']-merged_df1['対戦型マイニング順位分布_stdtime1'].fillna(merged_df1['対戦型マイニング順位分布_stdtime2'])\n",
    "merged_df1['対戦型マイニング順位分布勝馬差分']=merged_df1['対戦型マイニング順位分布']-merged_df1['対戦型マイニング順位分布_1着_stdtime1'].fillna(merged_df1['対戦型マイニング順位分布_1着_stdtime2'])\n",
    "\n",
    "# タイムS：基準タイム１差分\n",
    "merged_df1['タイムS上位差分']=merged_df1['タイムS']-merged_df1['タイムS_stdtime1'].fillna(merged_df1['タイムS_stdtime2'])\n",
    "merged_df1['タイムS勝馬差分']=merged_df1['タイムS']-merged_df1['タイムS_1着_stdtime1'].fillna(merged_df1['タイムS_1着_stdtime2'])\n",
    "\n",
    "# 補正走破タイム：基準タイム１差分\n",
    "merged_df1['補正走破タイム上位差分']=merged_df1['補正走破タイム']-merged_df1['補正走破タイム_stdtime1'].fillna(merged_df1['補正走破タイム_stdtime2'])\n",
    "merged_df1['補正走破タイム勝馬差分']=merged_df1['補正走破タイム']-merged_df1['補正走破タイム_1着_stdtime1'].fillna(merged_df1['補正走破タイム_1着_stdtime2'])\n",
    "\n",
    "# -3Fタイム：基準タイム１差分\n",
    "merged_df1['-3Fタイム上位差分']=merged_df1['-3Fタイム']-merged_df1['-3Fタイム_stdtime1'].fillna(merged_df1['-3Fタイム_stdtime2'])\n",
    "merged_df1['-3Fタイム勝馬差分']=merged_df1['-3Fタイム']-merged_df1['-3Fタイム_1着_stdtime1'].fillna(merged_df1['-3Fタイム_1着_stdtime2'])\n",
    "\n",
    "# 前半3F：基準タイム１差分\n",
    "merged_df1['前半3F上位差分']=merged_df1['前半3F']-merged_df1['前半3F_stdtime1'].fillna(merged_df1['前半3F_stdtime2'])\n",
    "merged_df1['前半3F勝馬差分']=merged_df1['前半3F']-merged_df1['前半3F_1着_stdtime1'].fillna(merged_df1['前半3F_1着_stdtime2'])\n",
    "\n",
    "# 前半3F偏差値：基準タイム１差分\n",
    "merged_df1['前半3F偏差値上位差分']=merged_df1['前半3F偏差値']-merged_df1['前半3F偏差値_stdtime1'].fillna(merged_df1['前半3F偏差値_stdtime2'])\n",
    "merged_df1['前半3F偏差値勝馬差分']=merged_df1['前半3F偏差値']-merged_df1['前半3F偏差値_1着_stdtime1'].fillna(merged_df1['前半3F偏差値_1着_stdtime2'])\n",
    "\n",
    "# 前半3F順位：基準タイム１差分\n",
    "merged_df1['前半3F順位上位差分']=merged_df1['前半3F順位']-merged_df1['前半3F順位_stdtime1'].fillna(merged_df1['前半3F順位_stdtime2'])\n",
    "merged_df1['前半3F順位勝馬差分']=merged_df1['前半3F順位']-merged_df1['前半3F順位_1着_stdtime1'].fillna(merged_df1['前半3F順位_1着_stdtime2'])\n",
    "\n",
    "# 前半3F順位分布：基準タイム１差分\n",
    "merged_df1['前半3F順位分布上位差分']=merged_df1['前半3F順位分布']-merged_df1['前半3F順位分布_stdtime1'].fillna(merged_df1['前半3F順位分布_stdtime2'])\n",
    "merged_df1['前半3F順位分布勝馬差分']=merged_df1['前半3F順位分布']-merged_df1['前半3F順位分布_1着_stdtime1'].fillna(merged_df1['前半3F順位分布_1着_stdtime2'])\n",
    "\n",
    "# 上り3F：基準タイム１差分\n",
    "merged_df1['上り3F上位差分']=merged_df1['上り3F']-merged_df1['上り3F_stdtime1'].fillna(merged_df1['上り3F_stdtime2'])\n",
    "merged_df1['上り3F勝馬差分']=merged_df1['上り3F']-merged_df1['上り3F_1着_stdtime1'].fillna(merged_df1['上り3F_1着_stdtime2'])\n",
    "\n",
    "# 上り3F偏差値：基準タイム１差分\n",
    "merged_df1['上り3F偏差値上位差分']=merged_df1['上り3F偏差値']-merged_df1['上り3F偏差値_stdtime1'].fillna(merged_df1['上り3F偏差値_stdtime2'])\n",
    "merged_df1['上り3F偏差値勝馬差分']=merged_df1['上り3F偏差値']-merged_df1['上り3F偏差値_1着_stdtime1'].fillna(merged_df1['上り3F偏差値_1着_stdtime2'])\n",
    "\n",
    "# 上り3F順位：基準タイム１差分\n",
    "merged_df1['上り3F順位上位差分']=merged_df1['上り3F順位']-merged_df1['上り3F順位_stdtime1'].fillna(merged_df1['上り3F順位_stdtime2'])\n",
    "merged_df1['上り3F順位勝馬差分']=merged_df1['上り3F順位']-merged_df1['上り3F順位_1着_stdtime1'].fillna(merged_df1['上り3F順位_1着_stdtime2'])\n",
    "\n",
    "# 上り3F順位分布：基準タイム１差分\n",
    "merged_df1['上り3F順位分布上位差分']=merged_df1['上り3F順位分布']-merged_df1['上り3F順位分布_stdtime1'].fillna(merged_df1['上り3F順位分布_stdtime2'])\n",
    "merged_df1['上り3F順位分布勝馬差分']=merged_df1['上り3F順位分布']-merged_df1['上り3F順位分布_1着_stdtime1'].fillna(merged_df1['上り3F順位分布_1着_stdtime2'])\n",
    "\n",
    "# Ave-3F：基準タイム１差分\n",
    "merged_df1['Ave-3F上位差分']=merged_df1['Ave-3F']-merged_df1['Ave-3F_stdtime1'].fillna(merged_df1['Ave-3F_stdtime2'])\n",
    "merged_df1['Ave-3F勝馬差分']=merged_df1['Ave-3F']-merged_df1['Ave-3F_1着_stdtime1'].fillna(merged_df1['Ave-3F_1着_stdtime2'])\n",
    "\n",
    "# Ave-3F偏差値：基準タイム１差分\n",
    "merged_df1['Ave-3F偏差値上位差分']=merged_df1['Ave-3F偏差値']-merged_df1['Ave-3F偏差値_stdtime1'].fillna(merged_df1['Ave-3F偏差値_stdtime2'])\n",
    "merged_df1['Ave-3F偏差値勝馬差分']=merged_df1['Ave-3F偏差値']-merged_df1['Ave-3F偏差値_1着_stdtime1'].fillna(merged_df1['Ave-3F偏差値_1着_stdtime2'])\n",
    "\n",
    "# Ave-3F順位：基準タイム１差分\n",
    "merged_df1['Ave-3F順位上位差分']=merged_df1['Ave-3F順位']-merged_df1['Ave-3F順位_stdtime1'].fillna(merged_df1['Ave-3F順位_stdtime2'])\n",
    "merged_df1['Ave-3F順位勝馬差分']=merged_df1['Ave-3F順位']-merged_df1['Ave-3F順位_1着_stdtime1'].fillna(merged_df1['Ave-3F順位_1着_stdtime2'])\n",
    "\n",
    "# Ave-3F順位分布：基準タイム１差分\n",
    "merged_df1['Ave-3F順位分布上位差分']=merged_df1['Ave-3F順位分布']-merged_df1['Ave-3F順位分布_stdtime1'].fillna(merged_df1['Ave-3F順位分布_stdtime2'])\n",
    "merged_df1['Ave-3F順位分布勝馬差分']=merged_df1['Ave-3F順位分布']-merged_df1['Ave-3F順位分布_1着_stdtime1'].fillna(merged_df1['Ave-3F順位分布_1着_stdtime2'])\n",
    "\n",
    "# -3F差：基準タイム１差分\n",
    "merged_df1['-3F差上位差分']=merged_df1['-3F差']-merged_df1['-3F差_stdtime1'].fillna(merged_df1['-3F差_stdtime2'])\n",
    "merged_df1['-3F差勝馬差分']=merged_df1['-3F差']-merged_df1['-3F差_1着_stdtime1'].fillna(merged_df1['-3F差_1着_stdtime2'])\n",
    "\n",
    "# テン指数：基準タイム１差分\n",
    "merged_df1['テン指数上位差分']=merged_df1['テン指数']-merged_df1['テン指数_stdtime1'].fillna(merged_df1['テン指数_stdtime2'])\n",
    "merged_df1['テン指数勝馬差分']=merged_df1['テン指数']-merged_df1['テン指数_1着_stdtime1'].fillna(merged_df1['テン指数_1着_stdtime2'])\n",
    "\n",
    "# テン指数偏差値：基準タイム１差分\n",
    "merged_df1['テン指数偏差値上位差分']=merged_df1['テン指数偏差値']-merged_df1['テン指数偏差値_stdtime1'].fillna(merged_df1['テン指数偏差値_stdtime2'])\n",
    "merged_df1['テン指数偏差値勝馬差分']=merged_df1['テン指数偏差値']-merged_df1['テン指数偏差値_1着_stdtime1'].fillna(merged_df1['テン指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# テン指数順位：基準タイム１差分\n",
    "merged_df1['テン指数順位上位差分']=merged_df1['テン指数順位']-merged_df1['テン指数順位_stdtime1'].fillna(merged_df1['テン指数順位_stdtime2'])\n",
    "merged_df1['テン指数順位勝馬差分']=merged_df1['テン指数順位']-merged_df1['テン指数順位_1着_stdtime1'].fillna(merged_df1['テン指数順位_1着_stdtime2'])\n",
    "\n",
    "# テン指数順位分布：基準タイム１差分\n",
    "merged_df1['テン指数順位分布上位差分']=merged_df1['テン指数順位分布']-merged_df1['テン指数順位分布_stdtime1'].fillna(merged_df1['テン指数順位分布_stdtime2'])\n",
    "merged_df1['テン指数順位分布勝馬差分']=merged_df1['テン指数順位分布']-merged_df1['テン指数順位分布_1着_stdtime1'].fillna(merged_df1['テン指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# 上り指数：基準タイム１差分\n",
    "merged_df1['上り指数上位差分']=merged_df1['上り指数']-merged_df1['上り指数_stdtime1'].fillna(merged_df1['上り指数_stdtime2'])\n",
    "merged_df1['上り指数勝馬差分']=merged_df1['上り指数']-merged_df1['上り指数_1着_stdtime1'].fillna(merged_df1['上り指数_1着_stdtime2'])\n",
    "\n",
    "# 上り指数偏差値：基準タイム１差分\n",
    "merged_df1['上り指数偏差値上位差分']=merged_df1['上り指数偏差値']-merged_df1['上り指数偏差値_stdtime1'].fillna(merged_df1['上り指数偏差値_stdtime2'])\n",
    "merged_df1['上り指数偏差値勝馬差分']=merged_df1['上り指数偏差値']-merged_df1['上り指数偏差値_1着_stdtime1'].fillna(merged_df1['上り指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# 上り指数順位：基準タイム１差分\n",
    "merged_df1['上り指数順位上位差分']=merged_df1['上り指数順位']-merged_df1['上り指数順位_stdtime1'].fillna(merged_df1['上り指数順位_stdtime2'])\n",
    "merged_df1['上り指数順位勝馬差分']=merged_df1['上り指数順位']-merged_df1['上り指数順位_1着_stdtime1'].fillna(merged_df1['上り指数順位_1着_stdtime2'])\n",
    "\n",
    "# 上り指数順位分布：基準タイム１差分\n",
    "merged_df1['上り指数順位分布上位差分']=merged_df1['上り指数順位分布']-merged_df1['上り指数順位分布_stdtime1'].fillna(merged_df1['上り指数順位分布_stdtime2'])\n",
    "merged_df1['上り指数順位分布勝馬差分']=merged_df1['上り指数順位分布']-merged_df1['上り指数順位分布_1着_stdtime1'].fillna(merged_df1['上り指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# スピード指数：基準タイム１差分\n",
    "merged_df1['スピード指数上位差分']=merged_df1['スピード指数']-merged_df1['スピード指数_stdtime1'].fillna(merged_df1['スピード指数_stdtime2'])\n",
    "merged_df1['スピード指数勝馬差分']=merged_df1['スピード指数']-merged_df1['スピード指数_1着_stdtime1'].fillna(merged_df1['スピード指数_1着_stdtime2'])\n",
    "\n",
    "# スピード指数偏差値：基準タイム１差分\n",
    "merged_df1['スピード指数偏差値上位差分']=merged_df1['スピード指数偏差値']-merged_df1['スピード指数偏差値_stdtime1'].fillna(merged_df1['スピード指数偏差値_stdtime2'])\n",
    "merged_df1['スピード指数偏差値勝馬差分']=merged_df1['スピード指数偏差値']-merged_df1['スピード指数偏差値_1着_stdtime1'].fillna(merged_df1['スピード指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# スピード指数順位：基準タイム１差分\n",
    "merged_df1['スピード指数順位上位差分']=merged_df1['スピード指数順位']-merged_df1['スピード指数順位_stdtime1'].fillna(merged_df1['スピード指数順位_stdtime2'])\n",
    "merged_df1['スピード指数順位勝馬差分']=merged_df1['スピード指数順位']-merged_df1['スピード指数順位_1着_stdtime1'].fillna(merged_df1['スピード指数順位_1着_stdtime2'])\n",
    "\n",
    "# スピード指数順位分布：基準タイム１差分\n",
    "merged_df1['スピード指数順位分布上位差分']=merged_df1['スピード指数順位分布']-merged_df1['スピード指数順位分布_stdtime1'].fillna(merged_df1['スピード指数順位分布_stdtime2'])\n",
    "merged_df1['スピード指数順位分布勝馬差分']=merged_df1['スピード指数順位分布']-merged_df1['スピード指数順位分布_1着_stdtime1'].fillna(merged_df1['スピード指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# 総合指数：基準タイム１差分\n",
    "merged_df1['総合指数上位差分']=merged_df1['総合指数']-merged_df1['総合指数_stdtime1'].fillna(merged_df1['総合指数_stdtime2'])\n",
    "merged_df1['総合指数勝馬差分']=merged_df1['総合指数']-merged_df1['総合指数_1着_stdtime1'].fillna(merged_df1['総合指数_1着_stdtime2'])\n",
    "\n",
    "# 総合指数偏差値：基準タイム１差分\n",
    "merged_df1['総合指数偏差値上位差分']=merged_df1['総合指数偏差値']-merged_df1['総合指数偏差値_stdtime1'].fillna(merged_df1['総合指数偏差値_stdtime2'])\n",
    "merged_df1['総合指数偏差値勝馬差分']=merged_df1['総合指数偏差値']-merged_df1['総合指数偏差値_1着_stdtime1'].fillna(merged_df1['総合指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# 総合指数順位：基準タイム１差分\n",
    "merged_df1['総合指数順位上位差分']=merged_df1['総合指数順位']-merged_df1['総合指数順位_stdtime1'].fillna(merged_df1['総合指数順位_stdtime2'])\n",
    "merged_df1['総合指数順位勝馬差分']=merged_df1['総合指数順位']-merged_df1['総合指数順位_1着_stdtime1'].fillna(merged_df1['総合指数順位_1着_stdtime2'])\n",
    "\n",
    "# 総合指数順位分布：基準タイム１差分\n",
    "merged_df1['総合指数順位分布上位差分']=merged_df1['総合指数順位分布']-merged_df1['総合指数順位分布_stdtime1'].fillna(merged_df1['総合指数順位分布_stdtime2'])\n",
    "merged_df1['総合指数順位分布勝馬差分']=merged_df1['総合指数順位分布']-merged_df1['総合指数順位分布_1着_stdtime1'].fillna(merged_df1['総合指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# PCI：基準タイム１差分\n",
    "merged_df1['PCI上位差分']=merged_df1['PCI']-merged_df1['PCI_stdtime1'].fillna(merged_df1['PCI_stdtime2'])\n",
    "merged_df1['PCI勝馬差分']=merged_df1['PCI']-merged_df1['PCI_1着_stdtime1'].fillna(merged_df1['PCI_1着_stdtime2'])\n",
    "\n",
    "# 初角_4角差：基準タイム１差分\n",
    "merged_df1['初角_4角差上位差分']=merged_df1['初角_4角差']-merged_df1['初角_4角差_stdtime1'].fillna(merged_df1['初角_4角差_stdtime2'])\n",
    "merged_df1['初角_4角差勝馬差分']=merged_df1['初角_4角差']-merged_df1['初角_4角差_1着_stdtime1'].fillna(merged_df1['初角_4角差_1着_stdtime2'])\n",
    "\n",
    "# 4角_入線順位差：基準タイム１差分\n",
    "merged_df1['4角_入線順位差上位差分']=merged_df1['4角_入線順位差']-merged_df1['4角_入線順位差_stdtime1'].fillna(merged_df1['4角_入線順位差_stdtime2'])\n",
    "merged_df1['4角_入線順位差勝馬差分']=merged_df1['4角_入線順位差']-merged_df1['4角_入線順位差_1着_stdtime1'].fillna(merged_df1['4角_入線順位差_1着_stdtime2'])\n",
    "\n",
    "# ---ステップ５：33ラップを判定する\n",
    "# 33ラップ判定用関数\n",
    "def assign_label(row):\n",
    "    lap_value = row['33ラップ']\n",
    "    if pd.isna(lap_value):\n",
    "        return np.nan\n",
    "\n",
    "    candidates = {\n",
    "        -2: row['33ラップ-2_33lap'],\n",
    "        -1: row['33ラップ-1_33lap'],\n",
    "         0: row['33ラップ±0_33lap'],\n",
    "         1: row['33ラップ+1_33lap'],\n",
    "         2: row['33ラップ+2_33lap'],\n",
    "    }\n",
    "\n",
    "    # 参照側が全部NaNなら判定不能\n",
    "    if all(pd.isna(v) for v in candidates.values()):\n",
    "        return np.nan\n",
    "\n",
    "    # 差分（絶対値）が最小のスケールを選ぶ\n",
    "    best_scale = min(\n",
    "        candidates.keys(),\n",
    "        key=lambda k: abs(lap_value - candidates[k]) if pd.notna(candidates[k]) else np.inf\n",
    "    )\n",
    "\n",
    "    # 0スケール\n",
    "    if best_scale == 0:\n",
    "        if lap_value < 0:\n",
    "            return '持0'\n",
    "        elif lap_value > 0:\n",
    "            return '瞬0'\n",
    "        else:\n",
    "            return '総'\n",
    "\n",
    "    prefix = '瞬' if lap_value > 0 else '持'\n",
    "    suffix = f'+{best_scale}' if best_scale > 0 else f'{best_scale}'\n",
    "    return prefix + suffix\n",
    "\n",
    "# 33ラップを判定\n",
    "merged_df1['33ラップ判定'] = merged_df1.apply(assign_label, axis=1)\n",
    "\n",
    "# レースタイプラベル列の追加\n",
    "insert_pos = merged_df1.columns.get_loc('33ラップ判定') + 1\n",
    "\n",
    "# '33ラップ判定' の値 → レースタイプ の対応表\n",
    "race_type_map = {\n",
    "    # 瞬発力戦\n",
    "    '瞬+2': '瞬発力戦',\n",
    "    '瞬+1': '瞬発力戦',\n",
    "    '瞬0':  '瞬発力戦',\n",
    "\n",
    "    # 総合力戦\n",
    "    '瞬-1': '総合力戦',\n",
    "    '瞬-2': '総合力戦',\n",
    "    '総':   '総合力戦',\n",
    "    '持-1': '総合力戦',\n",
    "    '持-2': '総合力戦',\n",
    "\n",
    "    # 持久力戦\n",
    "    '持+2': '持久力戦',\n",
    "    '持+1': '持久力戦',\n",
    "    '持+0': '持久力戦',\n",
    "}\n",
    "\n",
    "ref = merged_df1['33ラップ判定']\n",
    "merged_df1.insert(insert_pos, 'レースタイプ', ref.map(race_type_map))\n",
    "\n",
    "# ラベル書き換え用のマッピング辞書\n",
    "label_mapping = {\n",
    "    '持-2': '0T持-2',\n",
    "    '持-1': '0T持-1',\n",
    "    '持0': '0U持0',\n",
    "    '持+1': '0V持+1',\n",
    "    '持+2': '0V持+2',\n",
    "    '瞬-2': '0S瞬-2',\n",
    "    '瞬-1': '0S瞬-1',\n",
    "    '瞬0': '0R瞬0',\n",
    "    '瞬+1': '0Q瞬+1',\n",
    "    '瞬+2': '0Q瞬+2',\n",
    "    '総': '02総'\n",
    "}\n",
    "\n",
    "# 書き換え\n",
    "merged_df1['レース印２'] = merged_df1['33ラップ判定'].replace(label_mapping)\n",
    "\n",
    "# ---ステップ６：レースレベル判定\n",
    "# レースレベル指数\n",
    "# レース強度指数の計算\n",
    "first_load  = merged_df1['通過3F_stdtime1'].fillna(merged_df1['通過3F_stdtime2']) - merged_df1['通過3F']\n",
    "\n",
    "middle_diff1 = merged_df1['中盤ラップ1_stdtime1'].fillna(merged_df1['中盤ラップ1_stdtime2']) - merged_df1['中盤ラップ1']\n",
    "middle_diff2 = merged_df1['中盤ラップ2_stdtime1'].fillna(merged_df1['中盤ラップ2_stdtime2']) - merged_df1['中盤ラップ2']\n",
    "\n",
    "middle_load = pd.concat([middle_diff1, middle_diff2], axis=1).mean(axis=1, skipna=True)\n",
    "\n",
    "last_load   = merged_df1['レース上り3F_stdtime1'].fillna(merged_df1['レース上り3F_stdtime2']) - merged_df1['レース上り3F']\n",
    "spurt_load  = merged_df1['最大加速ラップ_stdtime1'].fillna(merged_df1['最大加速ラップ_stdtime2']) - merged_df1['最大加速ラップ']\n",
    "goal_load   = merged_df1['ゴール前ラップ差_stdtime1'].fillna(merged_df1['ゴール前ラップ差_stdtime2']) - merged_df1['ゴール前ラップ差']\n",
    "\n",
    "merged_df1['レース強度指数'] = (\n",
    "    100\n",
    "    + first_load.fillna(0)\n",
    "    + middle_load.fillna(0)\n",
    "    + last_load.fillna(0)\n",
    "    + spurt_load.fillna(0)\n",
    "    + goal_load.fillna(0)\n",
    "    + merged_df1['馬場補正値'].fillna(0)\n",
    ")\n",
    "\n",
    "# ベース値（Std2優先 → なければ Std1）\n",
    "rating_base = merged_df1['レイティング_stdtime2'].fillna(\n",
    "    merged_df1['レイティング_stdtime1']\n",
    ")\n",
    "speed_base = merged_df1['総合指数_stdtime2'].fillna(\n",
    "    merged_df1['総合指数_stdtime1']\n",
    ")\n",
    "strength_base = merged_df1['レース強度指数_stdtime2'].fillna(\n",
    "    merged_df1['レース強度指数_stdtime1']\n",
    ")\n",
    "\n",
    "# 差分（NaN は 0 扱い）\n",
    "rating_diff = (merged_df1['レイティング平均値'] - rating_base).fillna(0)\n",
    "speed_diff  = (merged_df1['Top3総合指数'] - speed_base).fillna(0)\n",
    "strength_diff = (merged_df1['レース強度指数'] - strength_base).fillna(0)\n",
    "\n",
    "# レースレベル指数算出\n",
    "merged_df1['レースレベル指数'] = (rating_diff + speed_diff + strength_diff + 100).round(1)\n",
    "\n",
    "# レース強度指数：基準タイム１差分\n",
    "merged_df1['レース強度指数上位差分']=merged_df1['レース強度指数']-merged_df1['レース強度指数_stdtime1'].fillna(merged_df1['レース強度指数_stdtime2'])\n",
    "\n",
    "# 差分\n",
    "rl_m2 = (merged_df1['レースレベル指数'] - merged_df1['RL-2_racelevel']).abs()\n",
    "rl_m1 = (merged_df1['レースレベル指数'] - merged_df1['RL-1_racelevel']).abs()\n",
    "rl_0  = (merged_df1['レースレベル指数'] - merged_df1['RL±0_racelevel']).abs()\n",
    "rl_p1 = (merged_df1['レースレベル指数'] - merged_df1['RL+1_racelevel']).abs()\n",
    "rl_p2 = (merged_df1['レースレベル指数'] - merged_df1['RL+2_racelevel']).abs()\n",
    "\n",
    "# 5本を横に並べて「最小の列名」を取る（行ごと）\n",
    "diff_df = pd.concat([rl_m2, rl_m1, rl_0, rl_p1, rl_p2], axis=1)\n",
    "diff_df.columns = [-2, -1, 0, 1, 2]  # そのまま判定値にする\n",
    "\n",
    "# 「基準が無い行」判定（5本すべてNaN）\n",
    "no_ref = diff_df.isna().all(axis=1)\n",
    "\n",
    "# idxminを安定させるため NaN は無限大扱いにして最小を取る\n",
    "band = diff_df.fillna(np.inf).idxmin(axis=1)\n",
    "\n",
    "# レースレベル判定 列を追加\n",
    "insert_pos = merged_df1.columns.get_loc('レースレベル指数') + 1\n",
    "merged_df1.insert(insert_pos, 'レースレベル判定', band.where(~no_ref, np.nan).astype('Int64'))\n",
    "\n",
    "# レースレベル評価 列を追加\n",
    "band_to_grade = {2: 'A', 1: 'B', 0: 'C', -1: 'D', -2: 'E'}\n",
    "insert_pos = merged_df1.columns.get_loc('レースレベル判定') + 1\n",
    "merged_df1.insert(insert_pos, 'レースレベル評価', merged_df1['レースレベル判定'].map(band_to_grade))\n",
    "\n",
    "# レース印３ 列を追加\n",
    "rank_to_label = {'A': '05A', 'B': '07B', 'C': '01C', 'D': '00D', 'E': '03E'}\n",
    "merged_df1['レース印３'] = merged_df1['レースレベル評価'].replace(rank_to_label)\n",
    "\n",
    "# サフィックス付き列を削除\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_stdtime1', '_stdtime2', '_paceindex', '_33lap', '_centralscore1', '_centralscore2', '_racelevel')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "merged_df1 = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "# ---ステップ７：指数系データのcsvファイル保存\n",
    "# 各指数をインポート用ファイルに加工して保存\n",
    "# テン指数\n",
    "imp_df1 = merged_df1[['target_horseid','テン指数']]\n",
    "# 上り指数\n",
    "imp_df2 = merged_df1[['target_horseid','上り指数']]\n",
    "# スピード指数\n",
    "imp_df3 = merged_df1[['target_horseid','スピード指数']]\n",
    "# 総合指数\n",
    "imp_df4 = merged_df1[['target_horseid','総合指数']]\n",
    "# 33ラップ判定\n",
    "imp_df5 = merged_df1[['target_raceid','レース印２']].drop_duplicates('target_raceid')\n",
    "# レースレベル判定\n",
    "imp_df6 = merged_df1[['target_raceid','レース印３']].drop_duplicates('target_raceid')\n",
    "\n",
    "output_df1 = pd.read_csv(output_filepath1, encoding='cp932')\n",
    "output_df2 = pd.read_csv(output_filepath2, encoding='cp932')\n",
    "output_df3 = pd.read_csv(output_filepath3, encoding='cp932')\n",
    "output_df4 = pd.read_csv(output_filepath4, encoding='cp932')\n",
    "output_df5 = pd.read_csv(output_filepath5, encoding='cp932')\n",
    "output_df6 = pd.read_csv(output_filepath6, encoding='cp932')\n",
    "\n",
    "# 結合\n",
    "output_df1 = pd.concat([output_df1, imp_df1], ignore_index=True)\n",
    "output_df2 = pd.concat([output_df2, imp_df2], ignore_index=True)\n",
    "output_df3 = pd.concat([output_df3, imp_df3], ignore_index=True)\n",
    "output_df4 = pd.concat([output_df4, imp_df4], ignore_index=True)\n",
    "output_df5 = pd.concat([output_df5, imp_df5], ignore_index=True)\n",
    "output_df6 = pd.concat([output_df6, imp_df6], ignore_index=True)\n",
    "\n",
    "# 重複削除（最新の行を残す）\n",
    "output_df1 = output_df1.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "output_df2 = output_df2.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "output_df3 = output_df3.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "output_df4 = output_df4.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "output_df5 = output_df5.drop_duplicates(subset=['target_raceid'], keep='last')\n",
    "output_df6 = output_df6.drop_duplicates(subset=['target_raceid'], keep='last')\n",
    "\n",
    "# 保存\n",
    "output_df1.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "output_df2.to_csv(output_filepath2, index=False, encoding='cp932')\n",
    "output_df3.to_csv(output_filepath3, index=False, encoding='cp932')\n",
    "output_df4.to_csv(output_filepath4, index=False, encoding='cp932')\n",
    "output_df5.to_csv(output_filepath5, index=False, encoding='cp932')\n",
    "output_df6.to_csv(output_filepath6, index=False, encoding='cp932')\n",
    "\n",
    "# 年度列を追加して保存\n",
    "# 年度列を追加（target_raceid,target_horseid先頭4桁が年）\n",
    "output_df1['year'] = pd.to_datetime(\n",
    "    output_df1['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df2['year'] = pd.to_datetime(\n",
    "    output_df2['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df3['year'] = pd.to_datetime(\n",
    "    output_df3['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df4['year'] = pd.to_datetime(\n",
    "    output_df4['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df5['year'] = pd.to_datetime(\n",
    "    output_df5['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df6['year'] = pd.to_datetime(\n",
    "    output_df6['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "# 年度別にファイル分割\n",
    "for year, df in output_df1.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir1}First_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df2.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir2}Spurt_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df3.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir3}Speed_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df4.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir4}Total_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df5.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir5}33Lap_Category_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df6.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir6}Race_Level_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "# ---ステップ８：成績データの結合\n",
    "# 成績データの列の並び替え\n",
    "header_df = pd.read_csv(header_filepath, header = None, encoding='cp932')\n",
    "column_list = header_df[0].tolist()\n",
    "merged_df1 = merged_df1[column_list]\n",
    "\n",
    "# マスタ成績ファイルを開いてmerged_df1を縦結合\n",
    "master_df = pd.read_csv(master_filepath, encoding='cp932')\n",
    "\n",
    "# 結合\n",
    "master_df = pd.concat([master_df, merged_df1], ignore_index=True)\n",
    "\n",
    "# 重複削除（最新の行を残す）\n",
    "master_df = master_df.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "\n",
    "# ---ステップ９：馬の持久力/瞬発力タイプ判定をして保存\n",
    "# master_dfをコピーして１~３着だけにする\n",
    "merge_key6 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)','馬場分類']\n",
    "\n",
    "# 馬名も含めて抽出\n",
    "horsetype_df = master_df[master_df['入線順位'].between(1, 3)].copy()\n",
    "horsetype_df = horsetype_df[['target_raceid', '血統登録番号', '馬名', 'PCI3', 'PCI'] + merge_key6].copy()\n",
    "\n",
    "# 基準タイムファイル１から基準PCI3を取ってマージ\n",
    "std1_df = base_time_df1[merge_key6 + ['PCI3_stdtime1']].copy()\n",
    "horsetype_df = pd.merge(horsetype_df, std1_df, on=merge_key6, how='left')\n",
    "\n",
    "# 不要なデータフレームをクリア\n",
    "del std1_df\n",
    "\n",
    "# レース性質（基準比）と、馬のレース内差分を合算\n",
    "# （※この計算式は前回のままでも動きますが、シンプルにするなら horsetype_df['PCI'] - horsetype_df['PCI3_stdtime1'] でも同じ結果です）\n",
    "horsetype_df['基準PCI3差分'] = horsetype_df['PCI3'] - horsetype_df['PCI3_stdtime1']\n",
    "horsetype_df['レースPCI3差分'] = horsetype_df['PCI'] - horsetype_df['PCI3']\n",
    "horsetype_df['PCI判定スコア'] = horsetype_df['基準PCI3差分'] + horsetype_df['レースPCI3差分']\n",
    "\n",
    "# 馬ごとに集計：スコアは「中央値」、馬名は「最後のもの（最新）」を取得\n",
    "# ※ここで horsetype_df 自体が「集計後のデータ」に上書き\n",
    "horsetype_df = horsetype_df.groupby('血統登録番号', as_index=False).agg({\n",
    "    'PCI判定スコア': 'median',\n",
    "    '馬名': 'last'\n",
    "})\n",
    "\n",
    "# 'タイプ' 列を追加して判定（マイナス=持、プラス=瞬）\n",
    "horsetype_df['タイプ'] = ''\n",
    "horsetype_df.loc[horsetype_df['PCI判定スコア'] < 0, 'タイプ'] = '0'\n",
    "horsetype_df.loc[horsetype_df['PCI判定スコア'] > 0, 'タイプ'] = '1'\n",
    "\n",
    "# 今日の日付を yymmdd で作る\n",
    "today_yymmdd = datetime.now().strftime(\"%y%m%d\")\n",
    "\n",
    "# ★「0/1が入った馬だけ」出力（中央値0や判定不能は除外）\n",
    "horsetype_df = horsetype_df[horsetype_df['タイプ'].isin(['0', '1'])].copy()\n",
    "\n",
    "# 登録日\n",
    "horsetype_df['登録日'] = today_yymmdd\n",
    "\n",
    "# 血統登録番号の整形\n",
    "horsetype_df['血統登録番号'] = horsetype_df['血統登録番号'].astype(str).str.strip()\n",
    "\n",
    "# 列順を整えて完了\n",
    "checkhorse_df = horsetype_df[['馬名', 'タイプ', '登録日', '血統登録番号']].copy()\n",
    "\n",
    "# 馬タイプをcsvファイル保存\n",
    "checkhorse_df.to_csv(output_filepath7, index=False, encoding='cp932')\n",
    "\n",
    "# ---ステップ１０：成績データファイルを保存\n",
    "master_df.to_csv(master_filepath, index=False, encoding='cp932')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del base_time_df1\n",
    "del base_time_df2\n",
    "del pace_medians_df\n",
    "del lap33_df\n",
    "del racelevel_df\n",
    "del horsetype_df\n",
    "del master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 過去n走分の特徴量を出力する\n",
    "## 2017~2024年の特徴量を出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] input: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2024_tmp.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\50_SourceCode\\add_past_features.py:948: DtypeWarning: Columns (148) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(cfg.input_path, encoding=\"cp932\")\n",
      "past_numeric_chunks: 100%|██████████| 4/4 [20:34<00:00, 308.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Horse\\horse_past_numeric_snapshot.csv\n",
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Horse\\horse_runningstyle_snapshot.csv\n",
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Horse\\horse_blinker_flags_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "horse_last5: 100%|██████████| 44759/44759 [04:21<00:00, 171.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Horse\\horse_last5_perf_snapshot.csv\n",
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Blinker\\Horse\\blinker_performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blood_keys:  25%|██▌       | 1/4 [00:07<00:23,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Sire\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blood_keys:  50%|█████     | 2/4 [00:11<00:10,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\SireLine\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blood_keys:  75%|███████▌  | 3/4 [00:29<00:11, 11.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Sire_BMS\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blood_keys: 100%|██████████| 4/4 [00:45<00:00, 11.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\SireLine_BMS\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  10%|█         | 1/10 [00:13<02:05, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Breeder\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  20%|██        | 2/10 [00:29<02:01, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Owner\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  30%|███       | 3/10 [00:42<01:36, 13.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Trainer\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  40%|████      | 4/10 [00:49<01:06, 11.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Jockey\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  50%|█████     | 5/10 [01:09<01:12, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Breeder_Owner\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  60%|██████    | 6/10 [01:33<01:10, 17.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Breeder_Trainer\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  70%|███████   | 7/10 [01:58<01:00, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Breeder_Jockey\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  80%|████████  | 8/10 [02:21<00:42, 21.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Owner_Trainer\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  90%|█████████ | 9/10 [02:48<00:22, 22.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Owner_Jockey\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys: 100%|██████████| 10/10 [03:11<00:00, 19.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Trainer_Jockey\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "course_keys:  50%|█████     | 1/2 [00:12<00:12, 12.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Trainer_Course\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "course_keys: 100%|██████████| 2/2 [00:21<00:00, 10.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Jockey_Course\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blinker_rel_keys:  33%|███▎      | 1/3 [00:01<00:03,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Blinker\\Trainer\\blinker_performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blinker_rel_keys:  67%|██████▋   | 2/3 [00:02<00:01,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Blinker\\Jockey\\blinker_performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blinker_rel_keys: 100%|██████████| 3/3 [00:02<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Blinker\\Trainer_Jockey\\blinker_performance_snapshot.csv\n",
      "[info] done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "    \n",
    "script_path = Path(r\"G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\50_SourceCode\\add_past_features.py\")\n",
    "spec = importlib.util.spec_from_file_location(\"add_past_features\", script_path)\n",
    "mod = importlib.util.module_from_spec(spec)\n",
    "\n",
    "sys.modules[spec.name] = mod\n",
    "spec.loader.exec_module(mod)\n",
    "\n",
    "mod.run(\n",
    "    input_path=r\"G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2024_tmp.csv\",\n",
    "    surface_col=\"芝・ダート\",\n",
    "    surface_turf_value=\"芝\",\n",
    "    surface_dirt_value=\"ダート\",\n",
    "    course_label_col=\"コースラベル\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↓アーカイブ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
