{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 成績データファイルを作成する\n",
    "## 元の成績データファイルへ新しい成績データを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/マイドライブ/20_HOBBY/20_KEIBA/10_Data_Source/10_Export_Data/Result_Data/Original/ResultData_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_8332\\272507429.py:26: DtypeWarning: Columns (24,25,101) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master_df = pd.read_csv(master_filepath, encoding='cp932').copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理が完了しました。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "# 使用するファイルパスの指定\n",
    "basedir = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original'\n",
    "filename = 'ResultData_Master_2023.csv'\n",
    "\n",
    "master_filepath = os.path.join(basedir, filename)\n",
    "\n",
    "# ファイル選択ダイアログを表示するための準備\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "root.attributes('-topmost', True) # ダイアログを最前面に出す（隠れるのを防ぐため）\n",
    "\n",
    "merged_filepath = filedialog.askopenfilename(title=\"CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "print(merged_filepath)\n",
    "\n",
    "# ファイルが選択されなかった場合は終了\n",
    "if not merged_filepath:\n",
    "    print(\"ファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# CSVファイルを開く\n",
    "master_df = pd.read_csv(master_filepath, encoding='cp932').copy()\n",
    "merged_df = pd.read_csv(merged_filepath, encoding='cp932').copy()\n",
    "\n",
    "# 開いたファイルの列をリネームする\n",
    "# リネームする列名を定義\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid'\n",
    "}\n",
    "\n",
    "master_df.rename(columns=rename_map, inplace=True)\n",
    "merged_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# master_dfにmerged_dfを縦結合する\n",
    "combined_df = pd.concat([master_df, merged_df], ignore_index=True)\n",
    "\n",
    "# 重複行を削除する（全列が同じ行を削除）\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# master_dfを上書き保存する\n",
    "# ※保存は元のマスターに合わせて cp932 にしています\n",
    "combined_df.to_csv(master_filepath, index=False, encoding='cp932')\n",
    "\n",
    "print(\"処理が完了しました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\4066021823.py:9: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  master_df = pd.read_csv(master_filepath, encoding='cp932')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# 使用するファイルパスの指定\n",
    "basedir = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original'\n",
    "filename = 'ResultData_Master_2023.csv'\n",
    "\n",
    "master_filepath = os.path.join(basedir, filename)\n",
    "\n",
    "master_df = pd.read_csv(master_filepath, encoding='cp932')\n",
    "\n",
    "# 開いたファイルの列をリネームする\n",
    "# リネームする列名を定義\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid'\n",
    "}\n",
    "\n",
    "master_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "# csvファイル保存\n",
    "master_df.to_csv(master_filepath, index=False, encoding='cp932')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追切指数の作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追切指数基準タイムを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\2642273033.py:19: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(master_filepath, encoding='cp932').copy()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\2642273033.py:155: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  course_top20_mean = round(merged_df1.groupby(['コース', '馬場状態']).apply(calculate_top20times_mean), 1).reset_index()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\2642273033.py:156: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  course_top10_mean = round(merged_df1.groupby(['コース', '馬場状態']).apply(calculate_top10times_mean), 1).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了：基準タイムファイル（MAD版）を出力しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# =========================\n",
    "# 設定\n",
    "# =========================\n",
    "output_dir = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\\\'\n",
    "traning_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\50_Training_Comments\\Training_Comments_Master.csv'\n",
    "master_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original\\ResultData_Master_2023.csv'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# =========================\n",
    "# 読み込み\n",
    "# =========================\n",
    "df1 = pd.read_csv(traning_filepath, encoding='cp932').copy()\n",
    "df2 = pd.read_csv(master_filepath, encoding='cp932').copy()\n",
    "\n",
    "# =========================\n",
    "# 前処理\n",
    "# =========================\n",
    "def clean_training_data(df):\n",
    "    df = df.copy()\n",
    "    mask_invalid = df[\"日付\"].astype(str).str.contains(\"■|◇\", na=False)\n",
    "    df = df[~mask_invalid].copy()\n",
    "    \n",
    "    check_cols = [c for c in ['8F','7F','6F','5F(4F)','4F(3F)','3F(2F)'] if c in df.columns]\n",
    "    for c in check_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    \n",
    "    is_not_hill = ~df['コース'].astype(str).str.contains('坂', na=False)\n",
    "    has_10sec_like = np.column_stack([df[c].between(1.0, 19.9) for c in check_cols]).any(axis=1)\n",
    "    \n",
    "    drop_mask = is_not_hill & has_10sec_like\n",
    "    df = df[~drop_mask].copy()\n",
    "    return df\n",
    "\n",
    "df1 = clean_training_data(df1)\n",
    "\n",
    "replace_map = {'南Ｗ': '美Ｗ', '南Ｄ': '美ダ', '南ダ': '美ダ', '南芝': '美芝'}\n",
    "df1['コース'] = df1['コース'].replace(replace_map)\n",
    "df1['馬場状態'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1[\"回り位置\"] = pd.to_numeric(df1[\"回り位置\"], errors=\"coerce\")\n",
    "\n",
    "distance_columns = [col for col in [\"8F\", \"7F\", \"6F\", \"5F(4F)\", \"4F(3F)\", \"3F(2F)\", \"1F\"] if col in df1.columns]\n",
    "\n",
    "for col in distance_columns:\n",
    "    df1[f\"{col}_補\"] = np.nan\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    if not pd.isna(row[\"回り位置\"]):\n",
    "        correction_value = (9 - row[\"回り位置\"]) * 0.1\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "            df1.at[index, f\"{leftmost_col}_補\"] = round(row[leftmost_col] + correction_value, 1)\n",
    "            \n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        df1.at[index, f\"{col}_補\"] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                df1.at[index, f\"{col}_補\"] = row[col]\n",
    "\n",
    "# =========================\n",
    "# マージ\n",
    "# =========================\n",
    "merge_cols = ['target_horseid', 'トラックコード(JV)', '年齢限定(競走種別コード)', 'クラスコード', '入線順位']\n",
    "df2 = df2[merge_cols]\n",
    "\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11: return 'サラブレッド系2歳'\n",
    "    elif race_type == 12: return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13: return 'サラブレッド系3歳以上'\n",
    "    else: return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15: return '新馬・未勝利'\n",
    "    elif class_code == 23: return '1勝クラス'\n",
    "    elif class_code == 43: return '2勝クラス'\n",
    "    elif class_code == 67: return '3勝クラス'\n",
    "    elif class_code >= 114: return 'OP・重賞'\n",
    "    else: return np.nan\n",
    "\n",
    "df2['年齢限定(競走種別コード)'] = df2['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df2['クラスコード'] = df2['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "merged_df1 = pd.merge(df1, df2, on=\"target_horseid\", how=\"inner\")\n",
    "del df1, df2\n",
    "\n",
    "merged_df1 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "time_columns = ['8F_補', '7F_補', '6F_補', '5F(4F)_補', '4F(3F)_補', '3F(2F)_補', '1F_補']\n",
    "\n",
    "# =========================\n",
    "# 基準タイム・MAD計算\n",
    "# =========================\n",
    "\n",
    "# MAD（中央値絶対偏差）計算用関数\n",
    "def robust_mad(x):\n",
    "    return np.median(np.abs(x - np.median(x)))\n",
    "\n",
    "# 並び替え用の列リストを定義\n",
    "mad_columns = [f\"MAD_{c}\" for c in time_columns]\n",
    "\n",
    "# 1. コース・馬場状態ごとの集計 (Median + MAD)\n",
    "course_stats = merged_df1.groupby(['コース', '馬場状態'])[time_columns].agg(['median', robust_mad])\n",
    "\n",
    "new_cols_course = []\n",
    "for col, stat in course_stats.columns:\n",
    "    if stat == 'median':\n",
    "        new_cols_course.append(col)\n",
    "    else:\n",
    "        new_cols_course.append(f\"MAD_{col}\") \n",
    "course_stats.columns = new_cols_course\n",
    "course_stats = course_stats.reset_index().round(2) # 精度確保のため2桁\n",
    "\n",
    "# 列の並び替え\n",
    "course_stats = course_stats[['コース', '馬場状態'] + time_columns + mad_columns]\n",
    "\n",
    "# 2. コース・クラス・馬場状態ごとの集計 (Median + MAD)\n",
    "class_stats = merged_df1.groupby(['コース', 'クラスコード', '馬場状態'])[time_columns].agg(['median', robust_mad])\n",
    "\n",
    "new_cols_class = []\n",
    "for col, stat in class_stats.columns:\n",
    "    if stat == 'median':\n",
    "        new_cols_class.append(col)\n",
    "    else:\n",
    "        new_cols_class.append(f\"MAD_{col}\")\n",
    "class_stats.columns = new_cols_class\n",
    "class_stats = class_stats.reset_index().round(2)\n",
    "\n",
    "# 列の並び替え\n",
    "class_stats = class_stats[['コース', 'クラスコード', '馬場状態'] + time_columns + mad_columns]\n",
    "\n",
    "# 3. 上位20% / 10% の平均\n",
    "def calculate_top20times_mean(group):\n",
    "    top20_threshold = group[time_columns].quantile(0.2)\n",
    "    top20_data = group[time_columns][group[time_columns] <= top20_threshold]\n",
    "    return top20_data.mean()\n",
    "\n",
    "def calculate_top10times_mean(group):\n",
    "    top10_threshold = group[time_columns].quantile(0.1)\n",
    "    top10_data = group[time_columns][group[time_columns] <= top10_threshold]\n",
    "    return top10_data.mean()\n",
    "\n",
    "course_top20_mean = round(merged_df1.groupby(['コース', '馬場状態']).apply(calculate_top20times_mean), 1).reset_index()\n",
    "course_top10_mean = round(merged_df1.groupby(['コース', '馬場状態']).apply(calculate_top10times_mean), 1).reset_index()\n",
    "\n",
    "# =========================\n",
    "# 出力\n",
    "# =========================\n",
    "course_stats.to_csv(f\"{output_dir}traning_std_course.csv\", index=False, encoding=\"cp932\")\n",
    "class_stats.to_csv(f\"{output_dir}traning_std_class.csv\", index=False, encoding=\"cp932\")\n",
    "course_top20_mean.to_csv(f\"{output_dir}traning_std_course_top20.csv\", index=False, encoding=\"cp932\")\n",
    "course_top10_mean.to_csv(f\"{output_dir}traning_std_course_top10.csv\", index=False, encoding=\"cp932\")\n",
    "\n",
    "del merged_df1, course_stats, class_stats, course_top20_mean, course_top10_mean\n",
    "\n",
    "print(\"完了：基準タイムファイル（MAD版）を出力しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 追切指数を算出する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\1744245144.py:24: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(master_filepath,  encoding='cp932').copy()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_24020\\1744245144.py:240: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, merged_unique], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了：追切指数（MAD・ロバスト偏差値版）を出力しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# 読み込みファイルパス\n",
    "# =========================\n",
    "traning_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\50_Training_Comments\\Training_Comments_Master.csv'\n",
    "master_filepath  = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original\\ResultData_Master_2023.csv'\n",
    "\n",
    "# 基準ファイル\n",
    "p_course_median  = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course.csv'\n",
    "p_class_median   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_class.csv'\n",
    "p_course_top20   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course_top20.csv'\n",
    "p_course_top10   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course_top10.csv'\n",
    "\n",
    "# 出力\n",
    "output_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\Training_Score_Master.csv'\n",
    "output_dir       = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\\\'\n",
    "\n",
    "# =========================\n",
    "# 読み込み & 前処理\n",
    "# =========================\n",
    "df1 = pd.read_csv(traning_filepath, encoding='cp932').copy()\n",
    "df2 = pd.read_csv(master_filepath,  encoding='cp932').copy()\n",
    "\n",
    "def clean_training_data(df):\n",
    "    df = df.copy()\n",
    "    mask_invalid = df[\"日付\"].astype(str).str.contains(\"■|◇\", na=False)\n",
    "    df = df[~mask_invalid].copy()\n",
    "    check_cols = [c for c in ['8F','7F','6F','5F(4F)','4F(3F)','3F(2F)'] if c in df.columns]\n",
    "    for c in check_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    is_not_hill = ~df['コース'].astype(str).str.contains('坂', na=False)\n",
    "    has_10sec_like = np.column_stack([df[c].between(10.0, 19.9) for c in check_cols]).any(axis=1)\n",
    "    drop_mask = is_not_hill & has_10sec_like\n",
    "    df = df[~drop_mask].copy()\n",
    "    return df\n",
    "\n",
    "df1 = clean_training_data(df1)\n",
    "\n",
    "replace_map = {'南Ｗ': '美Ｗ', '南Ｄ': '美ダ', '南ダ': '美ダ', '南芝': '美芝'}\n",
    "df1['コース'] = df1['コース'].replace(replace_map)\n",
    "df1['馬場状態'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1[\"回り位置\"] = pd.to_numeric(df1[\"回り位置\"], errors=\"coerce\")\n",
    "\n",
    "distance_columns = [col for col in [\"8F\", \"7F\", \"6F\", \"5F(4F)\", \"4F(3F)\", \"3F(2F)\", \"1F\"] if col in df1.columns]\n",
    "for col in distance_columns:\n",
    "    df1[f\"{col}_補\"] = np.nan\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    if not pd.isna(row[\"回り位置\"]):\n",
    "        correction_value = (9 - row[\"回り位置\"]) * 0.1\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "            df1.at[index, f\"{leftmost_col}_補\"] = round(row[leftmost_col] + correction_value, 1)\n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        df1.at[index, f\"{col}_補\"] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                df1.at[index, f\"{col}_補\"] = row[col]\n",
    "\n",
    "time_columns = [f\"{c}_補\" for c in distance_columns]\n",
    "\n",
    "# =========================\n",
    "# 成績マージ\n",
    "# =========================\n",
    "merge_cols = ['target_horseid', 'トラックコード(JV)', '年齢限定(競走種別コード)', 'クラスコード']\n",
    "df2 = df2[merge_cols]\n",
    "\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11: return 'サラブレッド系2歳'\n",
    "    elif race_type == 12: return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13: return 'サラブレッド系3歳以上'\n",
    "    else: return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15: return '新馬・未勝利'\n",
    "    elif class_code == 23: return '1勝クラス'\n",
    "    elif class_code == 43: return '2勝クラス'\n",
    "    elif class_code == 67: return '3勝クラス'\n",
    "    elif class_code >= 114: return 'OP・重賞'\n",
    "    else: return np.nan\n",
    "\n",
    "df2['年齢限定(競走種別コード)'] = df2['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df2['クラスコード'] = df2['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "merged_df1 = pd.merge(df1, df2, on='target_horseid', how='inner').copy()\n",
    "merged_df1['is_saka'] = merged_df1['コース'].astype(str).str.contains('坂', na=False)\n",
    "\n",
    "# =========================\n",
    "# 基準テーブル読み込み（MAD対応）\n",
    "# =========================\n",
    "def load_and_tag(path, suffix, has_std):\n",
    "    t = pd.read_csv(path, encoding='cp932').copy()\n",
    "    rename_map = {}\n",
    "    for c in time_columns:\n",
    "        if c in t.columns:\n",
    "            rename_map[c] = f\"{c}_{suffix}\"\n",
    "        \n",
    "        # 標準偏差ではなくMADを探す\n",
    "        madc = f\"MAD_{c}\"\n",
    "        if has_std and (madc in t.columns):\n",
    "            rename_map[madc] = f\"MAD_{c}_{suffix}\"\n",
    "    return t.rename(columns=rename_map)\n",
    "\n",
    "df3 = load_and_tag(p_course_median, 'course', True)\n",
    "df4 = load_and_tag(p_class_median,  'class',  True)\n",
    "df5 = load_and_tag(p_course_top20, 'course_20', False)\n",
    "df6 = load_and_tag(p_course_top10, 'course_10', False)\n",
    "\n",
    "key_course = ['コース','馬場状態']\n",
    "key_class  = ['年齢限定(競走種別コード)','クラスコード','コース','馬場状態']\n",
    "\n",
    "def smerge(left, right, keys):\n",
    "    exist_keys = [k for k in keys if (k in left.columns and k in right.columns)]\n",
    "    return pd.merge(left, right, on=exist_keys, how='left')\n",
    "\n",
    "merged_df1 = smerge(merged_df1, df3, key_course)\n",
    "merged_df1 = smerge(merged_df1, df4, key_class)\n",
    "merged_df1 = smerge(merged_df1, df5, key_course)\n",
    "merged_df1 = smerge(merged_df1, df6, key_course)\n",
    "\n",
    "# =========================\n",
    "# 偏差値（ロバスト偏差値計算：MAD使用）\n",
    "# =========================\n",
    "def dev_vec(v, m, mad):\n",
    "    # MADを正規分布の標準偏差相当に変換する定数 1.4826\n",
    "    sigma_est = mad * 1.4826\n",
    "    \n",
    "    ok = (~pd.isna(v)) & (~pd.isna(m)) & (~pd.isna(mad)) & (sigma_est != 0)\n",
    "    \n",
    "    # タイムは小さい方が良いので (Median - Value)\n",
    "    # sigma_est が 0 (全員同じタイム等) の場合は偏差値50とする\n",
    "    return np.where(ok, 50 + 10 * (m - v) / sigma_est, 50)\n",
    "\n",
    "bases_for_dev = ['course', 'class']\n",
    "\n",
    "for c in time_columns:\n",
    "    dev_cols = []\n",
    "    for b in bases_for_dev:\n",
    "        mean_col = f\"{c}_{b}\"\n",
    "        mad_col  = f\"MAD_{c}_{b}\"\n",
    "        colname = f\"偏差値_{c}_{b}\"\n",
    "        \n",
    "        # MADが存在する場合のみ計算\n",
    "        if mad_col in merged_df1.columns:\n",
    "            merged_df1[colname] = dev_vec(merged_df1[c], merged_df1[mean_col], merged_df1[mad_col])\n",
    "            dev_cols.append(colname)\n",
    "\n",
    "    if dev_cols:\n",
    "        merged_df1[f\"偏差値_統合_{c}\"] = merged_df1[dev_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "# 統合偏差値が存在する列のみでスコア計算\n",
    "valid_dev_cols = [f\"偏差値_統合_{c}\" for c in time_columns if f\"偏差値_統合_{c}\" in merged_df1.columns]\n",
    "if valid_dev_cols:\n",
    "    merged_df1['総合偏差値スコア'] = merged_df1[valid_dev_cols].mean(axis=1, skipna=True)\n",
    "else:\n",
    "    merged_df1['総合偏差値スコア'] = 50.0\n",
    "\n",
    "# =========================\n",
    "# 加点（変更なし）\n",
    "# =========================\n",
    "bonus_targets = {'4F': '4F(3F)_補', '2F': '3F(2F)_補', '1F': '1F_補'}\n",
    "\n",
    "def calculate_bonus(value, mean, is_saka, col_short):\n",
    "    if pd.isna(value) or pd.isna(mean): return 0.0\n",
    "    if is_saka:\n",
    "        if col_short == '4F': return 0.5 if value < mean else 0.0\n",
    "        if col_short == '2F': return 1.5 if value < mean else 0.0\n",
    "        if col_short == '1F': return 1.0 if value < mean else 0.0\n",
    "    else:\n",
    "        if col_short == '4F': return 0.5 if value < mean else 0.0\n",
    "        if col_short == '2F': return 1.0 if value < mean else 0.0\n",
    "        if col_short == '1F': return 1.5 if value < mean else 0.0\n",
    "    return 0.0\n",
    "\n",
    "th_sfx_list = ['course_20','course_10']\n",
    "bonus_cols = []\n",
    "for col_short, base_col in bonus_targets.items():\n",
    "    for sfx in th_sfx_list:\n",
    "        th_col = f\"{base_col}_{sfx}\"\n",
    "        if th_col in merged_df1.columns:\n",
    "            out_col = f\"加点_{col_short}_{sfx}\"\n",
    "            merged_df1[out_col] = merged_df1.apply(\n",
    "                lambda r: calculate_bonus(\n",
    "                    r.get(base_col, np.nan), r.get(th_col, np.nan),\n",
    "                    bool(r.get('is_saka', False)), col_short\n",
    "                ), axis=1\n",
    "            )\n",
    "            bonus_cols.append(out_col)\n",
    "\n",
    "merged_df1['総合加点スコア'] = merged_df1[bonus_cols].sum(axis=1, skipna=True) if bonus_cols else 0.0\n",
    "\n",
    "# =========================\n",
    "# 係数・最終指数\n",
    "# =========================\n",
    "def rider_coef(x):\n",
    "    s = '' if pd.isna(x) else str(x)\n",
    "    if '助手' in s: return 1.0\n",
    "    if '見習' in s: return 0.8\n",
    "    return 0.9\n",
    "\n",
    "def leg_coef(x):\n",
    "    s = '' if pd.isna(x) else str(x)\n",
    "    if '馬なり' in s: return 1.1\n",
    "    if ('Ｇ' in s) or ('G' in s) or ('強' in s): return 1.0\n",
    "    if '一杯' in s: return 0.8\n",
    "    if 'ヨレ' in s: return 0.7\n",
    "    if 'バテ' in s: return 0.6\n",
    "    return 0.9\n",
    "\n",
    "merged_df1['騎乗者係数'] = merged_df1['乗り役'].apply(rider_coef)\n",
    "merged_df1['脚色係数']   = merged_df1['脚色'].apply(leg_coef)\n",
    "\n",
    "merged_df1['追切指数'] = (\n",
    "    (merged_df1['総合偏差値スコア'].fillna(50) + merged_df1['総合加点スコア'].fillna(0.0))\n",
    "    * merged_df1['騎乗者係数'].fillna(0.9)\n",
    "    * merged_df1['脚色係数'].fillna(0.9)\n",
    ")\n",
    "\n",
    "merged_df1['追切指数'] = merged_df1['追切指数'].replace([np.inf, -np.inf], np.nan).fillna(1).round(1)\n",
    "\n",
    "# 重複排除\n",
    "merged_unique = merged_df1.loc[merged_df1.groupby('target_horseid')['追切指数'].idxmax()].reset_index(drop=True).copy()\n",
    "merged_unique = merged_unique[['target_horseid','追切指数']].copy()\n",
    "\n",
    "del df1,df2,df3,df4,df5,df6,merged_df1\n",
    "\n",
    "# 保存処理\n",
    "combined_df = pd.read_csv(output_filepath1, encoding='cp932').copy()\n",
    "combined_df = pd.concat([combined_df, merged_unique], ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates(subset='target_horseid', keep='last')\n",
    "combined_df.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "\n",
    "combined_df['year'] = pd.to_datetime(\n",
    "    combined_df['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y', errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "for year, dfy in combined_df.groupby('year'):\n",
    "    dfy.drop(columns='year').to_csv(f'{output_dir}Training_Score_Master_{year}.csv', index=False, encoding='cp932')\n",
    "\n",
    "del combined_df\n",
    "\n",
    "print(\"完了：追切指数（MAD・ロバスト偏差値版）を出力しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基準タイムファイルを出力するコード\n",
    "\n",
    "## ・スピード指数の算出に使うコース別の基準タイムファイルを出力する\n",
    "- 1着馬および1着馬〜3着馬の基準タイム、およびその他タイム系データを格納する\n",
    "- ファイルは2つ出力するが、スピード指数の算出には`00_StandardTimes2_yyyymmdd.csv`を用いる\n",
    "\n",
    "### 処理の概要\n",
    "- 成績CSVファイルを読み込み、コース・距離・競争種別コード・クラスコード・馬場状態でレースデータをグループ化する\n",
    "- 各グループの中央値を基準タイムファイル1とする\n",
    "- 各グループの中で1勝クラス・2勝クラスのデータの平均をとり、それを基準タイムファイル2とする\n",
    "\n",
    "### ステップ\n",
    "1. **CSVファイルの読み込み**\n",
    "   - `pandas`を使って、ある期間の1着馬から3着馬の成績が記録されたCSVファイルを読み込む\n",
    "\n",
    "2. **カテゴリの追加**\n",
    "   - `競争種別コード`と`クラスコード`をもとにレースタイプやクラスカテゴリを新たに分類し、カテゴリカラムを追加\n",
    "   - 馬場状態（良・稍／重・不良）に基づき馬場状態カテゴリを追加\n",
    "\n",
    "3. **タイム系カラムの計算**\n",
    "   - 1着馬から3着馬の走破タイムや3Fの平均を計算して新しいカラムとして追加\n",
    "\n",
    "4. **グループ化して中央値を計算**\n",
    "   - 「場所」、「芝・ダート」、「距離」、「馬場状態」、「競争種別カテゴリ」、「クラスカテゴリ」でグループ化\n",
    "   - 各グループごとのタイム系カラムの中央値を計算し、基準タイムファイル1として保存\n",
    "\n",
    "5. **クラス別フィルタリングと再計算**\n",
    "   - 基準タイムファイル1から「良・稍」と「重・不良」でデータをフィルタリング\n",
    "   - 各フィルタで1勝クラスと2勝クラスの中央値を取得し、その平均をとって基準タイムファイル2とする\n",
    "\n",
    "6. **出力ファイルの生成**\n",
    "   - `00_StandardTimes1_yyyymmdd.csv`（基準タイムファイル1）と`00_StandardTimes2_yyyymmdd.csv`（基準タイムファイル2）を出力\n",
    "   - スピード指数の算出には`00_StandardTimes2_yyyymmdd.csv`を使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:68: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(master_file_path, encoding='cp932')\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:728: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(remove_outliers)\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:1728: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_df1['year'] = pd.to_datetime(\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:1734: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_df2['year'] = pd.to_datetime(\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:1740: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_df3['year'] = pd.to_datetime(\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2686476637.py:1746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  imp_df4['year'] = pd.to_datetime(\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "#---ステップ１：成績データから基準タイムファイルを作成\n",
    "# ファイルパスの指定\n",
    "# 成績データファイルのパス\n",
    "master_file_path = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original\\ResultData_Master_2023.csv'\n",
    "\n",
    "# 成績データにマージするデータファイルのパス\n",
    "# 初角位置ファイルのパス\n",
    "merge_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\70_First_Corner_Position\\First_Corner_Position_Master.csv'\n",
    "# 2角位置ファイルのパス\n",
    "merge_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\80_Second_Corner_Position\\Second_Corner_Position_Master.csv'\n",
    "# 3角位置ファイルのパス\n",
    "merge_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\90_Third_Corner_Position\\Third_Corner_Position_Master.csv'\n",
    "# 4角位置ファイルのパス\n",
    "merge_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\100_Fourth_Corner_Position\\Fourth_Corner_Position_Master.csv'\n",
    "# 上り位置ファイルのパス\n",
    "merge_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\110_Spurt_Position\\Spurt_Position_Master.csv'\n",
    "# 馬場指数ファイルのパス\n",
    "merge_filepath6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\60_Track_Condition\\Track_Condition_Master.csv'\n",
    "# 前半3Fタイムファイルのパス\n",
    "merge_filepath7 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\120_First3F_Lap\\First3F_Lap_Master.csv'\n",
    "# 追切指数ファイルのパス\n",
    "merge_filepath8 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\Training_Score_Master.csv'\n",
    "\n",
    "# 保存先パス\n",
    "# 保存先のファイルパス\n",
    "# 加工後の成績データファイルの保存先パス\n",
    "output_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2024_tmp.csv'\n",
    "\n",
    "# 基準ファイル系\n",
    "# 基準タイムファイル1の保存先パス\n",
    "output_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\StdTime1.csv'\n",
    "# 基準タイムファイル2の保存先パス\n",
    "output_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\StdTime2.csv'\n",
    "# ペース係数ファイルの保存先パス\n",
    "output_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\PaceTime.csv'\n",
    "# 基準33ラップファイルの保存先パス\n",
    "output_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\33Lap.csv'\n",
    "# レースレベル基準ファイルのパス\n",
    "output_filepath6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\RaceLevel.csv'\n",
    "\n",
    "# 馬タイプ分類のファイルパス\n",
    "output_filepath7 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\220_Horse_Type\\Horse_Type_Master.csv'\n",
    "\n",
    "# 指数系\n",
    "# テン指数のディレクトリ\n",
    "output_dir1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\150_First_Score\\\\'\n",
    "# 上り指数のディレクトリ\n",
    "output_dir2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\160_Spurt_Score\\\\'\n",
    "# スピード指数のディレクトリ\n",
    "output_dir3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\170_Speed_Score\\\\'\n",
    "# 総合指数のディレクトリ\n",
    "output_dir4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\180_Total_Score\\\\'\n",
    "# 33ラップ判定のディレクトリ\n",
    "output_dir5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\140_33Lap_Category\\\\'\n",
    "# レースレベル判定のディレクトリ\n",
    "output_dir6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\190_Race_Level\\\\'\n",
    "\n",
    "# 列の並び定義ファイルパス\n",
    "header_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\50_SourceCode\\ResultData_Header.csv'\n",
    "\n",
    "# 成績データファイルとマージファイルの読み込み\n",
    "df1 = pd.read_csv(master_file_path, encoding='cp932')\n",
    "df2 = pd.read_csv(merge_filepath1, encoding='cp932')\n",
    "df3 = pd.read_csv(merge_filepath2, encoding='cp932')\n",
    "df4 = pd.read_csv(merge_filepath3, encoding='cp932')\n",
    "df5 = pd.read_csv(merge_filepath4, encoding='cp932')\n",
    "df6 = pd.read_csv(merge_filepath5, encoding='cp932')\n",
    "df7 = pd.read_csv(merge_filepath6, encoding='cp932')\n",
    "df8 = pd.read_csv(merge_filepath7, encoding='cp932')\n",
    "df9 = pd.read_csv(merge_filepath8, encoding='cp932')\n",
    "\n",
    "#　マージファイルで使用する列だけを定義\n",
    "df2 = df2[['target_horseid','初角サイドポジション']]\n",
    "df3 = df3[['target_horseid','2角サイドポジション']]\n",
    "df4 = df4[['target_horseid','3角サイドポジション']]\n",
    "df5 = df5[['target_horseid','4角サイドポジション']]\n",
    "df6 = df6[['target_horseid','4角位置']]\n",
    "df7 = df7[['target_raceid','馬場指数']]\n",
    "df8 = df8[['target_horseid','前半3F']]\n",
    "df9 = df9[['target_horseid','追切指数']]\n",
    "\n",
    "# カラムの整理\n",
    "# 成績データファイルの列名を変更\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid',\n",
    "    '上り3F': 'レース上り3F',\n",
    "    '上り4F': 'レース上り4F',\n",
    "    '上り5F': 'レース上り5F',\n",
    "    '外部指数1':'レイティング',\n",
    "    '外部指数順1':'レイティング順位',\n",
    "    '外部指数2':'ZI指数',\n",
    "    '外部指数順2':'ZI指数順位',\n",
    "    '外部指数3':'追切指数',\n",
    "    '外部指数順3':'追切指数順位',\n",
    "    '上り3F.1':'上り3F'\n",
    "}\n",
    "\n",
    "# df1の列名に対してrename_mapを適用\n",
    "df1 = df1.rename(columns=rename_map)\n",
    "\n",
    "# キーの型を揃える（数字/ゼロ埋めブレ防止）\n",
    "for c in ['target_horseid', 'target_raceid']:\n",
    "    if c in df1: df1[c] = df1[c].astype(str)\n",
    "for d in [df2, df3, df4, df5, df6, df7, df8, df9]:\n",
    "    for c in ['target_horseid', 'target_raceid']:\n",
    "        if c in d: d[c] = d[c].astype(str)\n",
    "\n",
    "#　種牡馬名のspace削除\n",
    "df1['種牡馬'] = df1['種牡馬'].astype(str).str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# ラベル化する列を追加\n",
    "# コースラベル\n",
    "insert_pos = df1.columns.get_loc('コースグループ名1') + 1\n",
    "df1.insert(insert_pos, 'コースラベル', df1['場所'].astype(str) + '_' + df1['芝・ダート'].astype(str) + '_' + df1['距離'].astype(str) + '_' + df1['トラックコード(JV)'].astype(str))\n",
    "\n",
    "# 父×母の父タイプ名\n",
    "insert_pos = df1.columns.get_loc('母の父タイプ名') + 1\n",
    "df1.insert(insert_pos, '父×母の父タイプ名', df1['種牡馬'].astype(str) + '×' + df1['母の父タイプ名'].astype(str))\n",
    "\n",
    "# 父タイプ名×母の父タイプ名\n",
    "insert_pos = df1.columns.get_loc('父×母の父タイプ名') + 1\n",
    "df1.insert(insert_pos, '父タイプ名×母の父タイプ名', df1['種牡馬タイプ名'].astype(str) + '×' + df1['母の父タイプ名'].astype(str))\n",
    "\n",
    "# 生産者×馬主\n",
    "insert_pos = df1.columns.get_loc('騎手') + 1\n",
    "df1.insert(insert_pos, '生産者×馬主', df1['生産者'].astype(str) + '×' + df1['馬主'].astype(str))\n",
    "\n",
    "# 生産者×調教師\n",
    "insert_pos = df1.columns.get_loc('生産者×馬主') + 1\n",
    "df1.insert(insert_pos, '生産者×調教師', df1['生産者'].astype(str) + '×' + df1['調教師'].astype(str))\n",
    "\n",
    "# 生産者×騎手\n",
    "insert_pos = df1.columns.get_loc('生産者×調教師') + 1\n",
    "df1.insert(insert_pos, '生産者×騎手', df1['生産者'].astype(str) + '×' + df1['騎手'].astype(str))\n",
    "\n",
    "# 馬主×調教師\n",
    "insert_pos = df1.columns.get_loc('生産者×騎手') + 1\n",
    "df1.insert(insert_pos, '馬主×調教師', df1['馬主'].astype(str) + '×' + df1['調教師'].astype(str))\n",
    "\n",
    "# 馬主×騎手\n",
    "insert_pos = df1.columns.get_loc('馬主×調教師') + 1\n",
    "df1.insert(insert_pos, '馬主×騎手', df1['馬主'].astype(str) + '×' + df1['騎手'].astype(str))\n",
    "\n",
    "# 調教師×騎手\n",
    "insert_pos = df1.columns.get_loc('馬主×騎手') + 1\n",
    "df1.insert(insert_pos, '調教師×騎手', df1['調教師'].astype(str) + '×' + df1['騎手'].astype(str))\n",
    "\n",
    "# 調教師×コースラベル\n",
    "insert_pos = df1.columns.get_loc('調教師×騎手') + 1\n",
    "df1.insert(insert_pos, '調教師×コースラベル', df1['調教師'].astype(str) + '×' + df1['コースラベル'].astype(str))\n",
    "\n",
    "# 騎手×コースラベル\n",
    "insert_pos = df1.columns.get_loc('調教師×コースラベル') + 1\n",
    "df1.insert(insert_pos, '騎手×コースラベル', df1['騎手'].astype(str) + '×' + df1['コースラベル'].astype(str))\n",
    "\n",
    "# 配当金額の列を作成する\n",
    "# 列から取り出す金額の数を定義\n",
    "target_cols = {\n",
    "    '単勝配当表記': ('単勝', 1),\n",
    "    '複勝配当表記': ('複勝', 3),\n",
    "    '枠連配当表記': ('枠連', 1),\n",
    "    '馬連配当表記': ('馬連', 1),\n",
    "    'ワイド配当表記': ('ワイド', 3),\n",
    "    '馬単配当表記': ('馬単', 1),\n",
    "    '３連複配当表記': ('３連複', 1),\n",
    "    '３連単配当表記': ('３連単', 1),\n",
    "}\n",
    "\n",
    "# 金額を取り出す正規表現パターン\n",
    "pattern = re.compile(r'[\\\\¥]\\s*([0-9,]+)(?=\\s*(?:\\(|/|$))')\n",
    "\n",
    "def pick_amounts(text, take=1):\n",
    "    if pd.isna(text):\n",
    "        return [np.nan]*take\n",
    "    s = str(text)\n",
    "    found = pattern.findall(s)\n",
    "    nums = []\n",
    "    for x in found:\n",
    "        try:\n",
    "            nums.append(int(x.replace(',', '')))\n",
    "        except:\n",
    "            # 変な値が来てもスルー\n",
    "            continue\n",
    "    # 必要な個数だけ先頭から取り、足りなければNaNで埋める\n",
    "    nums = nums[:take]\n",
    "    if len(nums) < take:\n",
    "        nums += [np.nan]*(take - len(nums))\n",
    "    return nums\n",
    "\n",
    "for src_col, (base_name, take) in target_cols.items():\n",
    "    if src_col not in df1.columns:\n",
    "        # その列が無い場合はスキップ\n",
    "        continue\n",
    "\n",
    "    # 値を取り出す\n",
    "    values = df1[src_col].apply(lambda x: pick_amounts(x, take))\n",
    "\n",
    "    # 1個だけなら「単勝」のように1列、3個なら「複勝1, 複勝2, 複勝3」の3列を作る\n",
    "    if take == 1:\n",
    "        col_name = base_name\n",
    "        df1[col_name] = values.apply(lambda v: v[0] if isinstance(v, list) else np.nan)\n",
    "        # Convert to integer, coercing errors to NaN\n",
    "        df1[col_name] = pd.to_numeric(df1[col_name], errors='coerce').astype('Int64')\n",
    "    else:\n",
    "        for i in range(take):\n",
    "            col_name = f'{base_name}{i+1}'\n",
    "            df1[col_name] = values.apply(lambda v: v[i] if isinstance(v, list) and len(v) > i else np.nan)\n",
    "            # Convert to integer, coercing errors to NaN\n",
    "            df1[col_name] = pd.to_numeric(df1[col_name], errors='coerce').astype('Int64')\n",
    "\n",
    "# 成績データファイルへ対象データをマージする\n",
    "# 初角位置のマージ\n",
    "df1 = pd.merge(df1, df2, on='target_horseid', how='left')\n",
    "# 2角位置のマージ\n",
    "df1 = pd.merge(df1, df3, on='target_horseid', how='left')\n",
    "# 3角位置のマージ\n",
    "df1 = pd.merge(df1, df4, on='target_horseid', how='left')\n",
    "# 4角位置のマージ\n",
    "df1 = pd.merge(df1, df5, on='target_horseid', how='left')\n",
    "# 上り位置のマージ\n",
    "df1 = pd.merge(df1, df6, on='target_horseid', how='left')\n",
    "# 馬場指数のマージ\n",
    "df1 = pd.merge(df1, df7, on='target_raceid', how='left')\n",
    "# 前半3Fのマージ\n",
    "df1 = pd.merge(df1, df8, on='target_horseid', how='left')\n",
    "# 追切指数の代入 とりあえずTrueで上書き\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df9[['target_horseid','追切指数']].dropna(subset=['追切指数']).set_index('target_horseid')\n",
    "left.update(right, overwrite=True)\n",
    "df1 = left.reset_index()\n",
    "\n",
    "# --- 関数群 ---\n",
    "def calculate_33_lap(df1):\n",
    "    \"\"\"距離ごとに33ラップを計算する\"\"\"\n",
    "    rap_33 = []\n",
    "    distance_to_lap_range = {\n",
    "        1000: (0, 3),\n",
    "        1200: (0, 3),\n",
    "        1300: (1, 4),\n",
    "        1400: (1, 4),\n",
    "        1500: (2, 5),\n",
    "        1600: (2, 5),\n",
    "        1700: (3, 6),\n",
    "        1800: (3, 6),\n",
    "        1900: (4, 7),\n",
    "        2000: (4, 7),\n",
    "        2100: (5, 8),\n",
    "        2200: (5, 8),\n",
    "        2300: (6, 9),\n",
    "        2400: (6, 9),\n",
    "        2500: (7, 10),\n",
    "        2600: (7, 10),\n",
    "        2700: (8, 11),\n",
    "        2800: (8, 11),\n",
    "        2900: (9, 12),\n",
    "        3000: (9, 12),\n",
    "        3100: (10, 13),\n",
    "        3200: (10, 13),\n",
    "        3300: (11, 14),\n",
    "        3400: (11, 14),\n",
    "        3500: (12, 15),\n",
    "        3600: (12, 15),\n",
    "    }\n",
    "    for _, row in df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_lap_range:\n",
    "            start, end = distance_to_lap_range[distance]\n",
    "            sum_6to4 = sum(lap_times[start:end])\n",
    "        elif distance == 1150:\n",
    "            sum_6to4 = round(lap_times[0] * 1.25, 1) + lap_times[1] + lap_times[2] if len(lap_times) >= 3 else None\n",
    "        else:\n",
    "            sum_6to4 = None\n",
    "        sum_3to1 = row['レース上り3F'] if 'レース上り3F' in row and not pd.isna(row['レース上り3F']) else None\n",
    "        rap_33_value = sum_6to4 - sum_3to1 if not pd.isna(sum_6to4) and not pd.isna(sum_3to1) else None\n",
    "        rap_33.append(rap_33_value)\n",
    "    df1['33ラップ'] = rap_33\n",
    "    return df1\n",
    "\n",
    "def calculate_middle_lap(df1):\n",
    "    \"\"\"距離ごとに中盤ラップ1・2を計算する\"\"\"\n",
    "    middle_lap1 = []\n",
    "    middle_lap2 = []\n",
    "    distance_to_mid_lap = {\n",
    "        1000: (2, 4, None, None),\n",
    "        1150: (2, 4, None, None),\n",
    "        1200: (2, 4, None, None),\n",
    "        1300: (2, 4, None, None),\n",
    "        1400: (2, 4, None, None),\n",
    "        1500: (3, 5, None, None),\n",
    "        1600: (3, 5, None, None),\n",
    "        1700: (3, 6, None, None),\n",
    "        1800: (3, 6, None, None),\n",
    "        1900: (3, 7, None, None),\n",
    "        2000: (3, 7, None, None),\n",
    "        2100: (3, 5, 5, 8),\n",
    "        2200: (3, 5, 5, 8),\n",
    "        2300: (3, 5, 5, 8),\n",
    "        2400: (3, 6, 6, 9),\n",
    "        2500: (3, 6, 6, 9),\n",
    "        2600: (3, 7, 7, 10),\n",
    "        3000: (3, 8, 8, 12),\n",
    "        3200: (3, 8, 8, 13),\n",
    "        3400: (3, 9, 9, 14),\n",
    "        3600: (3, 9, 9, 15),\n",
    "    }\n",
    "    for _, row in df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_mid_lap:\n",
    "            mid1_start, mid1_end, mid2_start, mid2_end = distance_to_mid_lap[distance]\n",
    "            mid1 = sum(lap_times[mid1_start:mid1_end]) if mid1_start is not None else None\n",
    "            mid2 = sum(lap_times[mid2_start:mid2_end]) if mid2_start is not None else None\n",
    "        else:\n",
    "            mid1 = None\n",
    "            mid2 = None\n",
    "        middle_lap1.append(mid1)\n",
    "        middle_lap2.append(mid2)\n",
    "    df1['中盤ラップ1'] = middle_lap1\n",
    "    df1['中盤ラップ2'] = middle_lap2\n",
    "    return df1\n",
    "\n",
    "def calculate_lap_features(df):\n",
    "    \"\"\"\n",
    "    Lap01～Lap25 を使って\n",
    "      ・最大加速（隣接ラップ差分の最小値）\n",
    "      ・ゴール前ラップ差（ラスト1F - ラスト2F）\n",
    "    を計算して df に列を追加する。\n",
    "    \"\"\"\n",
    "    lap_cols = [f'Lap{str(i).zfill(2)}' for i in range(1, 26)]\n",
    "\n",
    "    def _calc_row(row):\n",
    "        # その馬のラップ一覧（NaN は除外）\n",
    "        laps = []\n",
    "        for c in lap_cols:\n",
    "            if c in row.index and pd.notna(row[c]):\n",
    "                laps.append(row[c])\n",
    "\n",
    "        # ラップが1つ以下ならどっちも計算不能\n",
    "        if len(laps) < 2:\n",
    "            return pd.Series({'最大加速ラップ': np.nan, 'ゴール前ラップ差': np.nan})\n",
    "\n",
    "        laps = np.array(laps, dtype=float)\n",
    "\n",
    "        # 隣り合う差分（後ろ - 前）\n",
    "        diffs = np.diff(laps)   # 例：Lap02-Lap01, Lap03-Lap02, ...\n",
    "\n",
    "        # 最大加速 = 最もマイナスが大きい差分（＝最小値）\n",
    "        max_accel = diffs.min() if len(diffs) > 0 else np.nan\n",
    "\n",
    "        # 終盤ラップ差 = ラスト1F - ラスト2F\n",
    "        last_diff = laps[-1] - laps[-2] if len(laps) >= 2 else np.nan\n",
    "\n",
    "        return pd.Series({\n",
    "            '最大加速ラップ': max_accel if pd.notna(max_accel) else np.nan,\n",
    "            'ゴール前ラップ差': last_diff if pd.notna(last_diff) else np.nan\n",
    "        })\n",
    "\n",
    "    new_cols = df.apply(_calc_row, axis=1)\n",
    "    df['最大加速ラップ'] = new_cols['最大加速ラップ'].round(1)\n",
    "    df['ゴール前ラップ差'] = new_cols['ゴール前ラップ差'].round(1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_days_since_birth(df1):\n",
    "    \"\"\"生後日数を計算する\"\"\"\n",
    "    birth_days = []\n",
    "    for _, row in df1.iterrows():\n",
    "        race_date = datetime.strptime(row['日付S'], '%Y.%m.%d')\n",
    "        birth_str = row['誕生日'].replace(\" \", \"\").replace(\"日\", \"\").replace(\"-\", \"\")\n",
    "        birth_month, birth_day = map(int, birth_str.replace(\"月\", \" \").split())\n",
    "        birth_year = race_date.year - row['年齢']\n",
    "        try:\n",
    "            birth_date = datetime(birth_year, birth_month, birth_day)\n",
    "        except ValueError:\n",
    "            birth_date = datetime(birth_year, 2, 28)\n",
    "        days_old = (race_date - birth_date).days\n",
    "        birth_days.append(days_old)\n",
    "    df1['生後日数'] = birth_days\n",
    "    return df1\n",
    "\n",
    "def calculate_distance_diff(df1):\n",
    "    \"\"\"前走距離との差を計算する\"\"\"\n",
    "    df1['前走距離差'] = df1['距離'] - df1['前走距離']\n",
    "    return df1\n",
    "\n",
    "def calculate_firsthalf_diff(df1):\n",
    "    \"\"\"初角から4角位置の差分を計算\"\"\"\n",
    "    df1['初角_4角差'] = df1.apply(lambda row:\n",
    "        (row['通過1'] - row['通過4']) if pd.notna(row['通過1']) else \\\n",
    "        ((row['通過2'] - row['通過4']) if pd.notna(row['通過2']) else \\\n",
    "        ((row['通過3'] - row['通過4']) if pd.notna(row['通過3']) else np.nan))\n",
    "    , axis=1).fillna(0)\n",
    "    return df1\n",
    "\n",
    "def calculate_goal_diff(df1):\n",
    "    \"\"\"4角から入線順位の差分を計算\"\"\"\n",
    "    # 入線順位を一時的に数値化\n",
    "    rank_num = pd.to_numeric(df1['入線順位'], errors='coerce')\n",
    "\n",
    "    # 有効な順位（1以上）だけを判定するためのマスク\n",
    "    valid_mask = rank_num >= 1\n",
    "\n",
    "    # 出力列だけ作る\n",
    "    df1['4角_入線順位差'] = np.nan\n",
    "\n",
    "    # 有効な行だけ計算\n",
    "    df1.loc[valid_mask, '4角_入線順位差'] = (\n",
    "        pd.to_numeric(df1.loc[valid_mask, '通過4'], errors='coerce')\n",
    "        - rank_num[valid_mask]\n",
    "    )\n",
    "\n",
    "    return df1\n",
    "\n",
    "def calculate_sideposition(df1):\n",
    "    \"\"\"サイドポジションの平均を計算する\"\"\"\n",
    "    cols = ['初角サイドポジション', '2角サイドポジション', '3角サイドポジション', '4角サイドポジション']\n",
    "    df1['サイドポジション平均'] = df1[cols].mean(axis=1)\n",
    "    return df1\n",
    "\n",
    "def calculate_totalprize(df1):\n",
    "    \"\"\"獲得賞金を計算する\"\"\"\n",
    "    df1['獲得賞金'] = df1['賞金'].fillna(0) + df1['付加賞金'].fillna(0)\n",
    "    return df1\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "    \"\"\"タイム表記を秒数に変換\"\"\"\n",
    "    try:\n",
    "        parts = time_str.split(\".\")\n",
    "        if len(parts) == 3:\n",
    "            minutes, seconds, tenths = map(int, parts)\n",
    "            total_seconds = minutes * 60 + seconds + tenths * 0.1\n",
    "        else:\n",
    "            return np.nan\n",
    "        return total_seconds\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def remove_plus_sign(value):\n",
    "    \"\"\"数値データから `+` を削除して変換\"\"\"\n",
    "    try:\n",
    "        return float(str(value).replace(\"+\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def extract_weight(value):\n",
    "    \"\"\"斤量の数値部分だけを抽出\"\"\"\n",
    "    try:\n",
    "        match = re.search(r'\\d+', str(value))\n",
    "        return int(match.group()) if match else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_corner_loss(row):\n",
    "    \"\"\"コーナーロスを計算\"\"\"\n",
    "    corner_positions = [\n",
    "        row.get('初角サイドポジション', 1) - 1,\n",
    "        row.get('2角サイドポジション', 1) - 1,\n",
    "        row.get('3角サイドポジション', 1) - 1,\n",
    "        row.get('4角サイドポジション', 1) - 1\n",
    "    ]\n",
    "    total_distance_loss = sum(corner_positions) * 1.5  # m単位\n",
    "    finish_time_seconds = row['タイムS']\n",
    "    distance_m = row['距離']\n",
    "    if pd.isna(finish_time_seconds) or pd.isna(distance_m) or finish_time_seconds == 0:\n",
    "        return np.nan\n",
    "    avg_speed = distance_m / finish_time_seconds if finish_time_seconds > 0 else np.nan\n",
    "    corner_loss = total_distance_loss / avg_speed if avg_speed > 0 else 0\n",
    "    return round(corner_loss, 2)\n",
    "\n",
    "# 各列の整形\n",
    "# 対象の列を数値変換\n",
    "df1['馬場指数'] = df1['馬場指数'].astype(str).str.extract(r'(-?\\d+)')[0].astype('Int64')\n",
    "df1['レイティング'] = pd.to_numeric(df1['レイティング'], errors='coerce')\n",
    "df1['体重'] = pd.to_numeric(df1['体重'], errors='coerce')\n",
    "df1['Ave-3F'] = pd.to_numeric(df1['Ave-3F'], errors='coerce')\n",
    "df1['上り3F'] = pd.to_numeric(df1['上り3F'], errors='coerce')\n",
    "\n",
    "# 対象の列から記号を除去\n",
    "for col in ['前後3F差', '前後4F差', '前後5F差', '増減']:\n",
    "    df1[col] = df1[col].apply(remove_plus_sign)\n",
    "\n",
    "df1['斤量'] = df1['斤量'].apply(extract_weight)\n",
    "\n",
    "# タイムを秒数に変換\n",
    "df1['タイムS'] = df1['タイムS'].apply(convert_time_to_seconds)\n",
    "df1['-3Fタイム'] = df1['-3Fタイム'].apply(convert_time_to_seconds)\n",
    "\n",
    "# 決め手列を変換(マップにない場合はNanにする)\n",
    "lq_mapping = {\n",
    "    '中団': '差し',\n",
    "    '後方': '追込',\n",
    "}\n",
    "\n",
    "s = df1['決め手'].astype('string').str.strip()\n",
    "df1['決め手'] = s.map(lq_mapping)\n",
    "\n",
    "# 各種計算関数を順次実行\n",
    "# 33ラップの計算\n",
    "df1 = calculate_33_lap(df1)\n",
    "# 中盤ラップ1・2の計算\n",
    "df1 = calculate_middle_lap(df1)\n",
    "# 最大加速ラップ・ゴール前ラップ差の計算\n",
    "df1 = calculate_lap_features(df1)\n",
    "# 生後日数の計算\n",
    "df1 = calculate_days_since_birth(df1)\n",
    "# 前走距離差の計算\n",
    "df1 = calculate_distance_diff(df1)\n",
    "# 初角から4角通過順位差の計算\n",
    "df1 = calculate_firsthalf_diff(df1)\n",
    "# 4角から入線順位差の計算\n",
    "df1 = calculate_goal_diff(df1)\n",
    "# サイドポジション平均値の計算\n",
    "df1 = calculate_sideposition(df1)\n",
    "# 獲得賞金の計算\n",
    "df1 = calculate_totalprize(df1)\n",
    "# 基準斤量の計算\n",
    "df1['基準斤量'] = df1['斤量'] - df1['馬齢斤量差']\n",
    "# RPCI差の計算\n",
    "df1['RPCI差'] = df1['PCI'] - df1['レースPCI']\n",
    "# コーナーロスの計算\n",
    "df1['コーナーロス'] = df1.apply(calculate_corner_loss, axis=1)\n",
    "# 補正走破タイムの計算\n",
    "df1['補正走破タイム'] = df1['タイムS'] - df1['コーナーロス']\n",
    "# スローorハイ関数の計算\n",
    "df1['スローorハイ関数'] = df1['Ave-3F'] - df1['上り3F']\n",
    "\n",
    "# マージ用の列作成処理\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 115:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 範囲定義\n",
    "ranges = [ (-np.inf, -4.6), (-4.6, -3.6), (-3.6, -2.6), (-2.6, -1.6), (-1.6, -0.6), (-0.6, 0.6), (0.6, 1.6), (1.6, 2.6), (2.6, 3.6), (3.6, 4.6), (4.6, np.inf) ]\n",
    "\n",
    "# 区間ラベル\n",
    "def assign_range(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        if i < len(ranges) - 1:\n",
    "            if lower <= value < upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "        else:\n",
    "            # 最終区間（4.6～inf）は右も含める\n",
    "            if lower <= value <= upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "    return np.nan  # 念のため\n",
    "\n",
    "# 馬場分類・競走種別・クラス分類・スローor関数範囲の列を作成する\n",
    "df1['馬場分類'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1['競走種別'] = df1['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df1['クラス分類'] = df1['クラスコード'].apply(categorize_class_code)\n",
    "df1['スローorハイ関数範囲'] = df1['スローorハイ関数'].apply(assign_range)\n",
    "\n",
    "# --- 集計設定 ---\n",
    "agg_cols1 = {\n",
    "    'レースPCI': 'median',\n",
    "    'PCI3': 'median',\n",
    "    '通過3F': 'median',\n",
    "    '通過4F': 'median',\n",
    "    '通過5F': 'median',\n",
    "    'レース上り3F': 'median',\n",
    "    'レース上り4F': 'median',\n",
    "    'レース上り5F': 'median',\n",
    "    '中盤ラップ1': 'median',\n",
    "    '中盤ラップ2': 'median',\n",
    "    '33ラップ': 'median',\n",
    "    '最大加速ラップ': 'median',\n",
    "    'ゴール前ラップ差': 'median',\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング順位': 'median',\n",
    "    'ZI指数': 'median',\n",
    "    'ZI指数順位': 'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    'PCI': 'median',\n",
    "    'RPCI差': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '補正タイム': 'median',\n",
    "    '補9': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '初角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "agg_cols2 = {\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング順位': 'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    'ZI指数': 'median',\n",
    "    'ZI指数順位': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    'PCI': 'median',\n",
    "    'RPCI差': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '補正タイム': 'median',\n",
    "    '補9': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '初角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "# --- 基準タイム算出処理1 ---\n",
    "\n",
    "# 1勝クラス・2勝クラスのみ対象\n",
    "base_df1 = df1[df1['クラスコード'].isin([23, 43])].copy()\n",
    "\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops1 = base_df1[base_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st1 = base_df1[base_df1['入線順位'] == 1].copy()\n",
    "\n",
    "# クラス分類の統一\n",
    "df_tops1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "df_1st1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "\n",
    "# グループ化キー\n",
    "group_cols1 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)','馬場分類', 'クラス分類']\n",
    "\n",
    "# --- 集計処理 ---\n",
    "base_time_tops1 = df_tops1.groupby(group_cols1, dropna=False).agg(agg_cols1).reset_index()\n",
    "base_time_1st1 = df_1st1.groupby(group_cols1, dropna=False).agg(agg_cols2).reset_index()\n",
    "base_time_1st1 = base_time_1st1.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "\n",
    "# --- 結合 ---\n",
    "base_time_df1 = pd.merge(base_time_tops1, base_time_1st1, on=group_cols1, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df1['距離係数'] = (1 / base_time_df1['タイムS']) * 100\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "\n",
    "df_tops2 = df1[df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st2 = df1[df1['入線順位'] == 1].copy()\n",
    "\n",
    "# グループ化キー\n",
    "group_cols2 = ['場所', '芝・ダート', '距離','トラックコード(JV)', '競走種別', 'クラス分類', '馬場分類']\n",
    "\n",
    "base_time_tops2 = df_tops2.groupby(group_cols2).agg(agg_cols1).reset_index()\n",
    "base_time_1st2 = df_1st2.groupby(group_cols2).agg(agg_cols2).reset_index()\n",
    "base_time_1st2 = base_time_1st2.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "base_time_df2 = pd.merge(base_time_tops2, base_time_1st2, on=group_cols2, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df2['距離係数'] = (1 / base_time_df2['タイムS']) * 100\n",
    "\n",
    "# --- ペース係数算出処理 ---\n",
    "\n",
    "# 外れ値除外（IQR）\n",
    "def remove_outliers(group):\n",
    "    Q1 = group['タイムS'].quantile(0.25)\n",
    "    Q3 = group['タイムS'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return group[(group['タイムS'] >= lower_bound) & (group['タイムS'] <= upper_bound)]\n",
    "\n",
    "# グルーピング＆IQR除外\n",
    "pace_df = (\n",
    "    df1.groupby(['場所', '芝・ダート', '距離','トラックコード(JV)'])\n",
    "       .apply(remove_outliers)\n",
    "       .reset_index(drop=True)\n",
    "       .copy()\n",
    ")\n",
    "\n",
    "# 区間別の中央値（タイムS & スローorハイ関数）\n",
    "pace_medians_df = pace_df.groupby(\n",
    "    ['場所', '芝・ダート', '距離','トラックコード(JV)', 'スローorハイ関数範囲']\n",
    ").agg({\n",
    "    'タイムS': 'median',\n",
    "    'スローorハイ関数': 'median'\n",
    "}).reset_index()\n",
    "\n",
    "# --- ベースライン作成 ---\n",
    "# 優先：-0.6～0.6（中庸帯）\n",
    "# 代用：0.6～1.6 / -1.6～-0.6 の平均 → どちらか片方だけでも可\n",
    "baseline_medians = {}\n",
    "for (location, turf_dirt, distance,track_code), group_df in pace_medians_df.groupby(['場所', '芝・ダート', '距離','トラックコード(JV)']):\n",
    "    baseline_row = group_df[group_df['スローorハイ関数範囲'] == '-0.6～0.6']\n",
    "    if not baseline_row.empty:\n",
    "        baseline_median = float(baseline_row['タイムS'].iloc[0])\n",
    "    else:\n",
    "        range_negative = group_df[group_df['スローorハイ関数範囲'] == '-1.6～-0.6']\n",
    "        range_positive = group_df[group_df['スローorハイ関数範囲'] == '0.6～1.6']\n",
    "        if not range_negative.empty and not range_positive.empty:\n",
    "            baseline_median = (float(range_negative['タイムS'].median()) +\n",
    "                               float(range_positive['タイムS'].median())) / 2.0\n",
    "        elif not range_negative.empty:\n",
    "            baseline_median = float(range_negative['タイムS'].median())\n",
    "        elif not range_positive.empty:\n",
    "            baseline_median = float(range_positive['タイムS'].median())\n",
    "        else:\n",
    "            baseline_median = np.nan\n",
    "    baseline_medians[(location, turf_dirt, distance,track_code)] = baseline_median\n",
    "\n",
    "# ベースラインとの差（スローorハイ関数差指数）\n",
    "def calculate_difference(row):\n",
    "    key = (row['場所'], row['芝・ダート'], row['距離'],row['トラックコード(JV)'])\n",
    "    baseline_time = baseline_medians.get(key, np.nan)\n",
    "    return row['タイムS'] - baseline_time if not pd.isna(baseline_time) else np.nan\n",
    "\n",
    "pace_medians_df['スローorハイ関数差指数'] = pace_medians_df.apply(calculate_difference, axis=1)\n",
    "\n",
    "# 係数計算（0除算・NaN安全＋クリップ）\n",
    "def calculate_pace_adjustment_coefficient(row):\n",
    "    val = row['スローorハイ関数']\n",
    "    diff = row['スローorハイ関数差指数']\n",
    "    if pd.notna(val) and val != 0 and pd.notna(diff):\n",
    "        coefficient = round(diff / val, 2)\n",
    "        return float(np.clip(coefficient, -3, 3))\n",
    "    return 0.0\n",
    "\n",
    "pace_medians_df['ペース補正係数'] = pace_medians_df.apply(calculate_pace_adjustment_coefficient, axis=1)\n",
    "\n",
    "# --- 基準33ラップ算出処理 ---\n",
    "\n",
    "lap33_df = (\n",
    "    df1\n",
    "      .dropna(subset=['33ラップ'])  # まず欠損を除外\n",
    "      .groupby(['場所', '芝・ダート', '距離', 'トラックコード(JV)'], dropna=False)['33ラップ']\n",
    "      .agg(['mean', 'std'])  # mean と std を同時に集計\n",
    "      .reset_index()\n",
    ").copy()\n",
    "\n",
    "# 近似Zスコア用の基準値を計算\n",
    "lap33_df['33ラップ±0'] = lap33_df['mean'].round(2)\n",
    "lap33_df['33ラップ+1'] = (lap33_df['mean'] + lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ-1'] = (lap33_df['mean'] - lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ+2'] = (lap33_df['mean'] + 2 * lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ-2'] = (lap33_df['mean'] - 2 * lap33_df['std']).round(2)\n",
    "\n",
    "# 必要なカラムだけ残す\n",
    "lap33_df = lap33_df[\n",
    "    ['場所', '芝・ダート', '距離', 'トラックコード(JV)',\n",
    "     '33ラップ-2', '33ラップ-1', '33ラップ±0', '33ラップ+1', '33ラップ+2',\n",
    "     'mean', 'std']\n",
    "]\n",
    "\n",
    "#---ステップ２：成績データへ指数の追加\n",
    "# 共通関数：参照側DFのキー以外の列にサフィックスを付ける\n",
    "def prepare_ref_df(df_ref, merge_keys, suffix):\n",
    "    \"\"\"\n",
    "    マージ用の参照DFの列名に suffix を付ける（キー列以外すべて）\n",
    "    \"\"\"\n",
    "    df_ref = df_ref.copy()\n",
    "    rename_map = {\n",
    "        c: f\"{c}{suffix}\"\n",
    "        for c in df_ref.columns\n",
    "        if c not in merge_keys\n",
    "    }\n",
    "    df_ref = df_ref.rename(columns=rename_map)\n",
    "    return df_ref\n",
    "\n",
    "# マージキー\n",
    "merge_key1 = ['場所','芝・ダート','距離','トラックコード(JV)','馬場分類']\n",
    "merge_key2 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類','馬場分類']\n",
    "merge_key3 = ['場所','芝・ダート','距離','トラックコード(JV)','スローorハイ関数範囲']\n",
    "merge_key4 = ['場所','芝・ダート','距離','トラックコード(JV)']\n",
    "\n",
    "# 参照側の列名にsuffixを付与\n",
    "ref_df1 = prepare_ref_df(base_time_df1, merge_key1, '_stdtime1').copy()\n",
    "ref_df2 = prepare_ref_df(base_time_df2, merge_key2, '_stdtime2').copy()\n",
    "ref_df3 = prepare_ref_df(pace_medians_df, merge_key3, '_paceindex').copy()\n",
    "ref_df4 = prepare_ref_df(lap33_df, merge_key4, '_33lap').copy()\n",
    "\n",
    "# df1へその他データフレームをマージ\n",
    "merged_df1 = pd.merge(df1, ref_df1, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, ref_df2, on=merge_key2, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, ref_df3, on=merge_key3, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, ref_df4, on=merge_key4, how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del df1, ref_df1, ref_df2, ref_df3, ref_df4\n",
    "\n",
    "# 各指数算出の前処理\n",
    "# 基準タイム/距離係数のベース列を作る（Std1優先、なければStd2）\n",
    "base_time = merged_df1['タイムS_stdtime1'].fillna(merged_df1['タイムS_stdtime2'])\n",
    "dist_coef = merged_df1['距離係数_stdtime1'].fillna(merged_df1['距離係数_stdtime2'])\n",
    "\n",
    "# 基準タイム差（秒）：基準タイム - 補正走破タイム\n",
    "base_time_diff = base_time - merged_df1['補正走破タイム']\n",
    "\n",
    "# 基準タイム差×距離係数\n",
    "speed_core = base_time_diff * dist_coef\n",
    "\n",
    "# 平均3F補正値\n",
    "ave3f_base = merged_df1['Ave-3F_stdtime1'].fillna(merged_df1['Ave-3F_stdtime2'])\n",
    "revi_Ave3F = ave3f_base - merged_df1['Ave-3F']\n",
    "\n",
    "# 斤量補正値\n",
    "revi_weight = merged_df1['斤量'] - merged_df1['基準斤量']\n",
    "\n",
    "# クラス補正値（Std1が存在する行だけ有効。Std2代用行では0）\n",
    "# ※ Std1が無い = その条件の1・2勝基準が作れない想定なので、クラス補正は入れない\n",
    "revi_class = (merged_df1['タイムS_stdtime1'] - merged_df1['タイムS_stdtime2']).where(\n",
    "    merged_df1['タイムS_stdtime1'].notna(), 0\n",
    ")\n",
    "\n",
    "# ペース補正値\n",
    "revi_pace = merged_df1['スローorハイ関数'] * merged_df1['ペース補正係数_paceindex']\n",
    "\n",
    "# 馬場指数秒数換算\n",
    "merged_df1['馬場補正値'] = merged_df1['馬場指数'] / 10\n",
    "\n",
    "# 初角位置\n",
    "merged_df1['初角位置'] = (\n",
    "    merged_df1['通過1']\n",
    "      .fillna(merged_df1['通過2'])\n",
    "      .fillna(merged_df1['通過3'])\n",
    "      .fillna(merged_df1['通過4'])\n",
    ")\n",
    "\n",
    "# テン指数の計算\n",
    "merged_df1['テン指数'] = round((\n",
    "(merged_df1['前半3F_stdtime1'].fillna(merged_df1['前半3F_stdtime2']) - merged_df1['前半3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数'] - merged_df1['初角位置'] + 1) / merged_df1['頭数']) # 初角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# 上り指数の計算\n",
    "merged_df1['上り指数'] = round((\n",
    "(merged_df1['上り3F_stdtime1'].fillna(merged_df1['上り3F_stdtime2']) - merged_df1['上り3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数']) - merged_df1['入線順位'] + 1) / merged_df1['頭数'] # 着順評価\n",
    "+ (merged_df1['通過4'] - merged_df1['入線順位']) / merged_df1['頭数'] # ポジション押し上げ力評価\n",
    "+ (merged_df1['頭数'] - merged_df1['通過4'] + 1) / merged_df1['頭数'] # 4角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# スピード指数の計算 ---\n",
    "merged_df1['スピード指数'] = (\n",
    "    (\n",
    "        speed_core\n",
    "        + merged_df1['馬場補正値'].fillna(0)\n",
    "        + revi_Ave3F.fillna(0)\n",
    "        + revi_weight.fillna(0)\n",
    "        + revi_class.fillna(0)\n",
    "        + revi_pace.fillna(0)\n",
    "        + 100\n",
    "    )\n",
    "    .round(1)\n",
    "    .where(speed_core.notna() & (speed_core != 0))\n",
    ")\n",
    "\n",
    "# 総合指数の計算\n",
    "merged_df1['総合指数'] = merged_df1[['スピード指数', '補正タイム', '補9']].mean(axis=1).round(1)\n",
    "\n",
    "# 総合指数の代表値(1着～3着)をdf1へ追加\n",
    "central_score_df1 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "central_score_df1 = central_score_df1.groupby('target_raceid' ,as_index = False)['総合指数'].mean()\n",
    "central_score_df1.rename(columns={'総合指数': 'Top3総合指数'}, inplace=True)\n",
    "central_score_df1['Top3総合指数'] = round(central_score_df1['Top3総合指数'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df1, on='target_raceid', how='left',suffixes=('', '_centralscore1')).copy()\n",
    "\n",
    "# レイティングの平均値を成績データへ追加\n",
    "merged_df1['レイティング'] = pd.to_numeric(merged_df1['レイティング'], errors='coerce')\n",
    "central_score_df2 = merged_df1.groupby('target_raceid' ,as_index = False)['レイティング'].mean().copy()\n",
    "central_score_df2.rename(columns={'レイティング': 'レイティング平均値'}, inplace=True)\n",
    "central_score_df2['レイティング平均値'] = round(central_score_df2['レイティング平均値'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df2, on='target_raceid', how='left' ,suffixes=('', '_centralscore2')).copy()\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del central_score_df1, central_score_df2\n",
    "\n",
    "# 各指数の偏差値を計算\n",
    "def deviation_in_race(series):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    if pd.isna(std) or std == 0:\n",
    "        return pd.Series(np.nan, index=series.index)\n",
    "    return ((series - mean) / std * 10 + 50)\n",
    "\n",
    "# レース内偏差値\n",
    "merged_df1['レイティング偏差値'] = (merged_df1.groupby('target_raceid')['レイティング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['ZI指数偏差値'] = (merged_df1.groupby('target_raceid')['ZI指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['追切指数偏差値'] = (merged_df1.groupby('target_raceid')['追切指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['マイニング偏差値'] = (merged_df1.groupby('target_raceid')['マイニング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['対戦型マイニング偏差値'] = (merged_df1.groupby('target_raceid')['対戦型マイニング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['前半3F偏差値'] = merged_df1.groupby('target_raceid')['前半3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['上り3F偏差値'] = merged_df1.groupby('target_raceid')['上り3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['Ave-3F偏差値'] = merged_df1.groupby('target_raceid')['Ave-3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['テン指数偏差値'] = (merged_df1.groupby('target_raceid')['テン指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['上り指数偏差値'] = (merged_df1.groupby('target_raceid')['上り指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['スピード指数偏差値'] = (merged_df1.groupby('target_raceid')['スピード指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['総合指数偏差値'] = (merged_df1.groupby('target_raceid')['総合指数'].transform(deviation_in_race).round(1))\n",
    "\n",
    "# レース内順位（dense）\n",
    "merged_df1['前半3F順位'] = (merged_df1.groupby('target_raceid')['前半3F'].rank(ascending=True, method='dense').astype('Int64'))\n",
    "merged_df1['テン指数順位'] = (merged_df1.groupby('target_raceid')['テン指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['上り指数順位'] = (merged_df1.groupby('target_raceid')['上り指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['Ave-3F順位'] = (merged_df1.groupby('target_raceid')['Ave-3F'].rank(ascending=True, method='dense').astype('Int64'))\n",
    "merged_df1['スピード指数順位'] = (merged_df1.groupby('target_raceid')['スピード指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['総合指数順位'] = (merged_df1.groupby('target_raceid')['総合指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "\n",
    "# 順位分布の計算\n",
    "merged_df1['レイティング順位分布'] = (merged_df1['レイティング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['ZI指数順位分布'] = (merged_df1['ZI指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['追切指数順位分布'] = (merged_df1['追切指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['マイニング順位分布'] = (merged_df1['マイニング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['対戦型マイニング順位分布'] = (merged_df1['対戦型マイニング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['前半3F順位分布'] = (merged_df1['前半3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['テン指数順位分布'] = (merged_df1['テン指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['上り3F順位分布'] = (merged_df1['上り3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['上り指数順位分布'] = (merged_df1['上り指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['Ave-3F順位分布'] = (merged_df1['Ave-3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['スピード指数順位分布'] = (merged_df1['スピード指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['総合指数順位分布'] = (merged_df1['総合指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "\n",
    "# 33ラップ判定用関数\n",
    "def assign_label(row):\n",
    "    lap_value = row['33ラップ']\n",
    "    if pd.isna(lap_value):\n",
    "        return np.nan\n",
    "\n",
    "    candidates = {\n",
    "        -2: row['33ラップ-2_33lap'],\n",
    "        -1: row['33ラップ-1_33lap'],\n",
    "         0: row['33ラップ±0_33lap'],\n",
    "         1: row['33ラップ+1_33lap'],\n",
    "         2: row['33ラップ+2_33lap'],\n",
    "    }\n",
    "\n",
    "    # 参照側が全部NaNなら判定不能\n",
    "    if all(pd.isna(v) for v in candidates.values()):\n",
    "        return np.nan\n",
    "\n",
    "    # 差分（絶対値）が最小のスケールを選ぶ\n",
    "    best_scale = min(\n",
    "        candidates.keys(),\n",
    "        key=lambda k: abs(lap_value - candidates[k]) if pd.notna(candidates[k]) else np.inf\n",
    "    )\n",
    "\n",
    "    # 0スケール\n",
    "    if best_scale == 0:\n",
    "        if lap_value < 0:\n",
    "            return '持0'\n",
    "        elif lap_value > 0:\n",
    "            return '瞬0'\n",
    "        else:\n",
    "            return '総'\n",
    "\n",
    "    prefix = '瞬' if lap_value > 0 else '持'\n",
    "    suffix = f'+{best_scale}' if best_scale > 0 else f'{best_scale}'\n",
    "    return prefix + suffix\n",
    "\n",
    "# 33ラップを判定\n",
    "merged_df1['33ラップ判定'] = merged_df1.apply(assign_label, axis=1)\n",
    "\n",
    "# レースタイプラベル列の追加\n",
    "insert_pos = merged_df1.columns.get_loc('33ラップ判定') + 1\n",
    "\n",
    "# '33ラップ判定' の値 → レースタイプ の対応表\n",
    "race_type_map = {\n",
    "    # 瞬発力戦\n",
    "    '瞬+2': '瞬発力戦',\n",
    "    '瞬+1': '瞬発力戦',\n",
    "    '瞬0':  '瞬発力戦',\n",
    "\n",
    "    # 総合力戦\n",
    "    '瞬-1': '総合力戦',\n",
    "    '瞬-2': '総合力戦',\n",
    "    '総':   '総合力戦',\n",
    "    '持-1': '総合力戦',\n",
    "    '持-2': '総合力戦',\n",
    "\n",
    "    # 持久力戦\n",
    "    '持+2': '持久力戦',\n",
    "    '持+1': '持久力戦',\n",
    "    '持+0': '持久力戦',\n",
    "}\n",
    "\n",
    "ref = merged_df1['33ラップ判定']\n",
    "merged_df1.insert(insert_pos, 'レースタイプ', ref.map(race_type_map))\n",
    "\n",
    "# ラベル書き換え用のマッピング辞書\n",
    "label_mapping = {\n",
    "    '持-2': '0T持-2',\n",
    "    '持-1': '0T持-1',\n",
    "    '持0': '0U持0',\n",
    "    '持+1': '0V持+1',\n",
    "    '持+2': '0V持+2',\n",
    "    '瞬-2': '0S瞬-2',\n",
    "    '瞬-1': '0S瞬-1',\n",
    "    '瞬0': '0R瞬0',\n",
    "    '瞬+1': '0Q瞬+1',\n",
    "    '瞬+2': '0Q瞬+2',\n",
    "    '総': '02総'\n",
    "}\n",
    "\n",
    "# 書き換え\n",
    "merged_df1['レース印２'] = merged_df1['33ラップ判定'].replace(label_mapping)\n",
    "\n",
    "# レース強度指数の計算\n",
    "first_load  = merged_df1['通過3F_stdtime1'].fillna(merged_df1['通過3F_stdtime2']) - merged_df1['通過3F']\n",
    "\n",
    "middle_diff1 = merged_df1['中盤ラップ1_stdtime1'].fillna(merged_df1['中盤ラップ1_stdtime2']) - merged_df1['中盤ラップ1']\n",
    "middle_diff2 = merged_df1['中盤ラップ2_stdtime1'].fillna(merged_df1['中盤ラップ2_stdtime2']) - merged_df1['中盤ラップ2']\n",
    "\n",
    "middle_load = pd.concat([middle_diff1, middle_diff2], axis=1).mean(axis=1, skipna=True)\n",
    "\n",
    "last_load   = merged_df1['レース上り3F_stdtime1'].fillna(merged_df1['レース上り3F_stdtime2']) - merged_df1['レース上り3F']\n",
    "spurt_load  = merged_df1['最大加速ラップ_stdtime1'].fillna(merged_df1['最大加速ラップ_stdtime2']) - merged_df1['最大加速ラップ']\n",
    "goal_load   = merged_df1['ゴール前ラップ差_stdtime1'].fillna(merged_df1['ゴール前ラップ差_stdtime2']) - merged_df1['ゴール前ラップ差']\n",
    "\n",
    "merged_df1['レース強度指数'] = (\n",
    "    100\n",
    "    + first_load.fillna(0)\n",
    "    + middle_load.fillna(0)\n",
    "    + last_load.fillna(0)\n",
    "    + spurt_load.fillna(0)\n",
    "    + goal_load.fillna(0)\n",
    "    + merged_df1['馬場補正値'].fillna(0)\n",
    ")\n",
    "\n",
    "# サフィックス付き列を削除\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_1着','_stdtime1', '_stdtime2', '_paceindex', '_33lap', '_centralscore1', '_centralscore2')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "merged_df1 = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "#---ステップ３：基準タイムファイル１・２の再集計\n",
    "# --- 集計設定 ---\n",
    "agg_cols3 = {\n",
    "    'レースPCI': 'median',\n",
    "    'PCI3': 'median',\n",
    "    '通過3F': 'median',\n",
    "    '通過4F': 'median',\n",
    "    '通過5F': 'median',\n",
    "    'レース上り3F': 'median',\n",
    "    'レース上り4F': 'median',\n",
    "    'レース上り5F': 'median',\n",
    "    '中盤ラップ1': 'median',\n",
    "    '中盤ラップ2': 'median',\n",
    "    '33ラップ': 'median',\n",
    "    '最大加速ラップ': 'median',\n",
    "    'ゴール前ラップ差': 'median',\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング偏差値': 'median',\n",
    "    'レイティング順位': 'median',\n",
    "    'レイティング順位分布':'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数偏差値': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    '追切指数順位分布': 'median',\n",
    "    'ZI指数': 'median',\n",
    "    'ZI指数順位': 'median',\n",
    "    'ZI指数偏差値': 'median',\n",
    "    'ZI指数順位分布': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング偏差値': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    'マイニング順位分布': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング偏差値': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    '対戦型マイニング順位分布': 'median',\n",
    "    'PCI': 'median',\n",
    "    'RPCI差': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '前半3F偏差値': 'median',\n",
    "    '前半3F順位': 'median',\n",
    "    '前半3F順位分布': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F偏差値': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    '上り3F順位分布': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    'Ave-3F偏差値': 'median',\n",
    "    'Ave-3F順位': 'median',\n",
    "    'Ave-3F順位分布': 'median',\n",
    "    '-3F差': 'median',\n",
    "    'テン指数': 'median',\n",
    "    'テン指数偏差値': 'median',\n",
    "    'テン指数順位': 'median',\n",
    "    'テン指数順位分布': 'median',\n",
    "    '上り指数': 'median',\n",
    "    '上り指数偏差値': 'median',\n",
    "    '上り指数順位': 'median',\n",
    "    '上り指数順位分布': 'median',\n",
    "    '補正タイム': 'median',\n",
    "    '補9': 'median',\n",
    "    'スピード指数': 'median',\n",
    "    'スピード指数偏差値': 'median',\n",
    "    'スピード指数順位': 'median',\n",
    "    'スピード指数順位分布': 'median',\n",
    "    '総合指数': 'median',\n",
    "    '総合指数偏差値': 'median',\n",
    "    '総合指数順位': 'median',\n",
    "    '総合指数順位分布': 'median',\n",
    "    'レース強度指数': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '初角位置': 'median',\n",
    "    '初角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "agg_cols4 = {\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング偏差値': 'median',\n",
    "    'レイティング順位': 'median',\n",
    "    'レイティング順位分布':'median',\n",
    "    'ZI指数': 'median',\n",
    "    'ZI指数順位': 'median',\n",
    "    'ZI指数偏差値': 'median',\n",
    "    'ZI指数順位分布': 'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    '追切指数偏差値': 'median',\n",
    "    '追切指数順位分布': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング偏差値': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    'マイニング順位分布': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング偏差値': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    '対戦型マイニング順位分布': 'median',\n",
    "    'PCI': 'median',\n",
    "    'RPCI差': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '前半3F偏差値': 'median',\n",
    "    '前半3F順位': 'median',\n",
    "    '前半3F順位分布': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F偏差値': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    '上り3F順位分布': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    'Ave-3F偏差値': 'median',\n",
    "    'Ave-3F順位': 'median',\n",
    "    'Ave-3F順位分布': 'median',\n",
    "    '-3F差': 'median',\n",
    "    'テン指数': 'median',\n",
    "    'テン指数偏差値': 'median',\n",
    "    'テン指数順位': 'median',\n",
    "    'テン指数順位分布': 'median',\n",
    "    '上り指数': 'median',\n",
    "    '上り指数偏差値': 'median',\n",
    "    '上り指数順位': 'median',\n",
    "    '上り指数順位分布': 'median',\n",
    "    'スピード指数': 'median',\n",
    "    'スピード指数偏差値': 'median',\n",
    "    'スピード指数順位': 'median',\n",
    "    'スピード指数順位分布': 'median',\n",
    "    '補正タイム': 'median',\n",
    "    '補9': 'median',\n",
    "    '総合指数': 'median',\n",
    "    '総合指数偏差値': 'median',\n",
    "    '総合指数順位': 'median',\n",
    "    '総合指数順位分布': 'median',\n",
    "    'レース強度指数': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '初角位置': 'median',\n",
    "    '初角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "# 1勝クラス・2勝クラスのみ対象\n",
    "base_df1 = merged_df1[merged_df1['クラスコード'].isin([23, 43])].copy()\n",
    "\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops1 = base_df1[base_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st1 = base_df1[base_df1['入線順位'] == 1].copy()\n",
    "\n",
    "# クラス分類の統一\n",
    "df_tops1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "df_1st1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "\n",
    "# --- 集計処理 ---\n",
    "base_time_tops1 = df_tops1.groupby(group_cols1, dropna=False).agg(agg_cols3).reset_index()\n",
    "base_time_1st1 = df_1st1.groupby(group_cols1, dropna=False).agg(agg_cols4).reset_index()\n",
    "base_time_1st1 = base_time_1st1.rename(columns={col: f\"{col}_1着\" for col in agg_cols4.keys()})\n",
    "\n",
    "# --- 結合 ---\n",
    "base_time_df1 = pd.merge(base_time_tops1, base_time_1st1, on=group_cols1, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df1['距離係数'] = (1 / base_time_df1['タイムS']) * 100\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "df_tops2 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st2 = merged_df1[merged_df1['入線順位'] == 1].copy()\n",
    "\n",
    "base_time_tops2 = df_tops2.groupby(group_cols2).agg(agg_cols3).reset_index()\n",
    "base_time_1st2 = df_1st2.groupby(group_cols2).agg(agg_cols4).reset_index()\n",
    "base_time_1st2 = base_time_1st2.rename(columns={col: f\"{col}_1着\" for col in agg_cols4.keys()})\n",
    "base_time_df2 = pd.merge(base_time_tops2, base_time_1st2, on=group_cols2, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df2['距離係数'] = (1 / base_time_df2['タイムS']) * 100\n",
    "\n",
    "#---ステップ４：成績データへレースレベル指数の追加\n",
    "# 再集計した基準DFを suffix 付きで準備\n",
    "std1_pre = prepare_ref_df(base_time_df1, merge_key1, '_stdtime1_new')\n",
    "std2_pre = prepare_ref_df(base_time_df2, merge_key2, '_stdtime2_new')\n",
    "\n",
    "# merged_df1にマージ\n",
    "merged_df1 = pd.merge(merged_df1, std1_pre, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, std2_pre, on=merge_key2, how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del std1_pre, std2_pre\n",
    "\n",
    "# ベース値（Std2優先 → なければ Std1）\n",
    "rating_base = merged_df1['レイティング_stdtime2_new'].fillna(\n",
    "    merged_df1['レイティング_stdtime1_new']\n",
    ")\n",
    "speed_base = merged_df1['総合指数_stdtime2_new'].fillna(\n",
    "    merged_df1['総合指数_stdtime1_new']\n",
    ")\n",
    "strength_base = merged_df1['レース強度指数_stdtime2_new'].fillna(\n",
    "    merged_df1['レース強度指数_stdtime1_new']\n",
    ")\n",
    "\n",
    "# 差分（NaN は 0 扱い）\n",
    "rating_diff = (merged_df1['レイティング平均値'] - rating_base).fillna(0)\n",
    "speed_diff  = (merged_df1['Top3総合指数'] - speed_base).fillna(0)\n",
    "strength_diff = (merged_df1['レース強度指数'] - strength_base).fillna(0)\n",
    "\n",
    "# レースレベル指数\n",
    "merged_df1['レースレベル指数'] = (rating_diff + speed_diff + strength_diff + 100).round(1)\n",
    "\n",
    "#---ステップ５：各指数の差分を成績データへ追加\n",
    "# Top3総合指数と総合指数の差分を成績データへ追加\n",
    "merged_df1['Top3総合指数差分'] = merged_df1['総合指数'] - merged_df1['Top3総合指数']\n",
    "\n",
    "# レイティング平均値とレイティングの差分を追加\n",
    "merged_df1['平均レイティング差分'] = merged_df1['レイティング'] - merged_df1['レイティング平均値']\n",
    "\n",
    "# レース強度指数：基準タイム１差分\n",
    "merged_df1['レース強度指数上位差分']=merged_df1['レース強度指数']-merged_df1['レース強度指数_stdtime1_new'].fillna(merged_df1['レース強度指数_stdtime2_new'])\n",
    "\n",
    "# PCI3：基準タイム１差分\n",
    "merged_df1['PCI3差分']=merged_df1['PCI3']-merged_df1['PCI3_stdtime1_new'].fillna(merged_df1['PCI3_stdtime2_new'])\n",
    "\n",
    "# PCI：基準タイム１差分\n",
    "merged_df1['PCI上位差分']=merged_df1['PCI']-merged_df1['PCI_stdtime1_new'].fillna(merged_df1['PCI_stdtime2_new'])\n",
    "merged_df1['PCI勝馬差分']=merged_df1['PCI']-merged_df1['PCI_1着_stdtime1_new'].fillna(merged_df1['PCI_1着_stdtime2_new'])\n",
    "\n",
    "# 生後日数：基準タイム２差分\n",
    "merged_df1['生後日数上位差分']=merged_df1['生後日数']-merged_df1['生後日数_stdtime2_new'].fillna(merged_df1['生後日数_stdtime1_new'])\n",
    "merged_df1['生後日数勝馬差分']=merged_df1['生後日数']-merged_df1['生後日数_1着_stdtime2_new'].fillna(merged_df1['生後日数_1着_stdtime1_new'])\n",
    "\n",
    "# 馬体重：基準タイム２差分\n",
    "merged_df1['体重上位差分']=merged_df1['体重']-merged_df1['体重_stdtime2_new'].fillna(merged_df1['体重_stdtime1_new'])\n",
    "merged_df1['体重勝馬差分']=merged_df1['体重']-merged_df1['体重_1着_stdtime2_new'].fillna(merged_df1['体重_1着_stdtime1_new'])\n",
    "\n",
    "# 馬体重斤量比：基準タイム２差分\n",
    "merged_df1['斤量馬体重比上位差分']=merged_df1['斤量馬体重比']-merged_df1['斤量馬体重比_stdtime2_new'].fillna(merged_df1['斤量馬体重比_stdtime1_new'])\n",
    "merged_df1['斤量馬体重比勝馬差分']=merged_df1['斤量馬体重比']-merged_df1['斤量馬体重比_1着_stdtime2_new'].fillna(merged_df1['斤量馬体重比_1着_stdtime1_new'])\n",
    "\n",
    "# 前走距離：基準タイム１差分\n",
    "merged_df1['前走距離上位差分']=merged_df1['前走距離']-merged_df1['前走距離_stdtime1_new'].fillna(merged_df1['前走距離_stdtime2_new'])\n",
    "merged_df1['前走距離勝馬差分']=merged_df1['前走距離']-merged_df1['前走距離_1着_stdtime1_new'].fillna(merged_df1['前走距離_1着_stdtime2_new'])\n",
    "\n",
    "# 前走距離差：基準タイム１差分\n",
    "merged_df1['前走距離差上位差分']=merged_df1['前走距離差']-merged_df1['前走距離差_stdtime1_new'].fillna(merged_df1['前走距離差_stdtime2_new'])\n",
    "merged_df1['前走距離差勝馬差分']=merged_df1['前走距離差']-merged_df1['前走距離差_1着_stdtime1_new'].fillna(merged_df1['前走距離差_1着_stdtime2_new'])\n",
    "\n",
    "# レイティング：基準タイム１差分\n",
    "merged_df1['レイティング上位差分']=merged_df1['レイティング']-merged_df1['レイティング_stdtime1_new'].fillna(merged_df1['レイティング_stdtime2_new'])\n",
    "merged_df1['レイティング勝馬差分']=merged_df1['レイティング']-merged_df1['レイティング_1着_stdtime1_new'].fillna(merged_df1['レイティング_1着_stdtime2_new'])\n",
    "\n",
    "# レイティング偏差値：基準タイム１差分\n",
    "merged_df1['レイティング偏差値上位差分']=merged_df1['レイティング偏差値']-merged_df1['レイティング偏差値_stdtime1_new'].fillna(merged_df1['レイティング偏差値_stdtime2_new'])\n",
    "merged_df1['レイティング偏差値勝馬差分']=merged_df1['レイティング偏差値']-merged_df1['レイティング偏差値_1着_stdtime1_new'].fillna(merged_df1['レイティング偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# レイティング順位分布：基準タイム１差分\n",
    "merged_df1['レイティング順位分布上位差分']=merged_df1['レイティング順位分布']-merged_df1['レイティング順位分布_stdtime1_new'].fillna(merged_df1['レイティング順位分布_stdtime2_new'])\n",
    "merged_df1['レイティング順位分布勝馬差分']=merged_df1['レイティング順位分布']-merged_df1['レイティング順位分布_1着_stdtime1_new'].fillna(merged_df1['レイティング順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# ZI指数：基準タイム１差分\n",
    "merged_df1['ZI指数上位差分']=merged_df1['ZI指数']-merged_df1['ZI指数_stdtime1_new'].fillna(merged_df1['ZI指数_stdtime2_new'])\n",
    "merged_df1['ZI指数勝馬差分']=merged_df1['ZI指数']-merged_df1['ZI指数_1着_stdtime1_new'].fillna(merged_df1['ZI指数_1着_stdtime2_new'])\n",
    "\n",
    "# ZI指数偏差値：基準タイム１差分\n",
    "merged_df1['ZI指数偏差値上位差分']=merged_df1['ZI指数偏差値']-merged_df1['ZI指数偏差値_stdtime1_new'].fillna(merged_df1['ZI指数偏差値_stdtime2_new'])\n",
    "merged_df1['ZI指数偏差値勝馬差分']=merged_df1['ZI指数偏差値']-merged_df1['ZI指数偏差値_1着_stdtime1_new'].fillna(merged_df1['ZI指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# ZI指数順位分布：基準タイム１差分\n",
    "merged_df1['ZI指数順位分布上位差分']=merged_df1['ZI指数順位分布']-merged_df1['ZI指数順位分布_stdtime1_new'].fillna(merged_df1['ZI指数順位分布_stdtime2_new'])\n",
    "merged_df1['ZI指数順位分布勝馬差分']=merged_df1['ZI指数順位分布']-merged_df1['ZI指数順位分布_1着_stdtime1_new'].fillna(merged_df1['ZI指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 追切指数：基準タイム１差分\n",
    "merged_df1['追切指数上位差分']=merged_df1['追切指数']-merged_df1['追切指数_stdtime1_new'].fillna(merged_df1['追切指数_stdtime2_new'])\n",
    "merged_df1['追切指数勝馬差分']=merged_df1['追切指数']-merged_df1['追切指数_1着_stdtime1_new'].fillna(merged_df1['追切指数_1着_stdtime2_new'])\n",
    "\n",
    "# 追切指数偏差値：基準タイム１差分\n",
    "merged_df1['追切指数偏差値上位差分']=merged_df1['追切指数偏差値']-merged_df1['追切指数偏差値_stdtime1_new'].fillna(merged_df1['追切指数偏差値_stdtime2_new'])\n",
    "merged_df1['追切指数偏差値勝馬差分']=merged_df1['追切指数偏差値']-merged_df1['追切指数偏差値_1着_stdtime1_new'].fillna(merged_df1['追切指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 追切指数順位分布：基準タイム１差分\n",
    "merged_df1['追切指数順位分布上位差分']=merged_df1['追切指数順位分布']-merged_df1['追切指数順位分布_stdtime1_new'].fillna(merged_df1['追切指数順位分布_stdtime2_new'])\n",
    "merged_df1['追切指数順位分布勝馬差分']=merged_df1['追切指数順位分布']-merged_df1['追切指数順位分布_1着_stdtime1_new'].fillna(merged_df1['追切指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# マイニング：基準タイム１差分\n",
    "merged_df1['マイニング上位差分']=merged_df1['マイニング']-merged_df1['マイニング_stdtime1_new'].fillna(merged_df1['マイニング_stdtime2_new'])\n",
    "merged_df1['マイニング勝馬差分']=merged_df1['マイニング']-merged_df1['マイニング_1着_stdtime1_new'].fillna(merged_df1['マイニング_1着_stdtime2_new'])\n",
    "\n",
    "# マイニング偏差値：基準タイム１差分\n",
    "merged_df1['マイニング偏差値上位差分']=merged_df1['マイニング偏差値']-merged_df1['マイニング偏差値_stdtime1_new'].fillna(merged_df1['マイニング偏差値_stdtime2_new'])\n",
    "merged_df1['マイニング偏差値勝馬差分']=merged_df1['マイニング偏差値']-merged_df1['マイニング偏差値_1着_stdtime1_new'].fillna(merged_df1['マイニング偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# マイニング順位分布：基準タイム１差分\n",
    "merged_df1['マイニング順位分布上位差分']=merged_df1['マイニング順位分布']-merged_df1['マイニング順位分布_stdtime1_new'].fillna(merged_df1['マイニング順位分布_stdtime2_new'])\n",
    "merged_df1['マイニング順位分布勝馬差分']=merged_df1['マイニング順位分布']-merged_df1['マイニング順位分布_1着_stdtime1_new'].fillna(merged_df1['マイニング順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 対戦型マイニング：基準タイム１差分\n",
    "merged_df1['対戦型マイニング上位差分']=merged_df1['対戦型マイニング']-merged_df1['対戦型マイニング_stdtime1_new'].fillna(merged_df1['対戦型マイニング_stdtime2_new'])\n",
    "merged_df1['対戦型マイニング勝馬差分']=merged_df1['対戦型マイニング']-merged_df1['対戦型マイニング_1着_stdtime1_new'].fillna(merged_df1['対戦型マイニング_1着_stdtime2_new'])\n",
    "\n",
    "# 対戦型マイニング偏差値：基準タイム１差分\n",
    "merged_df1['対戦型マイニング偏差値上位差分']=merged_df1['対戦型マイニング偏差値']-merged_df1['対戦型マイニング偏差値_stdtime1_new'].fillna(merged_df1['対戦型マイニング偏差値_stdtime2_new'])\n",
    "merged_df1['対戦型マイニング偏差値勝馬差分']=merged_df1['対戦型マイニング偏差値']-merged_df1['対戦型マイニング偏差値_1着_stdtime1_new'].fillna(merged_df1['対戦型マイニング偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 対戦型マイニング順位分布：基準タイム１差分\n",
    "merged_df1['対戦型マイニング順位分布上位差分']=merged_df1['対戦型マイニング順位分布']-merged_df1['対戦型マイニング順位分布_stdtime1_new'].fillna(merged_df1['対戦型マイニング順位分布_stdtime2_new'])\n",
    "merged_df1['対戦型マイニング順位分布勝馬差分']=merged_df1['対戦型マイニング順位分布']-merged_df1['対戦型マイニング順位分布_1着_stdtime1_new'].fillna(merged_df1['対戦型マイニング順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# タイムS：基準タイム１差分\n",
    "merged_df1['タイムS上位差分']=merged_df1['タイムS']-merged_df1['タイムS_stdtime1_new'].fillna(merged_df1['タイムS_stdtime2_new'])\n",
    "merged_df1['タイムS勝馬差分']=merged_df1['タイムS']-merged_df1['タイムS_1着_stdtime1_new'].fillna(merged_df1['タイムS_1着_stdtime2_new'])\n",
    "\n",
    "# 補正走破タイム：基準タイム１差分\n",
    "merged_df1['補正走破タイム上位差分']=merged_df1['補正走破タイム']-merged_df1['補正走破タイム_stdtime1_new'].fillna(merged_df1['補正走破タイム_stdtime2_new'])\n",
    "merged_df1['補正走破タイム勝馬差分']=merged_df1['補正走破タイム']-merged_df1['補正走破タイム_1着_stdtime1_new'].fillna(merged_df1['補正走破タイム_1着_stdtime2_new'])\n",
    "\n",
    "# -3Fタイム：基準タイム１差分\n",
    "merged_df1['-3Fタイム上位差分']=merged_df1['-3Fタイム']-merged_df1['-3Fタイム_stdtime1_new'].fillna(merged_df1['-3Fタイム_stdtime2_new'])\n",
    "merged_df1['-3Fタイム勝馬差分']=merged_df1['-3Fタイム']-merged_df1['-3Fタイム_1着_stdtime1_new'].fillna(merged_df1['-3Fタイム_1着_stdtime2_new'])\n",
    "\n",
    "# 前半3F：基準タイム１差分\n",
    "merged_df1['前半3F上位差分']=merged_df1['前半3F']-merged_df1['前半3F_stdtime1_new'].fillna(merged_df1['前半3F_stdtime2_new'])\n",
    "merged_df1['前半3F勝馬差分']=merged_df1['前半3F']-merged_df1['前半3F_1着_stdtime1_new'].fillna(merged_df1['前半3F_1着_stdtime2_new'])\n",
    "\n",
    "# 前半3F偏差値：基準タイム１差分\n",
    "merged_df1['前半3F偏差値上位差分']=merged_df1['前半3F偏差値']-merged_df1['前半3F偏差値_stdtime1_new'].fillna(merged_df1['前半3F偏差値_stdtime2_new'])\n",
    "merged_df1['前半3F偏差値勝馬差分']=merged_df1['前半3F偏差値']-merged_df1['前半3F偏差値_1着_stdtime1_new'].fillna(merged_df1['前半3F偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 前半3F順位：基準タイム１差分\n",
    "merged_df1['前半3F順位上位差分']=merged_df1['前半3F順位']-merged_df1['前半3F順位_stdtime1_new'].fillna(merged_df1['前半3F順位_stdtime2_new'])\n",
    "merged_df1['前半3F順位勝馬差分']=merged_df1['前半3F順位']-merged_df1['前半3F順位_1着_stdtime1_new'].fillna(merged_df1['前半3F順位_1着_stdtime2_new'])\n",
    "\n",
    "# 前半3F順位分布：基準タイム１差分\n",
    "merged_df1['前半3F順位分布上位差分']=merged_df1['前半3F順位分布']-merged_df1['前半3F順位分布_stdtime1_new'].fillna(merged_df1['前半3F順位分布_stdtime2_new'])\n",
    "merged_df1['前半3F順位分布勝馬差分']=merged_df1['前半3F順位分布']-merged_df1['前半3F順位分布_1着_stdtime1_new'].fillna(merged_df1['前半3F順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 上り3F：基準タイム１差分\n",
    "merged_df1['上り3F上位差分']=merged_df1['上り3F']-merged_df1['上り3F_stdtime1_new'].fillna(merged_df1['上り3F_stdtime2_new'])\n",
    "merged_df1['上り3F勝馬差分']=merged_df1['上り3F']-merged_df1['上り3F_1着_stdtime1_new'].fillna(merged_df1['上り3F_1着_stdtime2_new'])\n",
    "\n",
    "# 上り3F偏差値：基準タイム１差分\n",
    "merged_df1['上り3F偏差値上位差分']=merged_df1['上り3F偏差値']-merged_df1['上り3F偏差値_stdtime1_new'].fillna(merged_df1['上り3F偏差値_stdtime2_new'])\n",
    "merged_df1['上り3F偏差値勝馬差分']=merged_df1['上り3F偏差値']-merged_df1['上り3F偏差値_1着_stdtime1_new'].fillna(merged_df1['上り3F偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 上り3F順位：基準タイム１差分\n",
    "merged_df1['上り3F順位上位差分']=merged_df1['上り3F順位']-merged_df1['上り3F順位_stdtime1_new'].fillna(merged_df1['上り3F順位_stdtime2_new'])\n",
    "merged_df1['上り3F順位勝馬差分']=merged_df1['上り3F順位']-merged_df1['上り3F順位_1着_stdtime1_new'].fillna(merged_df1['上り3F順位_1着_stdtime2_new'])\n",
    "\n",
    "# 上り3F順位分布：基準タイム１差分\n",
    "merged_df1['上り3F順位分布上位差分']=merged_df1['上り3F順位分布']-merged_df1['上り3F順位分布_stdtime1_new'].fillna(merged_df1['上り3F順位分布_stdtime2_new'])\n",
    "merged_df1['上り3F順位分布勝馬差分']=merged_df1['上り3F順位分布']-merged_df1['上り3F順位分布_1着_stdtime1_new'].fillna(merged_df1['上り3F順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# Ave-3F：基準タイム１差分\n",
    "merged_df1['Ave-3F上位差分']=merged_df1['Ave-3F']-merged_df1['Ave-3F_stdtime1_new'].fillna(merged_df1['Ave-3F_stdtime2_new'])\n",
    "merged_df1['Ave-3F勝馬差分']=merged_df1['Ave-3F']-merged_df1['Ave-3F_1着_stdtime1_new'].fillna(merged_df1['Ave-3F_1着_stdtime2_new'])\n",
    "\n",
    "# Ave-3F偏差値：基準タイム１差分\n",
    "merged_df1['Ave-3F偏差値上位差分']=merged_df1['Ave-3F偏差値']-merged_df1['Ave-3F偏差値_stdtime1_new'].fillna(merged_df1['Ave-3F偏差値_stdtime2_new'])\n",
    "merged_df1['Ave-3F偏差値勝馬差分']=merged_df1['Ave-3F偏差値']-merged_df1['Ave-3F偏差値_1着_stdtime1_new'].fillna(merged_df1['Ave-3F偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# Ave-3F順位：基準タイム１差分\n",
    "merged_df1['Ave-3F順位上位差分']=merged_df1['Ave-3F順位']-merged_df1['Ave-3F順位_stdtime1_new'].fillna(merged_df1['Ave-3F順位_stdtime2_new'])\n",
    "merged_df1['Ave-3F順位勝馬差分']=merged_df1['Ave-3F順位']-merged_df1['Ave-3F順位_1着_stdtime1_new'].fillna(merged_df1['Ave-3F順位_1着_stdtime2_new'])\n",
    "\n",
    "# Ave-3F順位分布：基準タイム１差分\n",
    "merged_df1['Ave-3F順位分布上位差分']=merged_df1['Ave-3F順位分布']-merged_df1['Ave-3F順位分布_stdtime1_new'].fillna(merged_df1['Ave-3F順位分布_stdtime2_new'])\n",
    "merged_df1['Ave-3F順位分布勝馬差分']=merged_df1['Ave-3F順位分布']-merged_df1['Ave-3F順位分布_1着_stdtime1_new'].fillna(merged_df1['Ave-3F順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# -3F差：基準タイム１差分\n",
    "merged_df1['-3F差上位差分']=merged_df1['-3F差']-merged_df1['-3F差_stdtime1_new'].fillna(merged_df1['-3F差_stdtime2_new'])\n",
    "merged_df1['-3F差勝馬差分']=merged_df1['-3F差']-merged_df1['-3F差_1着_stdtime1_new'].fillna(merged_df1['-3F差_1着_stdtime2_new'])\n",
    "\n",
    "# テン指数：基準タイム１差分\n",
    "merged_df1['テン指数上位差分']=merged_df1['テン指数']-merged_df1['テン指数_stdtime1_new'].fillna(merged_df1['テン指数_stdtime2_new'])\n",
    "merged_df1['テン指数勝馬差分']=merged_df1['テン指数']-merged_df1['テン指数_1着_stdtime1_new'].fillna(merged_df1['テン指数_1着_stdtime2_new'])\n",
    "\n",
    "# テン指数偏差値：基準タイム１差分\n",
    "merged_df1['テン指数偏差値上位差分']=merged_df1['テン指数偏差値']-merged_df1['テン指数偏差値_stdtime1_new'].fillna(merged_df1['テン指数偏差値_stdtime2_new'])\n",
    "merged_df1['テン指数偏差値勝馬差分']=merged_df1['テン指数偏差値']-merged_df1['テン指数偏差値_1着_stdtime1_new'].fillna(merged_df1['テン指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# テン指数順位：基準タイム１差分\n",
    "merged_df1['テン指数順位上位差分']=merged_df1['テン指数順位']-merged_df1['テン指数順位_stdtime1_new'].fillna(merged_df1['テン指数順位_stdtime2_new'])\n",
    "merged_df1['テン指数順位勝馬差分']=merged_df1['テン指数順位']-merged_df1['テン指数順位_1着_stdtime1_new'].fillna(merged_df1['テン指数順位_1着_stdtime2_new'])\n",
    "\n",
    "# テン指数順位分布：基準タイム１差分\n",
    "merged_df1['テン指数順位分布上位差分']=merged_df1['テン指数順位分布']-merged_df1['テン指数順位分布_stdtime1_new'].fillna(merged_df1['テン指数順位分布_stdtime2_new'])\n",
    "merged_df1['テン指数順位分布勝馬差分']=merged_df1['テン指数順位分布']-merged_df1['テン指数順位分布_1着_stdtime1_new'].fillna(merged_df1['テン指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 上り指数：基準タイム１差分\n",
    "merged_df1['上り指数上位差分']=merged_df1['上り指数']-merged_df1['上り指数_stdtime1_new'].fillna(merged_df1['上り指数_stdtime2_new'])\n",
    "merged_df1['上り指数勝馬差分']=merged_df1['上り指数']-merged_df1['上り指数_1着_stdtime1_new'].fillna(merged_df1['上り指数_1着_stdtime2_new'])\n",
    "\n",
    "# 上り指数偏差値：基準タイム１差分\n",
    "merged_df1['上り指数偏差値上位差分']=merged_df1['上り指数偏差値']-merged_df1['上り指数偏差値_stdtime1_new'].fillna(merged_df1['上り指数偏差値_stdtime2_new'])\n",
    "merged_df1['上り指数偏差値勝馬差分']=merged_df1['上り指数偏差値']-merged_df1['上り指数偏差値_1着_stdtime1_new'].fillna(merged_df1['上り指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 上り指数順位：基準タイム１差分\n",
    "merged_df1['上り指数順位上位差分']=merged_df1['上り指数順位']-merged_df1['上り指数順位_stdtime1_new'].fillna(merged_df1['上り指数順位_stdtime2_new'])\n",
    "merged_df1['上り指数順位勝馬差分']=merged_df1['上り指数順位']-merged_df1['上り指数順位_1着_stdtime1_new'].fillna(merged_df1['上り指数順位_1着_stdtime2_new'])\n",
    "\n",
    "# 上り指数順位分布：基準タイム１差分\n",
    "merged_df1['上り指数順位分布上位差分']=merged_df1['上り指数順位分布']-merged_df1['上り指数順位分布_stdtime1_new'].fillna(merged_df1['上り指数順位分布_stdtime2_new'])\n",
    "merged_df1['上り指数順位分布勝馬差分']=merged_df1['上り指数順位分布']-merged_df1['上り指数順位分布_1着_stdtime1_new'].fillna(merged_df1['上り指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# スピード指数：基準タイム１差分\n",
    "merged_df1['スピード指数上位差分']=merged_df1['スピード指数']-merged_df1['スピード指数_stdtime1_new'].fillna(merged_df1['スピード指数_stdtime2_new'])\n",
    "merged_df1['スピード指数勝馬差分']=merged_df1['スピード指数']-merged_df1['スピード指数_1着_stdtime1_new'].fillna(merged_df1['スピード指数_1着_stdtime2_new'])\n",
    "\n",
    "# スピード指数偏差値：基準タイム１差分\n",
    "merged_df1['スピード指数偏差値上位差分']=merged_df1['スピード指数偏差値']-merged_df1['スピード指数偏差値_stdtime1_new'].fillna(merged_df1['スピード指数偏差値_stdtime2_new'])\n",
    "merged_df1['スピード指数偏差値勝馬差分']=merged_df1['スピード指数偏差値']-merged_df1['スピード指数偏差値_1着_stdtime1_new'].fillna(merged_df1['スピード指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# スピード指数順位：基準タイム１差分\n",
    "merged_df1['スピード指数順位上位差分']=merged_df1['スピード指数順位']-merged_df1['スピード指数順位_stdtime1_new'].fillna(merged_df1['スピード指数順位_stdtime2_new'])\n",
    "merged_df1['スピード指数順位勝馬差分']=merged_df1['スピード指数順位']-merged_df1['スピード指数順位_1着_stdtime1_new'].fillna(merged_df1['スピード指数順位_1着_stdtime2_new'])\n",
    "\n",
    "# スピード指数順位分布：基準タイム１差分\n",
    "merged_df1['スピード指数順位分布上位差分']=merged_df1['スピード指数順位分布']-merged_df1['スピード指数順位分布_stdtime1_new'].fillna(merged_df1['スピード指数順位分布_stdtime2_new'])\n",
    "merged_df1['スピード指数順位分布勝馬差分']=merged_df1['スピード指数順位分布']-merged_df1['スピード指数順位分布_1着_stdtime1_new'].fillna(merged_df1['スピード指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# 総合指数：基準タイム１差分\n",
    "merged_df1['総合指数上位差分']=merged_df1['総合指数']-merged_df1['総合指数_stdtime1_new'].fillna(merged_df1['総合指数_stdtime2_new'])\n",
    "merged_df1['総合指数勝馬差分']=merged_df1['総合指数']-merged_df1['総合指数_1着_stdtime1_new'].fillna(merged_df1['総合指数_1着_stdtime2_new'])\n",
    "\n",
    "# 総合指数偏差値：基準タイム１差分\n",
    "merged_df1['総合指数偏差値上位差分']=merged_df1['総合指数偏差値']-merged_df1['総合指数偏差値_stdtime1_new'].fillna(merged_df1['総合指数偏差値_stdtime2_new'])\n",
    "merged_df1['総合指数偏差値勝馬差分']=merged_df1['総合指数偏差値']-merged_df1['総合指数偏差値_1着_stdtime1_new'].fillna(merged_df1['総合指数偏差値_1着_stdtime2_new'])\n",
    "\n",
    "# 総合指数順位：基準タイム１差分\n",
    "merged_df1['総合指数順位上位差分']=merged_df1['総合指数順位']-merged_df1['総合指数順位_stdtime1_new'].fillna(merged_df1['総合指数順位_stdtime2_new'])\n",
    "merged_df1['総合指数順位勝馬差分']=merged_df1['総合指数順位']-merged_df1['総合指数順位_1着_stdtime1_new'].fillna(merged_df1['総合指数順位_1着_stdtime2_new'])\n",
    "\n",
    "# 総合指数順位分布：基準タイム１差分\n",
    "merged_df1['総合指数順位分布上位差分']=merged_df1['総合指数順位分布']-merged_df1['総合指数順位分布_stdtime1_new'].fillna(merged_df1['総合指数順位分布_stdtime2_new'])\n",
    "merged_df1['総合指数順位分布勝馬差分']=merged_df1['総合指数順位分布']-merged_df1['総合指数順位分布_1着_stdtime1_new'].fillna(merged_df1['総合指数順位分布_1着_stdtime2_new'])\n",
    "\n",
    "# PCI：基準タイム１差分\n",
    "merged_df1['PCI上位差分']=merged_df1['PCI']-merged_df1['PCI_stdtime1_new'].fillna(merged_df1['PCI_stdtime2_new'])\n",
    "merged_df1['PCI勝馬差分']=merged_df1['PCI']-merged_df1['PCI_1着_stdtime1_new'].fillna(merged_df1['PCI_1着_stdtime2_new'])\n",
    "\n",
    "# 初角_4角差：基準タイム１差分\n",
    "merged_df1['初角_4角差上位差分']=merged_df1['初角_4角差']-merged_df1['初角_4角差_stdtime1_new'].fillna(merged_df1['初角_4角差_stdtime2_new'])\n",
    "merged_df1['初角_4角差勝馬差分']=merged_df1['初角_4角差']-merged_df1['初角_4角差_1着_stdtime1_new'].fillna(merged_df1['初角_4角差_1着_stdtime2_new'])\n",
    "\n",
    "# 4角_入線順位差：基準タイム１差分\n",
    "merged_df1['4角_入線順位差上位差分']=merged_df1['4角_入線順位差']-merged_df1['4角_入線順位差_stdtime1_new'].fillna(merged_df1['4角_入線順位差_stdtime2_new'])\n",
    "merged_df1['4角_入線順位差勝馬差分']=merged_df1['4角_入線順位差']-merged_df1['4角_入線順位差_1着_stdtime1_new'].fillna(merged_df1['4角_入線順位差_1着_stdtime2_new'])\n",
    "\n",
    "#---ステップ６：レースレベル基準の作成\n",
    "# グループ化キー\n",
    "group_cols3 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類']\n",
    "\n",
    "# --- 基準レースレベル算出処理 ---\n",
    "racelevel_df = (\n",
    "    merged_df1\n",
    "      .dropna(subset=['レースレベル指数'])  # 欠損を除外\n",
    "      .groupby(group_cols3, dropna=False)['レースレベル指数']\n",
    "      .agg(['mean', 'std'])  # mean と std を同時に集計\n",
    "      .reset_index()\n",
    ").copy()\n",
    "\n",
    "# 近似Zスコア用の基準値を計算\n",
    "racelevel_df['RL±0'] = racelevel_df['mean'].round(2)\n",
    "racelevel_df['RL+1'] = (racelevel_df['mean'] + racelevel_df['std']).round(2)\n",
    "racelevel_df['RL-1'] = (racelevel_df['mean'] - racelevel_df['std']).round(2)\n",
    "racelevel_df['RL+2'] = (racelevel_df['mean'] + 2 * racelevel_df['std']).round(2)\n",
    "racelevel_df['RL-2'] = (racelevel_df['mean'] - 2 * racelevel_df['std']).round(2)\n",
    "\n",
    "# 必要なカラムだけ残す\n",
    "racelevel_df = racelevel_df[\n",
    "    group_cols3 + ['RL-2','RL-1','RL±0','RL+1','RL+2','mean','std']\n",
    "].copy()\n",
    "\n",
    "#---ステップ７：レースレベル判定\n",
    "# レースレベル基準のデータフレームにサフィックスを付ける\n",
    "merged_df2 = prepare_ref_df(racelevel_df, group_cols3, '_racelevel')\n",
    "\n",
    "merged_df1 = pd.merge(merged_df1, merged_df2, on=group_cols3, how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del merged_df2\n",
    "\n",
    "# 差分\n",
    "rl_m2 = (merged_df1['レースレベル指数'] - merged_df1['RL-2_racelevel']).abs()\n",
    "rl_m1 = (merged_df1['レースレベル指数'] - merged_df1['RL-1_racelevel']).abs()\n",
    "rl_0  = (merged_df1['レースレベル指数'] - merged_df1['RL±0_racelevel']).abs()\n",
    "rl_p1 = (merged_df1['レースレベル指数'] - merged_df1['RL+1_racelevel']).abs()\n",
    "rl_p2 = (merged_df1['レースレベル指数'] - merged_df1['RL+2_racelevel']).abs()\n",
    "\n",
    "# 5本を横に並べて「最小の列名」を取る（行ごと）\n",
    "diff_df = pd.concat([rl_m2, rl_m1, rl_0, rl_p1, rl_p2], axis=1)\n",
    "diff_df.columns = [-2, -1, 0, 1, 2]  # そのまま判定値にする\n",
    "\n",
    "# 「基準が無い行」判定（5本すべてNaN）\n",
    "no_ref = diff_df.isna().all(axis=1)\n",
    "\n",
    "# idxminを安定させるため NaN は無限大扱いにして最小を取る\n",
    "band = diff_df.fillna(np.inf).idxmin(axis=1)\n",
    "\n",
    "# レースレベル判定 列を追加\n",
    "insert_pos = merged_df1.columns.get_loc('レースレベル指数') + 1\n",
    "merged_df1.insert(insert_pos, 'レースレベル判定', band.where(~no_ref, np.nan).astype('Int64'))\n",
    "\n",
    "# レースレベル評価 列を追加\n",
    "band_to_grade = {2: 'A', 1: 'B', 0: 'C', -1: 'D', -2: 'E'}\n",
    "insert_pos = merged_df1.columns.get_loc('レースレベル判定') + 1\n",
    "merged_df1.insert(insert_pos, 'レースレベル評価', merged_df1['レースレベル判定'].map(band_to_grade))\n",
    "\n",
    "# レース印３ 列を追加\n",
    "rank_to_label = {'A': '05A', 'B': '07B', 'C': '01C', 'D': '00D', 'E': '03E'}\n",
    "merged_df1['レース印３'] = merged_df1['レースレベル評価'].replace(rank_to_label)\n",
    "\n",
    "# サフィックス付き列を削除\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_stdtime1_new','_stdtime2_new', '_racelevel')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "merged_df1 = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "#---ステップ８：馬の持久力/瞬発力タイプ判定\n",
    "# merged_df1 をコピーして、1着～3着だけにする\n",
    "group_cols4 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)','馬場分類']\n",
    "\n",
    "horsetype_df = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "\n",
    "horsetype_df= horsetype_df[['target_raceid', '血統登録番号','PCI3', 'PCI'] + group_cols4].copy()\n",
    "\n",
    "# 基準タイムファイル１から基準PCI3を取ってマージ\n",
    "std1_df = base_time_df1[group_cols4 + ['PCI3']].copy()\n",
    "std1_df = std1_df.rename(columns={'PCI3': 'PCI3_stdtime1'})\n",
    "\n",
    "horsetype_df = pd.merge(horsetype_df, std1_df, on=group_cols4, how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del std1_df\n",
    "\n",
    "# レース性質（基準比）と、馬のレース内差分を合算\n",
    "horsetype_df['基準PCI3差分'] = horsetype_df['PCI3'] - horsetype_df['PCI3_stdtime1']\n",
    "horsetype_df['レースPCI3差分'] = horsetype_df['PCI'] - horsetype_df['PCI3']\n",
    "horsetype_df['PCI判定スコア'] = horsetype_df['基準PCI3差分'] + horsetype_df['レースPCI3差分']\n",
    "\n",
    "# 馬ごとに PCI3差分 の中央値を取る\n",
    "horsetype_df = horsetype_df.groupby('血統登録番号', as_index=False)['PCI判定スコア'].median()\n",
    "\n",
    "# 'Ｃ' 列を追加して判定（マイナス=持、プラス=瞬）\n",
    "horsetype_df['Ｃ'] = ''\n",
    "horsetype_df.loc[horsetype_df['PCI判定スコア'] < 0, 'Ｃ'] = '0'\n",
    "horsetype_df.loc[horsetype_df['PCI判定スコア'] > 0, 'Ｃ'] = '1'\n",
    "\n",
    "# 成績データへ馬タイプを代入する\n",
    "c_map = horsetype_df.set_index('血統登録番号')['Ｃ']\n",
    "merged_df1['Ｃ'] = merged_df1['血統登録番号'].map(c_map)\n",
    "\n",
    "# 今日の日付を yymmdd で作る\n",
    "today_yymmdd = datetime.now().strftime(\"%y%m%d\")\n",
    "\n",
    "# 判定済み horsetype_df（= 血統登録番号 + Ｃ）に馬名を付ける\n",
    "horse_name_df = (\n",
    "    merged_df1[['血統登録番号', '馬名']]\n",
    "    .dropna(subset=['馬名'])\n",
    "    .drop_duplicates(subset=['血統登録番号'], keep='last')\n",
    ")\n",
    "\n",
    "checkhorse_df = pd.merge(horsetype_df, horse_name_df, on='血統登録番号', how='left')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del horsetype_df\n",
    "del horse_name_df\n",
    "\n",
    "# ★「0/1が入った馬だけ」出力（中央値0や判定不能は除外）\n",
    "checkhorse_df = checkhorse_df[checkhorse_df['Ｃ'].isin(['0', '1'])].copy()\n",
    "\n",
    "# TARGET仕様の列名に変換\n",
    "checkhorse_df = checkhorse_df.rename(columns={'Ｃ': 'タイプ'})\n",
    "\n",
    "# 登録日\n",
    "checkhorse_df['登録日'] = today_yymmdd\n",
    "\n",
    "# 血統登録番号の整形（UX～なら zfill しない方が安全）\n",
    "checkhorse_df['血統登録番号'] = checkhorse_df['血統登録番号'].astype(str).str.strip()\n",
    "\n",
    "# 列順\n",
    "checkhorse_df = checkhorse_df[['馬名', 'タイプ', '登録日', '血統登録番号']]\n",
    "\n",
    "#---ステップ９：csvファイル保存\n",
    "# 成績データの列の並び替え\n",
    "header_df = pd.read_csv(header_filepath, header = None, encoding='cp932')\n",
    "column_list = header_df[0].tolist()\n",
    "merged_df1 = merged_df1[column_list]\n",
    "\n",
    "# csvファイル保存\n",
    "merged_df1.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "base_time_df1.to_csv(output_filepath2, index=False, encoding='cp932')\n",
    "base_time_df2.to_csv(output_filepath3, index=False, encoding='cp932')\n",
    "pace_medians_df.to_csv(output_filepath4, index=False, encoding='cp932')\n",
    "lap33_df.to_csv(output_filepath5, index=False, encoding='cp932')\n",
    "racelevel_df.to_csv(output_filepath6, index=False, encoding='cp932')\n",
    "checkhorse_df.to_csv(output_filepath7, index=False, encoding='cp932')\n",
    "\n",
    "# 各指数をインポート用ファイルに加工して保存\n",
    "# テン指数\n",
    "imp_df1 = merged_df1[['target_horseid','テン指数']]\n",
    "# 上り指数\n",
    "imp_df2 = merged_df1[['target_horseid','上り指数']]\n",
    "# スピード指数\n",
    "imp_df3 = merged_df1[['target_horseid','スピード指数']]\n",
    "# 総合指数\n",
    "imp_df4 = merged_df1[['target_horseid','総合指数']]\n",
    "# 33ラップ判定\n",
    "imp_df5 = merged_df1[['target_raceid','レース印２']].drop_duplicates('target_raceid')\n",
    "# レースレベル判定\n",
    "imp_df6 = merged_df1[['target_raceid','レース印３']].drop_duplicates('target_raceid')\n",
    "\n",
    "# 各指数のマスタをcsv保存\n",
    "imp_df1.to_csv(output_dir1 + 'First_Score_Master.csv', index=False, encoding='cp932')\n",
    "imp_df2.to_csv(output_dir2 + 'Spurt_Score_Master.csv', index=False, encoding='cp932')\n",
    "imp_df3.to_csv(output_dir3 + 'Speed_Score_Master.csv', index=False, encoding='cp932')\n",
    "imp_df4.to_csv(output_dir4 + 'Total_Score_Master.csv', index=False, encoding='cp932')\n",
    "imp_df5.to_csv(output_dir5 + '33Lap_Category_Master.csv', index=False, encoding='cp932')\n",
    "imp_df6.to_csv(output_dir6 + 'Race_Level_Master.csv', index=False, encoding='cp932')\n",
    "\n",
    "# 年度列を追加（target_raceid先頭4桁が年）\n",
    "imp_df1['year'] = pd.to_datetime(\n",
    "    imp_df1['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df2['year'] = pd.to_datetime(\n",
    "    imp_df2['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df3['year'] = pd.to_datetime(\n",
    "    imp_df3['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df4['year'] = pd.to_datetime(\n",
    "    imp_df4['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df5['year'] = pd.to_datetime(\n",
    "    imp_df5['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "imp_df6['year'] = pd.to_datetime(\n",
    "    imp_df6['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "# 年度別にファイル分割\n",
    "for year, df in imp_df1.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir1}First_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df2.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir2}Spurt_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df3.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir3}Speed_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df4.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir4}Total_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df5.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir5}33Lap_Category_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in imp_df6.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir6}Race_Level_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del merged_df1\n",
    "del base_time_df1\n",
    "del base_time_df2\n",
    "del pace_medians_df\n",
    "del lap33_df\n",
    "del racelevel_df\n",
    "del imp_df1\n",
    "del imp_df2\n",
    "del imp_df3\n",
    "del imp_df4\n",
    "del imp_df5\n",
    "del imp_df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 追切指数を算出する\n",
    "## 2024年分の追切指数を2017~2023年分の基準データで算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\1771354911.py:43: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(master_filepath,  encoding='cp932').copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完了：追切指数（MAD・ロバスト偏差値版）を出力しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "# =========================\n",
    "# 読み込みファイルパス\n",
    "# =========================\n",
    "master_filepath  = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Original\\ResultData_2024.csv'\n",
    "\n",
    "# 基準ファイル\n",
    "p_course_median  = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course.csv'\n",
    "p_class_median   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_class.csv'\n",
    "p_course_top20   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course_top20.csv'\n",
    "p_course_top10   = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Training_Data\\traning_std_course_top10.csv'\n",
    "\n",
    "# 出力\n",
    "output_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\Training_Score_Master.csv'\n",
    "output_dir       = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\\\'\n",
    "\n",
    "# =========================\n",
    "# ファイル選択\n",
    "# =========================\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "\n",
    "traning_filepath = filedialog.askopenfilename(\n",
    "    title=\"追切CSVファイルを選択してください\",\n",
    "    filetypes=[(\"CSV Files\", \"*.csv\")]\n",
    ")\n",
    "if not traning_filepath:\n",
    "    print(\"ファイルが選択されなかったため、処理を終了します。\")\n",
    "    raise SystemExit\n",
    "\n",
    "# =========================\n",
    "# 読み込み & 前処理\n",
    "# =========================\n",
    "df1 = pd.read_csv(traning_filepath, encoding='cp932').copy()\n",
    "df2 = pd.read_csv(master_filepath,  encoding='cp932').copy()\n",
    "\n",
    "def clean_training_data(df):\n",
    "    df = df.copy()\n",
    "    mask_invalid = df[\"日付\"].astype(str).str.contains(\"■|◇\", na=False)\n",
    "    df = df[~mask_invalid].copy()\n",
    "    check_cols = [c for c in ['8F','7F','6F','5F(4F)','4F(3F)','3F(2F)'] if c in df.columns]\n",
    "    for c in check_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    is_not_hill = ~df['コース'].astype(str).str.contains('坂', na=False)\n",
    "    has_10sec_like = np.column_stack([df[c].between(10.0, 19.9) for c in check_cols]).any(axis=1)\n",
    "    drop_mask = is_not_hill & has_10sec_like\n",
    "    df = df[~drop_mask].copy()\n",
    "    return df\n",
    "\n",
    "df1 = clean_training_data(df1)\n",
    "\n",
    "replace_map = {'南Ｗ': '美Ｗ', '南Ｄ': '美ダ', '南ダ': '美ダ', '南芝': '美芝'}\n",
    "df1['コース'] = df1['コース'].replace(replace_map)\n",
    "df1['馬場状態'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1[\"回り位置\"] = pd.to_numeric(df1[\"回り位置\"], errors=\"coerce\")\n",
    "\n",
    "distance_columns = [col for col in [\"8F\", \"7F\", \"6F\", \"5F(4F)\", \"4F(3F)\", \"3F(2F)\", \"1F\"] if col in df1.columns]\n",
    "for col in distance_columns:\n",
    "    df1[f\"{col}_補\"] = np.nan\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    if not pd.isna(row[\"回り位置\"]):\n",
    "        correction_value = (9 - row[\"回り位置\"]) * 0.1\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "            df1.at[index, f\"{leftmost_col}_補\"] = round(row[leftmost_col] + correction_value, 1)\n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        df1.at[index, f\"{col}_補\"] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                df1.at[index, f\"{col}_補\"] = row[col]\n",
    "\n",
    "time_columns = [f\"{c}_補\" for c in distance_columns]\n",
    "\n",
    "# =========================\n",
    "# 成績マージ\n",
    "# =========================\n",
    "# df2の列をリネームする\n",
    "# リネームする列名を定義\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid'\n",
    "}\n",
    "\n",
    "df2.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "merge_cols = ['target_horseid', 'トラックコード(JV)', '年齢限定(競走種別コード)', 'クラスコード']\n",
    "df2 = df2[merge_cols]\n",
    "\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11: return 'サラブレッド系2歳'\n",
    "    elif race_type == 12: return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13: return 'サラブレッド系3歳以上'\n",
    "    else: return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15: return '新馬・未勝利'\n",
    "    elif class_code == 23: return '1勝クラス'\n",
    "    elif class_code == 43: return '2勝クラス'\n",
    "    elif class_code == 67: return '3勝クラス'\n",
    "    elif class_code >= 114: return 'OP・重賞'\n",
    "    else: return np.nan\n",
    "\n",
    "df2['年齢限定(競走種別コード)'] = df2['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df2['クラスコード'] = df2['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "merged_df1 = pd.merge(df1, df2, on='target_horseid', how='inner').copy()\n",
    "merged_df1['is_saka'] = merged_df1['コース'].astype(str).str.contains('坂', na=False)\n",
    "\n",
    "# =========================\n",
    "# 基準テーブル読み込み（MAD対応）\n",
    "# =========================\n",
    "def load_and_tag(path, suffix, has_std):\n",
    "    t = pd.read_csv(path, encoding='cp932').copy()\n",
    "    rename_map = {}\n",
    "    for c in time_columns:\n",
    "        if c in t.columns:\n",
    "            rename_map[c] = f\"{c}_{suffix}\"\n",
    "        \n",
    "        # 標準偏差ではなくMADを探す\n",
    "        madc = f\"MAD_{c}\"\n",
    "        if has_std and (madc in t.columns):\n",
    "            rename_map[madc] = f\"MAD_{c}_{suffix}\"\n",
    "    return t.rename(columns=rename_map)\n",
    "\n",
    "df3 = load_and_tag(p_course_median, 'course', True)\n",
    "df4 = load_and_tag(p_class_median,  'class',  True)\n",
    "df5 = load_and_tag(p_course_top20, 'course_20', False)\n",
    "df6 = load_and_tag(p_course_top10, 'course_10', False)\n",
    "\n",
    "key_course = ['コース','馬場状態']\n",
    "key_class  = ['年齢限定(競走種別コード)','クラスコード','コース','馬場状態']\n",
    "\n",
    "def smerge(left, right, keys):\n",
    "    exist_keys = [k for k in keys if (k in left.columns and k in right.columns)]\n",
    "    return pd.merge(left, right, on=exist_keys, how='left')\n",
    "\n",
    "merged_df1 = smerge(merged_df1, df3, key_course)\n",
    "merged_df1 = smerge(merged_df1, df4, key_class)\n",
    "merged_df1 = smerge(merged_df1, df5, key_course)\n",
    "merged_df1 = smerge(merged_df1, df6, key_course)\n",
    "\n",
    "# =========================\n",
    "# 偏差値（ロバスト偏差値計算：MAD使用）\n",
    "# =========================\n",
    "def dev_vec(v, m, mad):\n",
    "    # MADを正規分布の標準偏差相当に変換する定数 1.4826\n",
    "    sigma_est = mad * 1.4826\n",
    "    \n",
    "    ok = (~pd.isna(v)) & (~pd.isna(m)) & (~pd.isna(mad)) & (sigma_est != 0)\n",
    "    \n",
    "    # タイムは小さい方が良いので (Median - Value)\n",
    "    # sigma_est が 0 (全員同じタイム等) の場合は偏差値50とする\n",
    "    return np.where(ok, 50 + 10 * (m - v) / sigma_est, 50)\n",
    "\n",
    "bases_for_dev = ['course', 'class']\n",
    "\n",
    "for c in time_columns:\n",
    "    dev_cols = []\n",
    "    for b in bases_for_dev:\n",
    "        mean_col = f\"{c}_{b}\"\n",
    "        mad_col  = f\"MAD_{c}_{b}\"\n",
    "        colname = f\"偏差値_{c}_{b}\"\n",
    "        \n",
    "        # MADが存在する場合のみ計算\n",
    "        if mad_col in merged_df1.columns:\n",
    "            merged_df1[colname] = dev_vec(merged_df1[c], merged_df1[mean_col], merged_df1[mad_col])\n",
    "            dev_cols.append(colname)\n",
    "\n",
    "    if dev_cols:\n",
    "        merged_df1[f\"偏差値_統合_{c}\"] = merged_df1[dev_cols].mean(axis=1, skipna=True)\n",
    "\n",
    "# 統合偏差値が存在する列のみでスコア計算\n",
    "valid_dev_cols = [f\"偏差値_統合_{c}\" for c in time_columns if f\"偏差値_統合_{c}\" in merged_df1.columns]\n",
    "if valid_dev_cols:\n",
    "    merged_df1['総合偏差値スコア'] = merged_df1[valid_dev_cols].mean(axis=1, skipna=True)\n",
    "else:\n",
    "    merged_df1['総合偏差値スコア'] = 50.0\n",
    "\n",
    "# =========================\n",
    "# 加点（変更なし）\n",
    "# =========================\n",
    "bonus_targets = {'4F': '4F(3F)_補', '2F': '3F(2F)_補', '1F': '1F_補'}\n",
    "\n",
    "def calculate_bonus(value, mean, is_saka, col_short):\n",
    "    if pd.isna(value) or pd.isna(mean): return 0.0\n",
    "    if is_saka:\n",
    "        if col_short == '4F': return 0.5 if value < mean else 0.0\n",
    "        if col_short == '2F': return 1.5 if value < mean else 0.0\n",
    "        if col_short == '1F': return 1.0 if value < mean else 0.0\n",
    "    else:\n",
    "        if col_short == '4F': return 0.5 if value < mean else 0.0\n",
    "        if col_short == '2F': return 1.0 if value < mean else 0.0\n",
    "        if col_short == '1F': return 1.5 if value < mean else 0.0\n",
    "    return 0.0\n",
    "\n",
    "th_sfx_list = ['course_20','course_10']\n",
    "bonus_cols = []\n",
    "for col_short, base_col in bonus_targets.items():\n",
    "    for sfx in th_sfx_list:\n",
    "        th_col = f\"{base_col}_{sfx}\"\n",
    "        if th_col in merged_df1.columns:\n",
    "            out_col = f\"加点_{col_short}_{sfx}\"\n",
    "            merged_df1[out_col] = merged_df1.apply(\n",
    "                lambda r: calculate_bonus(\n",
    "                    r.get(base_col, np.nan), r.get(th_col, np.nan),\n",
    "                    bool(r.get('is_saka', False)), col_short\n",
    "                ), axis=1\n",
    "            )\n",
    "            bonus_cols.append(out_col)\n",
    "\n",
    "merged_df1['総合加点スコア'] = merged_df1[bonus_cols].sum(axis=1, skipna=True) if bonus_cols else 0.0\n",
    "\n",
    "# =========================\n",
    "# 係数・最終指数\n",
    "# =========================\n",
    "def rider_coef(x):\n",
    "    s = '' if pd.isna(x) else str(x)\n",
    "    if '助手' in s: return 1.0\n",
    "    if '見習' in s: return 0.8\n",
    "    return 0.9\n",
    "\n",
    "def leg_coef(x):\n",
    "    s = '' if pd.isna(x) else str(x)\n",
    "    if '馬なり' in s: return 1.1\n",
    "    if ('Ｇ' in s) or ('G' in s) or ('強' in s): return 1.0\n",
    "    if '一杯' in s: return 0.8\n",
    "    if 'ヨレ' in s: return 0.7\n",
    "    if 'バテ' in s: return 0.6\n",
    "    return 0.9\n",
    "\n",
    "merged_df1['騎乗者係数'] = merged_df1['乗り役'].apply(rider_coef)\n",
    "merged_df1['脚色係数']   = merged_df1['脚色'].apply(leg_coef)\n",
    "\n",
    "merged_df1['追切指数'] = (\n",
    "    (merged_df1['総合偏差値スコア'].fillna(50) + merged_df1['総合加点スコア'].fillna(0.0))\n",
    "    * merged_df1['騎乗者係数'].fillna(0.9)\n",
    "    * merged_df1['脚色係数'].fillna(0.9)\n",
    ")\n",
    "\n",
    "merged_df1['追切指数'] = merged_df1['追切指数'].replace([np.inf, -np.inf], np.nan).fillna(1).round(1)\n",
    "\n",
    "# 重複排除\n",
    "merged_unique = merged_df1.loc[merged_df1.groupby('target_horseid')['追切指数'].idxmax()].reset_index(drop=True).copy()\n",
    "merged_unique = merged_unique[['target_horseid','追切指数']].copy()\n",
    "\n",
    "del df1,df2,df3,df4,df5,df6,merged_df1\n",
    "\n",
    "# 保存処理\n",
    "combined_df = pd.read_csv(output_filepath1, encoding='cp932').copy()\n",
    "combined_df = pd.concat([combined_df, merged_unique], ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates(subset='target_horseid', keep='last')\n",
    "combined_df.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "\n",
    "combined_df['year'] = pd.to_datetime(\n",
    "    combined_df['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y', errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "for year, dfy in combined_df.groupby('year'):\n",
    "    dfy.drop(columns='year').to_csv(f'{output_dir}Training_Score_Master_{year}.csv', index=False, encoding='cp932')\n",
    "\n",
    "del combined_df\n",
    "\n",
    "print(\"完了：追切指数（MAD・ロバスト偏差値版）を出力しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 選択した成績データを加工してマスタファイルへマージ\n",
    "## 2024年分の成績データを2017~2023年の基準タイムファイルを参照して指数を追加\n",
    "## 2024年分の成績データをマスタファイルへマージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:89: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_df1 = pd.read_csv(merged_filepath, encoding='cp932').copy()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1092: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1.insert(insert_pos, 'レースタイプ', ref.map(race_type_map))\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1126: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1['レース強度指数'] = (\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1153: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1['レースレベル指数'] = (rating_diff + speed_diff + strength_diff + 100).round(1)\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1['レース強度指数上位差分']=merged_df1['レース強度指数']-merged_df1['レース強度指数_stdtime1'].fillna(merged_df1['レース強度指数_stdtime2'])\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1177: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1.insert(insert_pos, 'レースレベル判定', band.where(~no_ref, np.nan).astype('Int64'))\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_18128\\2477927498.py:1182: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  merged_df1.insert(insert_pos, 'レースレベル評価', merged_df1['レースレベル判定'].map(band_to_grade))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "from tkinter import Tk, filedialog\n",
    "\n",
    "#---ステップ１：加工する成績データを指定\n",
    "# ファイルパスの指定\n",
    "# 成績データファイルのパス\n",
    "master_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2024_tmp.csv'\n",
    "\n",
    "# 成績データにマージするデータファイルのパス\n",
    "# 初角位置ファイルのパス\n",
    "merge_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\70_First_Corner_Position\\First_Corner_Position_Master.csv'\n",
    "# 2角位置ファイルのパス\n",
    "merge_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\80_Second_Corner_Position\\Second_Corner_Position_Master.csv'\n",
    "# 3角位置ファイルのパス\n",
    "merge_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\90_Third_Corner_Position\\Third_Corner_Position_Master.csv'\n",
    "# 4角位置ファイルのパス\n",
    "merge_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\100_Fourth_Corner_Position\\Fourth_Corner_Position_Master.csv'\n",
    "# 上り位置ファイルのパス\n",
    "merge_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\110_Spurt_Position\\Spurt_Position_Master.csv'\n",
    "# 馬場指数ファイルのパス\n",
    "merge_filepath6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\60_Track_Condition\\Track_Condition_Master.csv'\n",
    "# 前半3Fタイムファイルのパス\n",
    "merge_filepath7 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\120_First3F_Lap\\First3F_Lap_Master.csv'\n",
    "# 追切指数のファイルパス\n",
    "merge_filepath8 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\210_Training_Score\\Training_Score_Master.csv'\n",
    "\n",
    "# 参照先のファイルパス\n",
    "# 基準タイムファイル1の保存先パス\n",
    "ref_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\StdTime1.csv'\n",
    "# 基準タイムファイル2の保存先パス\n",
    "ref_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\StdTime2.csv'\n",
    "# ペース係数ファイルの保存先パス\n",
    "ref_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\PaceTime.csv'\n",
    "# 基準33ラップファイルの保存先パス\n",
    "ref_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\33Lap.csv'\n",
    "# レースレベル基準ファイルのパス\n",
    "ref_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\30_Index\\Times_Data\\RaceLevel.csv'\n",
    "\n",
    "# 保存先パス\n",
    "# テン指数の保存先\n",
    "output_filepath1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\150_First_Score\\First_Score_Master.csv'\n",
    "# 上り指数の保存先\n",
    "output_filepath2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\160_Spurt_Score\\Spurt_Score_Master.csv'\n",
    "# スピード指数の保存先\n",
    "output_filepath3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\170_Speed_Score\\Speed_Score_Master.csv'\n",
    "# 総合指数の保存先\n",
    "output_filepath4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\180_Total_Score\\Total_Score_Master.csv'\n",
    "# 33ラップ判定の保存先\n",
    "output_filepath5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\140_33Lap_Category\\33Lap_Category_Master.csv'\n",
    "# レースレベル判定の保存先\n",
    "output_filepath6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\190_Race_Level\\Race_Level_Master.csv'\n",
    "# 馬タイプ分類のファイルパス\n",
    "output_filepath7 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\220_Horse_Type\\Horse_Type_Master.csv'\n",
    "\n",
    "# テン指数のディレクトリ\n",
    "output_dir1 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\150_First_Score\\\\'\n",
    "# 上り指数のディレクトリ\n",
    "output_dir2 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\160_Spurt_Score\\\\'\n",
    "# スピード指数のディレクトリ\n",
    "output_dir3 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\170_Speed_Score\\\\'\n",
    "# 総合指数のディレクトリ\n",
    "output_dir4 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\180_Total_Score\\\\'\n",
    "# 33ラップ判定のディレクトリ\n",
    "output_dir5 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\140_33Lap_Category\\\\'\n",
    "# レースレベル判定のディレクトリ\n",
    "output_dir6 = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\00_Import_Data\\190_Race_Level\\\\'\n",
    "\n",
    "# 列の並び定義ファイルパス\n",
    "header_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\50_SourceCode\\ResultData_Header.csv'\n",
    "\n",
    "# ファイル選択ダイアログを表示\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "merged_filepath = filedialog.askopenfilename(title=\"CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "\n",
    "# ファイルが選択されなかった場合は終了\n",
    "if not merged_filepath:\n",
    "    print(\"ファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# ---ステップ２：マージする成績データの加工\n",
    "merged_df1 = pd.read_csv(merged_filepath, encoding='cp932').copy()\n",
    "\n",
    "merged_df2 = pd.read_csv(merge_filepath1, encoding='cp932').copy()\n",
    "merged_df3 = pd.read_csv(merge_filepath2, encoding='cp932').copy()\n",
    "merged_df4 = pd.read_csv(merge_filepath3, encoding='cp932').copy()\n",
    "merged_df5 = pd.read_csv(merge_filepath4, encoding='cp932').copy()\n",
    "merged_df6 = pd.read_csv(merge_filepath5, encoding='cp932').copy()\n",
    "merged_df7 = pd.read_csv(merge_filepath6, encoding='cp932').copy()\n",
    "merged_df8 = pd.read_csv(merge_filepath7, encoding='cp932').copy()\n",
    "merged_df9 = pd.read_csv(merge_filepath8, encoding='cp932').copy()\n",
    "\n",
    "#　マージファイルで使用する列だけを定義\n",
    "merged_df2 = merged_df2[['target_horseid','初角サイドポジション']]\n",
    "merged_df3 = merged_df3[['target_horseid','2角サイドポジション']]\n",
    "merged_df4 = merged_df4[['target_horseid','3角サイドポジション']]\n",
    "merged_df5 = merged_df5[['target_horseid','4角サイドポジション']]\n",
    "merged_df6 = merged_df6[['target_horseid','4角位置']]\n",
    "merged_df7 = merged_df7[['target_raceid','馬場指数']]\n",
    "merged_df8 = merged_df8[['target_horseid','前半3F']]\n",
    "merged_df9 = merged_df9[['target_horseid','追切指数']]\n",
    "\n",
    "# カラムの整理\n",
    "# 成績データファイルの列名を変更\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid',\n",
    "    '上り3F': 'レース上り3F',\n",
    "    '上り4F': 'レース上り4F',\n",
    "    '上り5F': 'レース上り5F',\n",
    "    '外部指数1':'レイティング',\n",
    "    '外部指数順1':'レイティング順位',\n",
    "    '外部指数2':'ZI指数',\n",
    "    '外部指数順2':'ZI指数順位',\n",
    "    '外部指数3':'追切指数',\n",
    "    '外部指数順3':'追切指数順位',\n",
    "    '上り3F.1':'上り3F'\n",
    "}\n",
    "\n",
    "# df1の列名に対してrename_mapを適用\n",
    "merged_df1 = merged_df1.rename(columns=rename_map)\n",
    "\n",
    "# キーの型を揃える（数字/ゼロ埋めブレ防止）\n",
    "for c in ['target_horseid', 'target_raceid']:\n",
    "    if c in merged_df1: merged_df1[c] = merged_df1[c].astype(str)\n",
    "for d in [merged_df2, merged_df3, merged_df4, merged_df5, merged_df6, merged_df7, merged_df8, merged_df9]:\n",
    "    for c in ['target_horseid', 'target_raceid']:\n",
    "        if c in d: d[c] = d[c].astype(str)\n",
    "\n",
    "#　種牡馬名のspace削除\n",
    "merged_df1['種牡馬'] = merged_df1['種牡馬'].astype(str).str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# ラベル化する列を追加\n",
    "# コースラベル\n",
    "insert_pos = merged_df1.columns.get_loc('コースグループ名1') + 1\n",
    "merged_df1.insert(insert_pos, 'コースラベル', merged_df1['場所'].astype(str) + '_' + merged_df1['芝・ダート'].astype(str) + '_' + merged_df1['トラックコード(JV)'].astype(str))\n",
    "\n",
    "# 父×母の父タイプ名\n",
    "insert_pos = merged_df1.columns.get_loc('母の父タイプ名') + 1\n",
    "merged_df1.insert(insert_pos, '父×母の父タイプ名', merged_df1['種牡馬'].astype(str) + '×' + merged_df1['母の父タイプ名'].astype(str))\n",
    "\n",
    "# 父タイプ名×母の父タイプ名\n",
    "insert_pos = merged_df1.columns.get_loc('父×母の父タイプ名') + 1\n",
    "merged_df1.insert(insert_pos, '父タイプ名×母の父タイプ名', merged_df1['種牡馬タイプ名'].astype(str) + '×' + merged_df1['母の父タイプ名'].astype(str))\n",
    "\n",
    "# 生産者×馬主\n",
    "insert_pos = merged_df1.columns.get_loc('騎手') + 1\n",
    "merged_df1.insert(insert_pos, '生産者×馬主', merged_df1['生産者'].astype(str) + '×' + merged_df1['馬主'].astype(str))\n",
    "\n",
    "# 生産者×調教師\n",
    "insert_pos = merged_df1.columns.get_loc('生産者×馬主') + 1\n",
    "merged_df1.insert(insert_pos, '生産者×調教師', merged_df1['生産者'].astype(str) + '×' + merged_df1['調教師'].astype(str))\n",
    "\n",
    "# 生産者×騎手\n",
    "insert_pos = merged_df1.columns.get_loc('生産者×調教師') + 1\n",
    "merged_df1.insert(insert_pos, '生産者×騎手', merged_df1['生産者'].astype(str) + '×' + merged_df1['騎手'].astype(str))\n",
    "\n",
    "# 馬主×調教師\n",
    "insert_pos = merged_df1.columns.get_loc('生産者×騎手') + 1\n",
    "merged_df1.insert(insert_pos, '馬主×調教師', merged_df1['馬主'].astype(str) + '×' + merged_df1['調教師'].astype(str))\n",
    "\n",
    "# 馬主×騎手\n",
    "insert_pos = merged_df1.columns.get_loc('馬主×調教師') + 1\n",
    "merged_df1.insert(insert_pos, '馬主×騎手', merged_df1['馬主'].astype(str) + '×' + merged_df1['騎手'].astype(str))\n",
    "\n",
    "# 調教師×騎手\n",
    "insert_pos = merged_df1.columns.get_loc('馬主×騎手') + 1\n",
    "merged_df1.insert(insert_pos, '調教師×騎手', merged_df1['調教師'].astype(str) + '×' + merged_df1['騎手'].astype(str))\n",
    "\n",
    "# 調教師×コースラベル\n",
    "insert_pos = merged_df1.columns.get_loc('調教師×騎手') + 1\n",
    "merged_df1.insert(insert_pos, '調教師×コースラベル', merged_df1['調教師'].astype(str) + '×' + merged_df1['コースラベル'].astype(str))\n",
    "\n",
    "# 騎手×コースラベル\n",
    "insert_pos = merged_df1.columns.get_loc('調教師×コースラベル') + 1\n",
    "merged_df1.insert(insert_pos, '騎手×コースラベル', merged_df1['騎手'].astype(str) + '×' + merged_df1['コースラベル'].astype(str))\n",
    "\n",
    "# 配当金額の列を作成する\n",
    "# 列から取り出す金額の数を定義\n",
    "target_cols = {\n",
    "    '単勝配当表記': ('単勝', 1),\n",
    "    '複勝配当表記': ('複勝', 3),\n",
    "    '枠連配当表記': ('枠連', 1),\n",
    "    '馬連配当表記': ('馬連', 1),\n",
    "    'ワイド配当表記': ('ワイド', 3),\n",
    "    '馬単配当表記': ('馬単', 1),\n",
    "    '３連複配当表記': ('３連複', 1),\n",
    "    '３連単配当表記': ('３連単', 1),\n",
    "}\n",
    "\n",
    "# 金額を取り出す正規表現パターン\n",
    "pattern = re.compile(r'[\\\\¥]\\s*([0-9,]+)(?=\\s*(?:\\(|/|$))')\n",
    "\n",
    "def pick_amounts(text, take=1):\n",
    "    if pd.isna(text):\n",
    "        return [np.nan]*take\n",
    "    s = str(text)\n",
    "    found = pattern.findall(s)\n",
    "    nums = []\n",
    "    for x in found:\n",
    "        try:\n",
    "            nums.append(int(x.replace(',', '')))\n",
    "        except:\n",
    "            # 変な値が来てもスルー\n",
    "            continue\n",
    "    # 必要な個数だけ先頭から取り、足りなければNaNで埋める\n",
    "    nums = nums[:take]\n",
    "    if len(nums) < take:\n",
    "        nums += [np.nan]*(take - len(nums))\n",
    "    return nums\n",
    "\n",
    "for src_col, (base_name, take) in target_cols.items():\n",
    "    if src_col not in merged_df1.columns:\n",
    "        # その列が無い場合はスキップ\n",
    "        continue\n",
    "\n",
    "    # 値を取り出す\n",
    "    values = merged_df1[src_col].apply(lambda x: pick_amounts(x, take))\n",
    "\n",
    "    # 1個だけなら「単勝」のように1列、3個なら「複勝1, 複勝2, 複勝3」の3列を作る\n",
    "    if take == 1:\n",
    "        col_name = base_name\n",
    "        merged_df1[col_name] = values.apply(lambda v: v[0] if isinstance(v, list) else np.nan)\n",
    "        # Convert to integer, coercing errors to NaN\n",
    "        merged_df1[col_name] = pd.to_numeric(merged_df1[col_name], errors='coerce').astype('Int64')\n",
    "    else:\n",
    "        for i in range(take):\n",
    "            col_name = f'{base_name}{i+1}'\n",
    "            merged_df1[col_name] = values.apply(lambda v: v[i] if isinstance(v, list) and len(v) > i else np.nan)\n",
    "            # Convert to integer, coercing errors to NaN\n",
    "            merged_df1[col_name] = pd.to_numeric(merged_df1[col_name], errors='coerce').astype('Int64')\n",
    "\n",
    "# 成績データファイルへ対象データをマージする\n",
    "# 初角位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df2, on='target_horseid', how='left')\n",
    "# 2角位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df3, on='target_horseid', how='left')\n",
    "# 3角位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df4, on='target_horseid', how='left')\n",
    "# 4角位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df5, on='target_horseid', how='left')\n",
    "# 上り位置のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df6, on='target_horseid', how='left')\n",
    "# 馬場指数のマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df7, on='target_raceid', how='left')\n",
    "# 前半3Fのマージ\n",
    "merged_df1 = pd.merge(merged_df1, merged_df8, on='target_horseid', how='left')\n",
    "# 追切指数の代入 とりあえずTrueで上書き\n",
    "left  = merged_df1.set_index('target_horseid')\n",
    "right = merged_df9[['target_horseid','追切指数']].dropna(subset=['追切指数']).set_index('target_horseid')\n",
    "left.update(right, overwrite=True)\n",
    "merged_df1 = left.reset_index()\n",
    "\n",
    "# 不要なデータフレームをクリア\n",
    "del merged_df2\n",
    "del merged_df3\n",
    "del merged_df4\n",
    "del merged_df5\n",
    "del merged_df6\n",
    "del merged_df7\n",
    "del merged_df8\n",
    "\n",
    "# --- 関数群 ---\n",
    "def calculate_33_lap(merged_df1):\n",
    "    \"\"\"距離ごとに33ラップを計算する\"\"\"\n",
    "    rap_33 = []\n",
    "    distance_to_lap_range = {\n",
    "        1000: (0, 3),\n",
    "        1200: (0, 3),\n",
    "        1300: (1, 4),\n",
    "        1400: (1, 4),\n",
    "        1500: (2, 5),\n",
    "        1600: (2, 5),\n",
    "        1700: (3, 6),\n",
    "        1800: (3, 6),\n",
    "        1900: (4, 7),\n",
    "        2000: (4, 7),\n",
    "        2100: (5, 8),\n",
    "        2200: (5, 8),\n",
    "        2300: (6, 9),\n",
    "        2400: (6, 9),\n",
    "        2500: (7, 10),\n",
    "        2600: (7, 10),\n",
    "        2700: (8, 11),\n",
    "        2800: (8, 11),\n",
    "        2900: (9, 12),\n",
    "        3000: (9, 12),\n",
    "        3100: (10, 13),\n",
    "        3200: (10, 13),\n",
    "        3300: (11, 14),\n",
    "        3400: (11, 14),\n",
    "        3500: (12, 15),\n",
    "        3600: (12, 15),\n",
    "    }\n",
    "    for _, row in merged_df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_lap_range:\n",
    "            start, end = distance_to_lap_range[distance]\n",
    "            sum_6to4 = sum(lap_times[start:end])\n",
    "        elif distance == 1150:\n",
    "            sum_6to4 = round(lap_times[0] * 1.25, 1) + lap_times[1] + lap_times[2] if len(lap_times) >= 3 else None\n",
    "        else:\n",
    "            sum_6to4 = None\n",
    "        sum_3to1 = row['レース上り3F'] if 'レース上り3F' in row and not pd.isna(row['レース上り3F']) else None\n",
    "        rap_33_value = sum_6to4 - sum_3to1 if not pd.isna(sum_6to4) and not pd.isna(sum_3to1) else None\n",
    "        rap_33.append(rap_33_value)\n",
    "    merged_df1['33ラップ'] = rap_33\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_middle_lap(merged_df1):\n",
    "    \"\"\"距離ごとに中盤ラップ1・2を計算する\"\"\"\n",
    "    middle_lap1 = []\n",
    "    middle_lap2 = []\n",
    "    distance_to_mid_lap = {\n",
    "        1000: (2, 4, None, None),\n",
    "        1150: (2, 4, None, None),\n",
    "        1200: (2, 4, None, None),\n",
    "        1300: (2, 4, None, None),\n",
    "        1400: (2, 4, None, None),\n",
    "        1500: (3, 5, None, None),\n",
    "        1600: (3, 5, None, None),\n",
    "        1700: (3, 6, None, None),\n",
    "        1800: (3, 6, None, None),\n",
    "        1900: (3, 7, None, None),\n",
    "        2000: (3, 7, None, None),\n",
    "        2100: (3, 5, 5, 8),\n",
    "        2200: (3, 5, 5, 8),\n",
    "        2300: (3, 5, 5, 8),\n",
    "        2400: (3, 6, 6, 9),\n",
    "        2500: (3, 6, 6, 9),\n",
    "        2600: (3, 7, 7, 10),\n",
    "        3000: (3, 8, 8, 12),\n",
    "        3200: (3, 8, 8, 13),\n",
    "        3400: (3, 9, 9, 14),\n",
    "        3600: (3, 9, 9, 15),\n",
    "    }\n",
    "    for _, row in merged_df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_mid_lap:\n",
    "            mid1_start, mid1_end, mid2_start, mid2_end = distance_to_mid_lap[distance]\n",
    "            mid1 = sum(lap_times[mid1_start:mid1_end]) if mid1_start is not None else None\n",
    "            mid2 = sum(lap_times[mid2_start:mid2_end]) if mid2_start is not None else None\n",
    "        else:\n",
    "            mid1 = None\n",
    "            mid2 = None\n",
    "        middle_lap1.append(mid1)\n",
    "        middle_lap2.append(mid2)\n",
    "    merged_df1['中盤ラップ1'] = middle_lap1\n",
    "    merged_df1['中盤ラップ2'] = middle_lap2\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_lap_features(df):\n",
    "    \"\"\"\n",
    "    Lap01～Lap25 を使って\n",
    "      ・最大加速（隣接ラップ差分の最小値）\n",
    "      ・ゴール前ラップ差（ラスト1F - ラスト2F）\n",
    "    を計算して df に列を追加する。\n",
    "    \"\"\"\n",
    "    lap_cols = [f'Lap{str(i).zfill(2)}' for i in range(1, 26)]\n",
    "\n",
    "    def _calc_row(row):\n",
    "        # その馬のラップ一覧（NaN は除外）\n",
    "        laps = []\n",
    "        for c in lap_cols:\n",
    "            if c in row.index and pd.notna(row[c]):\n",
    "                laps.append(row[c])\n",
    "\n",
    "        # ラップが1つ以下ならどっちも計算不能\n",
    "        if len(laps) < 2:\n",
    "            return pd.Series({'最大加速ラップ': np.nan, 'ゴール前ラップ差': np.nan})\n",
    "\n",
    "        laps = np.array(laps, dtype=float)\n",
    "\n",
    "        # 隣り合う差分（後ろ - 前）\n",
    "        diffs = np.diff(laps)   # 例：Lap02-Lap01, Lap03-Lap02, ...\n",
    "\n",
    "        # 最大加速 = 最もマイナスが大きい差分（＝最小値）\n",
    "        max_accel = diffs.min() if len(diffs) > 0 else np.nan\n",
    "\n",
    "        # 終盤ラップ差 = ラスト1F - ラスト2F\n",
    "        last_diff = laps[-1] - laps[-2] if len(laps) >= 2 else np.nan\n",
    "\n",
    "        return pd.Series({\n",
    "            '最大加速ラップ': max_accel if pd.notna(max_accel) else np.nan,\n",
    "            'ゴール前ラップ差': last_diff if pd.notna(last_diff) else np.nan\n",
    "        })\n",
    "\n",
    "    new_cols = df.apply(_calc_row, axis=1)\n",
    "    df['最大加速ラップ'] = new_cols['最大加速ラップ'].round(1)\n",
    "    df['ゴール前ラップ差'] = new_cols['ゴール前ラップ差'].round(1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def calculate_days_since_birth(merged_df1):\n",
    "    \"\"\"生後日数を計算する\"\"\"\n",
    "    birth_days = []\n",
    "    for _, row in merged_df1.iterrows():\n",
    "        race_date = datetime.strptime(row['日付S'], '%Y.%m.%d')\n",
    "        birth_str = row['誕生日'].replace(\" \", \"\").replace(\"日\", \"\").replace(\"-\", \"\")\n",
    "        birth_month, birth_day = map(int, birth_str.replace(\"月\", \" \").split())\n",
    "        birth_year = race_date.year - row['年齢']\n",
    "        try:\n",
    "            birth_date = datetime(birth_year, birth_month, birth_day)\n",
    "        except ValueError:\n",
    "            birth_date = datetime(birth_year, 2, 28)\n",
    "        days_old = (race_date - birth_date).days\n",
    "        birth_days.append(days_old)\n",
    "    merged_df1['生後日数'] = birth_days\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_distance_diff(merged_df1):\n",
    "    \"\"\"前走距離との差を計算する\"\"\"\n",
    "    merged_df1['前走距離差'] = merged_df1['距離'] - merged_df1['前走距離']\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_firsthalf_diff(merged_df1):\n",
    "    \"\"\"初角から4角位置の差分を計算\"\"\"\n",
    "    merged_df1['初角_4角差'] = merged_df1.apply(lambda row:\n",
    "        (row['通過1'] - row['通過4']) if pd.notna(row['通過1']) else \\\n",
    "        ((row['通過2'] - row['通過4']) if pd.notna(row['通過2']) else \\\n",
    "        ((row['通過3'] - row['通過4']) if pd.notna(row['通過3']) else np.nan))\n",
    "    , axis=1).fillna(0)\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_goal_diff(merged_df1):\n",
    "    \"\"\"4角から入線順位の差分を計算\"\"\"\n",
    "    # 入線順位を一時的に数値化\n",
    "    rank_num = pd.to_numeric(merged_df1['入線順位'], errors='coerce')\n",
    "\n",
    "    # 有効な順位（1以上）だけを判定するためのマスク\n",
    "    valid_mask = rank_num >= 1\n",
    "\n",
    "    # 出力列だけ作る\n",
    "    merged_df1['4角_入線順位差'] = np.nan\n",
    "\n",
    "    # 有効な行だけ計算\n",
    "    merged_df1.loc[valid_mask, '4角_入線順位差'] = (\n",
    "        pd.to_numeric(merged_df1.loc[valid_mask, '通過4'], errors='coerce')\n",
    "        - rank_num[valid_mask]\n",
    "    )\n",
    "\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_sideposition(merged_df1):\n",
    "    \"\"\"サイドポジションの平均を計算する\"\"\"\n",
    "    cols = ['初角サイドポジション', '2角サイドポジション', '3角サイドポジション', '4角サイドポジション']\n",
    "    merged_df1['サイドポジション平均'] = merged_df1[cols].mean(axis=1)\n",
    "    return merged_df1\n",
    "\n",
    "def calculate_totalprize(merged_df1):\n",
    "    \"\"\"獲得賞金を計算する\"\"\"\n",
    "    merged_df1['獲得賞金'] = merged_df1['賞金'].fillna(0) + merged_df1['付加賞金'].fillna(0)\n",
    "    return merged_df1\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "    \"\"\"タイム表記を秒数に変換\"\"\"\n",
    "    try:\n",
    "        parts = time_str.split(\".\")\n",
    "        if len(parts) == 3:\n",
    "            minutes, seconds, tenths = map(int, parts)\n",
    "            total_seconds = minutes * 60 + seconds + tenths * 0.1\n",
    "        else:\n",
    "            return np.nan\n",
    "        return total_seconds\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def remove_plus_sign(value):\n",
    "    \"\"\"数値データから `+` を削除して変換\"\"\"\n",
    "    try:\n",
    "        return float(str(value).replace(\"+\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def extract_weight(value):\n",
    "    \"\"\"斤量の数値部分だけを抽出\"\"\"\n",
    "    try:\n",
    "        match = re.search(r'\\d+', str(value))\n",
    "        return int(match.group()) if match else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_corner_loss(row):\n",
    "    \"\"\"コーナーロスを計算\"\"\"\n",
    "    corner_positions = [\n",
    "        row.get('初角サイドポジション', 1) - 1,\n",
    "        row.get('2角サイドポジション', 1) - 1,\n",
    "        row.get('3角サイドポジション', 1) - 1,\n",
    "        row.get('4角サイドポジション', 1) - 1\n",
    "    ]\n",
    "    total_distance_loss = sum(corner_positions) * 1.5  # m単位\n",
    "    finish_time_seconds = row['タイムS']\n",
    "    distance_m = row['距離']\n",
    "    if pd.isna(finish_time_seconds) or pd.isna(distance_m) or finish_time_seconds == 0:\n",
    "        return np.nan\n",
    "    avg_speed = distance_m / finish_time_seconds if finish_time_seconds > 0 else np.nan\n",
    "    corner_loss = total_distance_loss / avg_speed if avg_speed > 0 else 0\n",
    "    return round(corner_loss, 2)\n",
    "\n",
    "# 各列の整形\n",
    "# 対象の列を数値変換\n",
    "merged_df1['馬場指数'] = merged_df1['馬場指数'].astype(str).str.extract(r'(-?\\d+)')[0].astype('Int64')\n",
    "merged_df1['レイティング'] = pd.to_numeric(merged_df1['レイティング'], errors='coerce')\n",
    "merged_df1['体重'] = pd.to_numeric(merged_df1['体重'], errors='coerce')\n",
    "merged_df1['Ave-3F'] = pd.to_numeric(merged_df1['Ave-3F'], errors='coerce')\n",
    "merged_df1['上り3F'] = pd.to_numeric(merged_df1['上り3F'], errors='coerce')\n",
    "\n",
    "# 対象の列から記号を除去\n",
    "for col in ['前後3F差', '前後4F差', '前後5F差', '増減']:\n",
    "    merged_df1[col] = merged_df1[col].apply(remove_plus_sign)\n",
    "\n",
    "merged_df1['斤量'] = merged_df1['斤量'].apply(extract_weight)\n",
    "\n",
    "# タイムを秒数に変換\n",
    "merged_df1['タイムS'] = merged_df1['タイムS'].apply(convert_time_to_seconds)\n",
    "merged_df1['-3Fタイム'] = merged_df1['-3Fタイム'].apply(convert_time_to_seconds)\n",
    "\n",
    "# 決め手列を変換(マップにない場合はNanにする)\n",
    "lq_mapping = {\n",
    "    '中団': '差し',\n",
    "    '後方': '追込',\n",
    "}\n",
    "\n",
    "s = merged_df1['決め手'].astype('string').str.strip()\n",
    "merged_df1['決め手'] = s.map(lq_mapping)\n",
    "\n",
    "# 各種計算関数を順次実行\n",
    "# 33ラップの計算\n",
    "merged_df1 = calculate_33_lap(merged_df1)\n",
    "# 中盤ラップ1・2の計算\n",
    "merged_df1 = calculate_middle_lap(merged_df1)\n",
    "# 最大加速ラップ・ゴール前ラップ差の計算\n",
    "merged_df1 = calculate_lap_features(merged_df1)\n",
    "# 生後日数の計算\n",
    "merged_df1 = calculate_days_since_birth(merged_df1)\n",
    "# 前走距離差の計算\n",
    "merged_df1 = calculate_distance_diff(merged_df1)\n",
    "# 初角から4角通過順位差の計算\n",
    "merged_df1 = calculate_firsthalf_diff(merged_df1)\n",
    "# 4角から入線順位差の計算\n",
    "merged_df1 = calculate_goal_diff(merged_df1)\n",
    "# サイドポジション平均値の計算\n",
    "merged_df1 = calculate_sideposition(merged_df1)\n",
    "# 獲得賞金の計算\n",
    "merged_df1 = calculate_totalprize(merged_df1)\n",
    "# 基準斤量の計算\n",
    "merged_df1['基準斤量'] = merged_df1['斤量'] - merged_df1['馬齢斤量差']\n",
    "# RPCI差の計算\n",
    "merged_df1['RPCI差'] = merged_df1['PCI'] - merged_df1['レースPCI']\n",
    "# コーナーロスの計算\n",
    "merged_df1['コーナーロス'] = merged_df1.apply(calculate_corner_loss, axis=1)\n",
    "# 補正走破タイムの計算\n",
    "merged_df1['補正走破タイム'] = merged_df1['タイムS'] - merged_df1['コーナーロス']\n",
    "# スローorハイ関数の計算\n",
    "merged_df1['スローorハイ関数'] = merged_df1['Ave-3F'] - merged_df1['上り3F']\n",
    "\n",
    "# マージ用の列作成処理\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 115:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 範囲定義\n",
    "ranges = [ (-np.inf, -4.6), (-4.6, -3.6), (-3.6, -2.6), (-2.6, -1.6), (-1.6, -0.6), (-0.6, 0.6), (0.6, 1.6), (1.6, 2.6), (2.6, 3.6), (3.6, 4.6), (4.6, np.inf) ]\n",
    "\n",
    "# 区間ラベル\n",
    "def assign_range(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        if i < len(ranges) - 1:\n",
    "            if lower <= value < upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "        else:\n",
    "            # 最終区間（4.6～inf）は右も含める\n",
    "            if lower <= value <= upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "    return np.nan  # 念のため\n",
    "\n",
    "# 馬場分類・競走種別・クラス分類・スローor関数範囲の列を作成する\n",
    "merged_df1['馬場分類'] = merged_df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "merged_df1['競走種別'] = merged_df1['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "merged_df1['クラス分類'] = merged_df1['クラスコード'].apply(categorize_class_code)\n",
    "merged_df1['スローorハイ関数範囲'] = merged_df1['スローorハイ関数'].apply(assign_range)\n",
    "\n",
    "# 共通関数：参照側DFのキー以外の列にサフィックスを付ける\n",
    "def prepare_ref_df(df_ref, merge_keys, suffix):\n",
    "    \"\"\"\n",
    "    マージ用の参照DFの列名に suffix を付ける（キー列以外すべて）\n",
    "    \"\"\"\n",
    "    df_ref = df_ref.copy()\n",
    "    rename_map = {\n",
    "        c: f\"{c}{suffix}\"\n",
    "        for c in df_ref.columns\n",
    "        if c not in merge_keys\n",
    "    }\n",
    "    df_ref = df_ref.rename(columns=rename_map)\n",
    "    return df_ref\n",
    "\n",
    "# マージキー\n",
    "merge_key1 = ['場所','芝・ダート','距離','トラックコード(JV)','馬場分類']\n",
    "merge_key2 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類','馬場分類']\n",
    "merge_key3 = ['場所','芝・ダート','距離','トラックコード(JV)','スローorハイ関数範囲']\n",
    "merge_key4 = ['場所','芝・ダート','距離','トラックコード(JV)']\n",
    "merge_key5 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類']\n",
    "\n",
    "# 基準タイム等データフレームの読み込み\n",
    "base_time_df1 = pd.read_csv(ref_filepath1, encoding='cp932')\n",
    "base_time_df2 = pd.read_csv(ref_filepath2, encoding='cp932')\n",
    "pace_medians_df = pd.read_csv(ref_filepath3, encoding='cp932')\n",
    "lap33_df = pd.read_csv(ref_filepath4, encoding='cp932')\n",
    "racelevel_df = pd.read_csv(ref_filepath5, encoding='cp932')\n",
    "\n",
    "# 参照側の列名にsuffixを付与\n",
    "base_time_df1 = prepare_ref_df(base_time_df1, merge_key1, '_stdtime1').copy()\n",
    "base_time_df2 = prepare_ref_df(base_time_df2, merge_key2, '_stdtime2').copy()\n",
    "pace_medians_df = prepare_ref_df(pace_medians_df, merge_key3, '_paceindex').copy()\n",
    "lap33_df = prepare_ref_df(lap33_df, merge_key4, '_33lap').copy()\n",
    "racelevel_df = prepare_ref_df(racelevel_df, merge_key5, '_racelevel').copy()\n",
    "\n",
    "# merged_df1へその他データフレームをマージ\n",
    "merged_df1 = pd.merge(merged_df1, base_time_df1, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, base_time_df2, on=merge_key2, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, pace_medians_df, on=merge_key3, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, lap33_df, on=merge_key4, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, racelevel_df, on=merge_key5, how='left')\n",
    "\n",
    "# ---ステップ３：成績データに指数追加\n",
    "# 各指数算出の前処理\n",
    "# 基準タイム/距離係数のベース列を作る（Std1優先、なければStd2）\n",
    "base_time = merged_df1['タイムS_stdtime1'].fillna(merged_df1['タイムS_stdtime2'])\n",
    "dist_coef = merged_df1['距離係数_stdtime1'].fillna(merged_df1['距離係数_stdtime2'])\n",
    "\n",
    "# 基準タイム差（秒）：基準タイム - 補正走破タイム\n",
    "base_time_diff = base_time - merged_df1['補正走破タイム']\n",
    "\n",
    "# 基準タイム差×距離係数\n",
    "speed_core = base_time_diff * dist_coef\n",
    "\n",
    "# 平均3F補正値\n",
    "ave3f_base = merged_df1['Ave-3F_stdtime1'].fillna(merged_df1['Ave-3F_stdtime2'])\n",
    "revi_Ave3F = ave3f_base - merged_df1['Ave-3F']\n",
    "\n",
    "# 斤量補正値\n",
    "revi_weight = merged_df1['斤量'] - merged_df1['基準斤量']\n",
    "\n",
    "# クラス補正値（Std1が存在する行だけ有効。Std2代用行では0）\n",
    "# ※ Std1が無い = その条件の1・2勝基準が作れない想定なので、クラス補正は入れない\n",
    "revi_class = (merged_df1['タイムS_stdtime1'] - merged_df1['タイムS_stdtime2']).where(\n",
    "    merged_df1['タイムS_stdtime1'].notna(), 0\n",
    ")\n",
    "\n",
    "# ペース補正値\n",
    "revi_pace = merged_df1['スローorハイ関数'] * merged_df1['ペース補正係数_paceindex']\n",
    "\n",
    "# 馬場指数秒数換算\n",
    "merged_df1['馬場補正値'] = merged_df1['馬場指数'] / 10\n",
    "\n",
    "# 初角位置\n",
    "merged_df1['初角位置'] = (\n",
    "    merged_df1['通過1']\n",
    "      .fillna(merged_df1['通過2'])\n",
    "      .fillna(merged_df1['通過3'])\n",
    "      .fillna(merged_df1['通過4'])\n",
    ")\n",
    "\n",
    "# テン指数の計算\n",
    "merged_df1['テン指数'] = round((\n",
    "(merged_df1['前半3F_stdtime1'].fillna(merged_df1['前半3F_stdtime2']) - merged_df1['前半3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数'] - merged_df1['初角位置'] + 1) / merged_df1['頭数']) # 初角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# 上り指数の計算\n",
    "merged_df1['上り指数'] = round((\n",
    "(merged_df1['上り3F_stdtime1'].fillna(merged_df1['上り3F_stdtime2']) - merged_df1['上り3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数']) - merged_df1['入線順位'] + 1) / merged_df1['頭数'] # 着順評価\n",
    "+ (merged_df1['通過4'] - merged_df1['入線順位']) / merged_df1['頭数'] # ポジション押し上げ力評価\n",
    "+ (merged_df1['頭数'] - merged_df1['通過4'] + 1) / merged_df1['頭数'] # 4角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# スピード指数の計算 ---\n",
    "merged_df1['スピード指数'] = (\n",
    "    (\n",
    "        speed_core\n",
    "        + merged_df1['馬場補正値'].fillna(0)\n",
    "        + revi_Ave3F.fillna(0)\n",
    "        + revi_weight.fillna(0)\n",
    "        + revi_class.fillna(0)\n",
    "        + revi_pace.fillna(0)\n",
    "        + 100\n",
    "    )\n",
    "    .round(1)\n",
    "    .where(speed_core.notna() & (speed_core != 0))\n",
    ")\n",
    "\n",
    "# 総合指数の計算\n",
    "merged_df1['総合指数'] = merged_df1[['スピード指数', '補正タイム', '補9']].mean(axis=1).round(1)\n",
    "\n",
    "# 総合指数の代表値(1着～3着)をdf1へ追加\n",
    "central_score_df1 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "central_score_df1 = central_score_df1.groupby('target_raceid' ,as_index = False)['総合指数'].mean()\n",
    "central_score_df1.rename(columns={'総合指数': 'Top3総合指数'}, inplace=True)\n",
    "central_score_df1['Top3総合指数'] = round(central_score_df1['Top3総合指数'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df1, on='target_raceid', how='left',suffixes=('', '_centralscore1')).copy()\n",
    "\n",
    "# レイティングの平均値を成績データへ追加\n",
    "merged_df1['レイティング'] = pd.to_numeric(merged_df1['レイティング'], errors='coerce')\n",
    "central_score_df2 = merged_df1.groupby('target_raceid' ,as_index = False)['レイティング'].mean().copy()\n",
    "central_score_df2.rename(columns={'レイティング': 'レイティング平均値'}, inplace=True)\n",
    "central_score_df2['レイティング平均値'] = round(central_score_df2['レイティング平均値'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df2, on='target_raceid', how='left' ,suffixes=('', '_centralscore2')).copy()\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del central_score_df1\n",
    "del central_score_df2\n",
    "\n",
    "# 各指数の偏差値を計算\n",
    "def deviation_in_race(series):\n",
    "    mean = series.mean()\n",
    "    std = series.std()\n",
    "    if pd.isna(std) or std == 0:\n",
    "        return pd.Series(np.nan, index=series.index)\n",
    "    return ((series - mean) / std * 10 + 50)\n",
    "\n",
    "# レース内偏差値\n",
    "merged_df1['レイティング偏差値'] = (merged_df1.groupby('target_raceid')['レイティング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['ZI指数偏差値'] = (merged_df1.groupby('target_raceid')['ZI指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['追切指数偏差値'] = (merged_df1.groupby('target_raceid')['追切指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['マイニング偏差値'] = (merged_df1.groupby('target_raceid')['マイニング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['対戦型マイニング偏差値'] = (merged_df1.groupby('target_raceid')['対戦型マイニング'].transform(deviation_in_race).round(1))\n",
    "merged_df1['前半3F偏差値'] = merged_df1.groupby('target_raceid')['前半3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['上り3F偏差値'] = merged_df1.groupby('target_raceid')['上り3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['Ave-3F偏差値'] = merged_df1.groupby('target_raceid')['Ave-3F'].transform(lambda s: deviation_in_race(-s)).round(1)\n",
    "merged_df1['テン指数偏差値'] = (merged_df1.groupby('target_raceid')['テン指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['上り指数偏差値'] = (merged_df1.groupby('target_raceid')['上り指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['スピード指数偏差値'] = (merged_df1.groupby('target_raceid')['スピード指数'].transform(deviation_in_race).round(1))\n",
    "merged_df1['総合指数偏差値'] = (merged_df1.groupby('target_raceid')['総合指数'].transform(deviation_in_race).round(1))\n",
    "\n",
    "# レース内順位（dense）\n",
    "merged_df1['前半3F順位'] = (merged_df1.groupby('target_raceid')['前半3F'].rank(ascending=True, method='dense').astype('Int64'))\n",
    "merged_df1['テン指数順位'] = (merged_df1.groupby('target_raceid')['テン指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['上り指数順位'] = (merged_df1.groupby('target_raceid')['上り指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['Ave-3F順位'] = (merged_df1.groupby('target_raceid')['Ave-3F'].rank(ascending=True, method='dense').astype('Int64'))\n",
    "merged_df1['スピード指数順位'] = (merged_df1.groupby('target_raceid')['スピード指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "merged_df1['総合指数順位'] = (merged_df1.groupby('target_raceid')['総合指数'].rank(ascending=False, method='dense').astype('Int64'))\n",
    "\n",
    "# 順位分布の計算\n",
    "merged_df1['レイティング順位分布'] = (merged_df1['レイティング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['ZI指数順位分布'] = (merged_df1['ZI指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['追切指数順位分布'] = (merged_df1['追切指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['マイニング順位分布'] = (merged_df1['マイニング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['対戦型マイニング順位分布'] = (merged_df1['対戦型マイニング順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['前半3F順位分布'] = (merged_df1['前半3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['テン指数順位分布'] = (merged_df1['テン指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['上り3F順位分布'] = (merged_df1['上り3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['上り指数順位分布'] = (merged_df1['上り指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['Ave-3F順位分布'] = (merged_df1['Ave-3F順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['スピード指数順位分布'] = (merged_df1['スピード指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "merged_df1['総合指数順位分布'] = (merged_df1['総合指数順位'] - 1) / (merged_df1['頭数'] - 1)\n",
    "\n",
    "# ---ステップ４：基準タイムとの指数差追加\n",
    "# Top3総合指数と総合指数の差分を成績データへ追加\n",
    "merged_df1['Top3総合指数差分'] = merged_df1['総合指数'] - merged_df1['Top3総合指数']\n",
    "\n",
    "# レイティング平均値とレイティングの差分を追加\n",
    "merged_df1['平均レイティング差分'] = merged_df1['レイティング'] - merged_df1['レイティング平均値']\n",
    "\n",
    "# PCI3：基準タイム１差分\n",
    "merged_df1['PCI3差分']=merged_df1['PCI3']-merged_df1['PCI3_stdtime1'].fillna(merged_df1['PCI3_stdtime2'])\n",
    "\n",
    "# PCI：基準タイム１差分\n",
    "merged_df1['PCI上位差分']=merged_df1['PCI']-merged_df1['PCI_stdtime1'].fillna(merged_df1['PCI_stdtime2'])\n",
    "merged_df1['PCI勝馬差分']=merged_df1['PCI']-merged_df1['PCI_1着_stdtime1'].fillna(merged_df1['PCI_1着_stdtime2'])\n",
    "\n",
    "# 生後日数：基準タイム２差分\n",
    "merged_df1['生後日数上位差分']=merged_df1['生後日数']-merged_df1['生後日数_stdtime2'].fillna(merged_df1['生後日数_stdtime1'])\n",
    "merged_df1['生後日数勝馬差分']=merged_df1['生後日数']-merged_df1['生後日数_1着_stdtime2'].fillna(merged_df1['生後日数_1着_stdtime1'])\n",
    "\n",
    "# 馬体重：基準タイム２差分\n",
    "merged_df1['体重上位差分']=merged_df1['体重']-merged_df1['体重_stdtime2'].fillna(merged_df1['体重_stdtime1'])\n",
    "merged_df1['体重勝馬差分']=merged_df1['体重']-merged_df1['体重_1着_stdtime2'].fillna(merged_df1['体重_1着_stdtime1'])\n",
    "\n",
    "# 馬体重斤量比：基準タイム２差分\n",
    "merged_df1['斤量馬体重比上位差分']=merged_df1['斤量馬体重比']-merged_df1['斤量馬体重比_stdtime2'].fillna(merged_df1['斤量馬体重比_stdtime1'])\n",
    "merged_df1['斤量馬体重比勝馬差分']=merged_df1['斤量馬体重比']-merged_df1['斤量馬体重比_1着_stdtime2'].fillna(merged_df1['斤量馬体重比_1着_stdtime1'])\n",
    "\n",
    "# 前走距離：基準タイム１差分\n",
    "merged_df1['前走距離上位差分']=merged_df1['前走距離']-merged_df1['前走距離_stdtime1'].fillna(merged_df1['前走距離_stdtime2'])\n",
    "merged_df1['前走距離勝馬差分']=merged_df1['前走距離']-merged_df1['前走距離_1着_stdtime1'].fillna(merged_df1['前走距離_1着_stdtime2'])\n",
    "\n",
    "# 前走距離差：基準タイム１差分\n",
    "merged_df1['前走距離差上位差分']=merged_df1['前走距離差']-merged_df1['前走距離差_stdtime1'].fillna(merged_df1['前走距離差_stdtime2'])\n",
    "merged_df1['前走距離差勝馬差分']=merged_df1['前走距離差']-merged_df1['前走距離差_1着_stdtime1'].fillna(merged_df1['前走距離差_1着_stdtime2'])\n",
    "\n",
    "# レイティング：基準タイム１差分\n",
    "merged_df1['レイティング上位差分']=merged_df1['レイティング']-merged_df1['レイティング_stdtime1'].fillna(merged_df1['レイティング_stdtime2'])\n",
    "merged_df1['レイティング勝馬差分']=merged_df1['レイティング']-merged_df1['レイティング_1着_stdtime1'].fillna(merged_df1['レイティング_1着_stdtime2'])\n",
    "\n",
    "# レイティング偏差値：基準タイム１差分\n",
    "merged_df1['レイティング偏差値上位差分']=merged_df1['レイティング偏差値']-merged_df1['レイティング偏差値_stdtime1'].fillna(merged_df1['レイティング偏差値_stdtime2'])\n",
    "merged_df1['レイティング偏差値勝馬差分']=merged_df1['レイティング偏差値']-merged_df1['レイティング偏差値_1着_stdtime1'].fillna(merged_df1['レイティング偏差値_1着_stdtime2'])\n",
    "\n",
    "# レイティング順位分布：基準タイム１差分\n",
    "merged_df1['レイティング順位分布上位差分']=merged_df1['レイティング順位分布']-merged_df1['レイティング順位分布_stdtime1'].fillna(merged_df1['レイティング順位分布_stdtime2'])\n",
    "merged_df1['レイティング順位分布勝馬差分']=merged_df1['レイティング順位分布']-merged_df1['レイティング順位分布_1着_stdtime1'].fillna(merged_df1['レイティング順位分布_1着_stdtime2'])\n",
    "\n",
    "# ZI指数：基準タイム１差分\n",
    "merged_df1['ZI指数上位差分']=merged_df1['ZI指数']-merged_df1['ZI指数_stdtime1'].fillna(merged_df1['ZI指数_stdtime2'])\n",
    "merged_df1['ZI指数勝馬差分']=merged_df1['ZI指数']-merged_df1['ZI指数_1着_stdtime1'].fillna(merged_df1['ZI指数_1着_stdtime2'])\n",
    "\n",
    "# ZI指数偏差値：基準タイム１差分\n",
    "merged_df1['ZI指数偏差値上位差分']=merged_df1['ZI指数偏差値']-merged_df1['ZI指数偏差値_stdtime1'].fillna(merged_df1['ZI指数偏差値_stdtime2'])\n",
    "merged_df1['ZI指数偏差値勝馬差分']=merged_df1['ZI指数偏差値']-merged_df1['ZI指数偏差値_1着_stdtime1'].fillna(merged_df1['ZI指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# ZI指数順位分布：基準タイム１差分\n",
    "merged_df1['ZI指数順位分布上位差分']=merged_df1['ZI指数順位分布']-merged_df1['ZI指数順位分布_stdtime1'].fillna(merged_df1['ZI指数順位分布_stdtime2'])\n",
    "merged_df1['ZI指数順位分布勝馬差分']=merged_df1['ZI指数順位分布']-merged_df1['ZI指数順位分布_1着_stdtime1'].fillna(merged_df1['ZI指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# 追切指数：基準タイム１差分\n",
    "merged_df1['追切指数上位差分']=merged_df1['追切指数']-merged_df1['追切指数_stdtime1'].fillna(merged_df1['追切指数_stdtime2'])\n",
    "merged_df1['追切指数勝馬差分']=merged_df1['追切指数']-merged_df1['追切指数_1着_stdtime1'].fillna(merged_df1['追切指数_1着_stdtime2'])\n",
    "\n",
    "# 追切指数偏差値：基準タイム１差分\n",
    "merged_df1['追切指数偏差値上位差分']=merged_df1['追切指数偏差値']-merged_df1['追切指数偏差値_stdtime1'].fillna(merged_df1['追切指数偏差値_stdtime2'])\n",
    "merged_df1['追切指数偏差値勝馬差分']=merged_df1['追切指数偏差値']-merged_df1['追切指数偏差値_1着_stdtime1'].fillna(merged_df1['追切指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# 追切指数順位分布：基準タイム１差分\n",
    "merged_df1['追切指数順位分布上位差分']=merged_df1['追切指数順位分布']-merged_df1['追切指数順位分布_stdtime1'].fillna(merged_df1['追切指数順位分布_stdtime2'])\n",
    "merged_df1['追切指数順位分布勝馬差分']=merged_df1['追切指数順位分布']-merged_df1['追切指数順位分布_1着_stdtime1'].fillna(merged_df1['追切指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# マイニング：基準タイム１差分\n",
    "merged_df1['マイニング上位差分']=merged_df1['マイニング']-merged_df1['マイニング_stdtime1'].fillna(merged_df1['マイニング_stdtime2'])\n",
    "merged_df1['マイニング勝馬差分']=merged_df1['マイニング']-merged_df1['マイニング_1着_stdtime1'].fillna(merged_df1['マイニング_1着_stdtime2'])\n",
    "\n",
    "# マイニング偏差値：基準タイム１差分\n",
    "merged_df1['マイニング偏差値上位差分']=merged_df1['マイニング偏差値']-merged_df1['マイニング偏差値_stdtime1'].fillna(merged_df1['マイニング偏差値_stdtime2'])\n",
    "merged_df1['マイニング偏差値勝馬差分']=merged_df1['マイニング偏差値']-merged_df1['マイニング偏差値_1着_stdtime1'].fillna(merged_df1['マイニング偏差値_1着_stdtime2'])\n",
    "\n",
    "# マイニング順位分布：基準タイム１差分\n",
    "merged_df1['マイニング順位分布上位差分']=merged_df1['マイニング順位分布']-merged_df1['マイニング順位分布_stdtime1'].fillna(merged_df1['マイニング順位分布_stdtime2'])\n",
    "merged_df1['マイニング順位分布勝馬差分']=merged_df1['マイニング順位分布']-merged_df1['マイニング順位分布_1着_stdtime1'].fillna(merged_df1['マイニング順位分布_1着_stdtime2'])\n",
    "\n",
    "# 対戦型マイニング：基準タイム１差分\n",
    "merged_df1['対戦型マイニング上位差分']=merged_df1['対戦型マイニング']-merged_df1['対戦型マイニング_stdtime1'].fillna(merged_df1['対戦型マイニング_stdtime2'])\n",
    "merged_df1['対戦型マイニング勝馬差分']=merged_df1['対戦型マイニング']-merged_df1['対戦型マイニング_1着_stdtime1'].fillna(merged_df1['対戦型マイニング_1着_stdtime2'])\n",
    "\n",
    "# 対戦型マイニング偏差値：基準タイム１差分\n",
    "merged_df1['対戦型マイニング偏差値上位差分']=merged_df1['対戦型マイニング偏差値']-merged_df1['対戦型マイニング偏差値_stdtime1'].fillna(merged_df1['対戦型マイニング偏差値_stdtime2'])\n",
    "merged_df1['対戦型マイニング偏差値勝馬差分']=merged_df1['対戦型マイニング偏差値']-merged_df1['対戦型マイニング偏差値_1着_stdtime1'].fillna(merged_df1['対戦型マイニング偏差値_1着_stdtime2'])\n",
    "\n",
    "# 対戦型マイニング順位分布：基準タイム１差分\n",
    "merged_df1['対戦型マイニング順位分布上位差分']=merged_df1['対戦型マイニング順位分布']-merged_df1['対戦型マイニング順位分布_stdtime1'].fillna(merged_df1['対戦型マイニング順位分布_stdtime2'])\n",
    "merged_df1['対戦型マイニング順位分布勝馬差分']=merged_df1['対戦型マイニング順位分布']-merged_df1['対戦型マイニング順位分布_1着_stdtime1'].fillna(merged_df1['対戦型マイニング順位分布_1着_stdtime2'])\n",
    "\n",
    "# タイムS：基準タイム１差分\n",
    "merged_df1['タイムS上位差分']=merged_df1['タイムS']-merged_df1['タイムS_stdtime1'].fillna(merged_df1['タイムS_stdtime2'])\n",
    "merged_df1['タイムS勝馬差分']=merged_df1['タイムS']-merged_df1['タイムS_1着_stdtime1'].fillna(merged_df1['タイムS_1着_stdtime2'])\n",
    "\n",
    "# 補正走破タイム：基準タイム１差分\n",
    "merged_df1['補正走破タイム上位差分']=merged_df1['補正走破タイム']-merged_df1['補正走破タイム_stdtime1'].fillna(merged_df1['補正走破タイム_stdtime2'])\n",
    "merged_df1['補正走破タイム勝馬差分']=merged_df1['補正走破タイム']-merged_df1['補正走破タイム_1着_stdtime1'].fillna(merged_df1['補正走破タイム_1着_stdtime2'])\n",
    "\n",
    "# -3Fタイム：基準タイム１差分\n",
    "merged_df1['-3Fタイム上位差分']=merged_df1['-3Fタイム']-merged_df1['-3Fタイム_stdtime1'].fillna(merged_df1['-3Fタイム_stdtime2'])\n",
    "merged_df1['-3Fタイム勝馬差分']=merged_df1['-3Fタイム']-merged_df1['-3Fタイム_1着_stdtime1'].fillna(merged_df1['-3Fタイム_1着_stdtime2'])\n",
    "\n",
    "# 前半3F：基準タイム１差分\n",
    "merged_df1['前半3F上位差分']=merged_df1['前半3F']-merged_df1['前半3F_stdtime1'].fillna(merged_df1['前半3F_stdtime2'])\n",
    "merged_df1['前半3F勝馬差分']=merged_df1['前半3F']-merged_df1['前半3F_1着_stdtime1'].fillna(merged_df1['前半3F_1着_stdtime2'])\n",
    "\n",
    "# 前半3F偏差値：基準タイム１差分\n",
    "merged_df1['前半3F偏差値上位差分']=merged_df1['前半3F偏差値']-merged_df1['前半3F偏差値_stdtime1'].fillna(merged_df1['前半3F偏差値_stdtime2'])\n",
    "merged_df1['前半3F偏差値勝馬差分']=merged_df1['前半3F偏差値']-merged_df1['前半3F偏差値_1着_stdtime1'].fillna(merged_df1['前半3F偏差値_1着_stdtime2'])\n",
    "\n",
    "# 前半3F順位：基準タイム１差分\n",
    "merged_df1['前半3F順位上位差分']=merged_df1['前半3F順位']-merged_df1['前半3F順位_stdtime1'].fillna(merged_df1['前半3F順位_stdtime2'])\n",
    "merged_df1['前半3F順位勝馬差分']=merged_df1['前半3F順位']-merged_df1['前半3F順位_1着_stdtime1'].fillna(merged_df1['前半3F順位_1着_stdtime2'])\n",
    "\n",
    "# 前半3F順位分布：基準タイム１差分\n",
    "merged_df1['前半3F順位分布上位差分']=merged_df1['前半3F順位分布']-merged_df1['前半3F順位分布_stdtime1'].fillna(merged_df1['前半3F順位分布_stdtime2'])\n",
    "merged_df1['前半3F順位分布勝馬差分']=merged_df1['前半3F順位分布']-merged_df1['前半3F順位分布_1着_stdtime1'].fillna(merged_df1['前半3F順位分布_1着_stdtime2'])\n",
    "\n",
    "# 上り3F：基準タイム１差分\n",
    "merged_df1['上り3F上位差分']=merged_df1['上り3F']-merged_df1['上り3F_stdtime1'].fillna(merged_df1['上り3F_stdtime2'])\n",
    "merged_df1['上り3F勝馬差分']=merged_df1['上り3F']-merged_df1['上り3F_1着_stdtime1'].fillna(merged_df1['上り3F_1着_stdtime2'])\n",
    "\n",
    "# 上り3F偏差値：基準タイム１差分\n",
    "merged_df1['上り3F偏差値上位差分']=merged_df1['上り3F偏差値']-merged_df1['上り3F偏差値_stdtime1'].fillna(merged_df1['上り3F偏差値_stdtime2'])\n",
    "merged_df1['上り3F偏差値勝馬差分']=merged_df1['上り3F偏差値']-merged_df1['上り3F偏差値_1着_stdtime1'].fillna(merged_df1['上り3F偏差値_1着_stdtime2'])\n",
    "\n",
    "# 上り3F順位：基準タイム１差分\n",
    "merged_df1['上り3F順位上位差分']=merged_df1['上り3F順位']-merged_df1['上り3F順位_stdtime1'].fillna(merged_df1['上り3F順位_stdtime2'])\n",
    "merged_df1['上り3F順位勝馬差分']=merged_df1['上り3F順位']-merged_df1['上り3F順位_1着_stdtime1'].fillna(merged_df1['上り3F順位_1着_stdtime2'])\n",
    "\n",
    "# 上り3F順位分布：基準タイム１差分\n",
    "merged_df1['上り3F順位分布上位差分']=merged_df1['上り3F順位分布']-merged_df1['上り3F順位分布_stdtime1'].fillna(merged_df1['上り3F順位分布_stdtime2'])\n",
    "merged_df1['上り3F順位分布勝馬差分']=merged_df1['上り3F順位分布']-merged_df1['上り3F順位分布_1着_stdtime1'].fillna(merged_df1['上り3F順位分布_1着_stdtime2'])\n",
    "\n",
    "# Ave-3F：基準タイム１差分\n",
    "merged_df1['Ave-3F上位差分']=merged_df1['Ave-3F']-merged_df1['Ave-3F_stdtime1'].fillna(merged_df1['Ave-3F_stdtime2'])\n",
    "merged_df1['Ave-3F勝馬差分']=merged_df1['Ave-3F']-merged_df1['Ave-3F_1着_stdtime1'].fillna(merged_df1['Ave-3F_1着_stdtime2'])\n",
    "\n",
    "# Ave-3F偏差値：基準タイム１差分\n",
    "merged_df1['Ave-3F偏差値上位差分']=merged_df1['Ave-3F偏差値']-merged_df1['Ave-3F偏差値_stdtime1'].fillna(merged_df1['Ave-3F偏差値_stdtime2'])\n",
    "merged_df1['Ave-3F偏差値勝馬差分']=merged_df1['Ave-3F偏差値']-merged_df1['Ave-3F偏差値_1着_stdtime1'].fillna(merged_df1['Ave-3F偏差値_1着_stdtime2'])\n",
    "\n",
    "# Ave-3F順位：基準タイム１差分\n",
    "merged_df1['Ave-3F順位上位差分']=merged_df1['Ave-3F順位']-merged_df1['Ave-3F順位_stdtime1'].fillna(merged_df1['Ave-3F順位_stdtime2'])\n",
    "merged_df1['Ave-3F順位勝馬差分']=merged_df1['Ave-3F順位']-merged_df1['Ave-3F順位_1着_stdtime1'].fillna(merged_df1['Ave-3F順位_1着_stdtime2'])\n",
    "\n",
    "# Ave-3F順位分布：基準タイム１差分\n",
    "merged_df1['Ave-3F順位分布上位差分']=merged_df1['Ave-3F順位分布']-merged_df1['Ave-3F順位分布_stdtime1'].fillna(merged_df1['Ave-3F順位分布_stdtime2'])\n",
    "merged_df1['Ave-3F順位分布勝馬差分']=merged_df1['Ave-3F順位分布']-merged_df1['Ave-3F順位分布_1着_stdtime1'].fillna(merged_df1['Ave-3F順位分布_1着_stdtime2'])\n",
    "\n",
    "# -3F差：基準タイム１差分\n",
    "merged_df1['-3F差上位差分']=merged_df1['-3F差']-merged_df1['-3F差_stdtime1'].fillna(merged_df1['-3F差_stdtime2'])\n",
    "merged_df1['-3F差勝馬差分']=merged_df1['-3F差']-merged_df1['-3F差_1着_stdtime1'].fillna(merged_df1['-3F差_1着_stdtime2'])\n",
    "\n",
    "# テン指数：基準タイム１差分\n",
    "merged_df1['テン指数上位差分']=merged_df1['テン指数']-merged_df1['テン指数_stdtime1'].fillna(merged_df1['テン指数_stdtime2'])\n",
    "merged_df1['テン指数勝馬差分']=merged_df1['テン指数']-merged_df1['テン指数_1着_stdtime1'].fillna(merged_df1['テン指数_1着_stdtime2'])\n",
    "\n",
    "# テン指数偏差値：基準タイム１差分\n",
    "merged_df1['テン指数偏差値上位差分']=merged_df1['テン指数偏差値']-merged_df1['テン指数偏差値_stdtime1'].fillna(merged_df1['テン指数偏差値_stdtime2'])\n",
    "merged_df1['テン指数偏差値勝馬差分']=merged_df1['テン指数偏差値']-merged_df1['テン指数偏差値_1着_stdtime1'].fillna(merged_df1['テン指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# テン指数順位：基準タイム１差分\n",
    "merged_df1['テン指数順位上位差分']=merged_df1['テン指数順位']-merged_df1['テン指数順位_stdtime1'].fillna(merged_df1['テン指数順位_stdtime2'])\n",
    "merged_df1['テン指数順位勝馬差分']=merged_df1['テン指数順位']-merged_df1['テン指数順位_1着_stdtime1'].fillna(merged_df1['テン指数順位_1着_stdtime2'])\n",
    "\n",
    "# テン指数順位分布：基準タイム１差分\n",
    "merged_df1['テン指数順位分布上位差分']=merged_df1['テン指数順位分布']-merged_df1['テン指数順位分布_stdtime1'].fillna(merged_df1['テン指数順位分布_stdtime2'])\n",
    "merged_df1['テン指数順位分布勝馬差分']=merged_df1['テン指数順位分布']-merged_df1['テン指数順位分布_1着_stdtime1'].fillna(merged_df1['テン指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# 上り指数：基準タイム１差分\n",
    "merged_df1['上り指数上位差分']=merged_df1['上り指数']-merged_df1['上り指数_stdtime1'].fillna(merged_df1['上り指数_stdtime2'])\n",
    "merged_df1['上り指数勝馬差分']=merged_df1['上り指数']-merged_df1['上り指数_1着_stdtime1'].fillna(merged_df1['上り指数_1着_stdtime2'])\n",
    "\n",
    "# 上り指数偏差値：基準タイム１差分\n",
    "merged_df1['上り指数偏差値上位差分']=merged_df1['上り指数偏差値']-merged_df1['上り指数偏差値_stdtime1'].fillna(merged_df1['上り指数偏差値_stdtime2'])\n",
    "merged_df1['上り指数偏差値勝馬差分']=merged_df1['上り指数偏差値']-merged_df1['上り指数偏差値_1着_stdtime1'].fillna(merged_df1['上り指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# 上り指数順位：基準タイム１差分\n",
    "merged_df1['上り指数順位上位差分']=merged_df1['上り指数順位']-merged_df1['上り指数順位_stdtime1'].fillna(merged_df1['上り指数順位_stdtime2'])\n",
    "merged_df1['上り指数順位勝馬差分']=merged_df1['上り指数順位']-merged_df1['上り指数順位_1着_stdtime1'].fillna(merged_df1['上り指数順位_1着_stdtime2'])\n",
    "\n",
    "# 上り指数順位分布：基準タイム１差分\n",
    "merged_df1['上り指数順位分布上位差分']=merged_df1['上り指数順位分布']-merged_df1['上り指数順位分布_stdtime1'].fillna(merged_df1['上り指数順位分布_stdtime2'])\n",
    "merged_df1['上り指数順位分布勝馬差分']=merged_df1['上り指数順位分布']-merged_df1['上り指数順位分布_1着_stdtime1'].fillna(merged_df1['上り指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# スピード指数：基準タイム１差分\n",
    "merged_df1['スピード指数上位差分']=merged_df1['スピード指数']-merged_df1['スピード指数_stdtime1'].fillna(merged_df1['スピード指数_stdtime2'])\n",
    "merged_df1['スピード指数勝馬差分']=merged_df1['スピード指数']-merged_df1['スピード指数_1着_stdtime1'].fillna(merged_df1['スピード指数_1着_stdtime2'])\n",
    "\n",
    "# スピード指数偏差値：基準タイム１差分\n",
    "merged_df1['スピード指数偏差値上位差分']=merged_df1['スピード指数偏差値']-merged_df1['スピード指数偏差値_stdtime1'].fillna(merged_df1['スピード指数偏差値_stdtime2'])\n",
    "merged_df1['スピード指数偏差値勝馬差分']=merged_df1['スピード指数偏差値']-merged_df1['スピード指数偏差値_1着_stdtime1'].fillna(merged_df1['スピード指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# スピード指数順位：基準タイム１差分\n",
    "merged_df1['スピード指数順位上位差分']=merged_df1['スピード指数順位']-merged_df1['スピード指数順位_stdtime1'].fillna(merged_df1['スピード指数順位_stdtime2'])\n",
    "merged_df1['スピード指数順位勝馬差分']=merged_df1['スピード指数順位']-merged_df1['スピード指数順位_1着_stdtime1'].fillna(merged_df1['スピード指数順位_1着_stdtime2'])\n",
    "\n",
    "# スピード指数順位分布：基準タイム１差分\n",
    "merged_df1['スピード指数順位分布上位差分']=merged_df1['スピード指数順位分布']-merged_df1['スピード指数順位分布_stdtime1'].fillna(merged_df1['スピード指数順位分布_stdtime2'])\n",
    "merged_df1['スピード指数順位分布勝馬差分']=merged_df1['スピード指数順位分布']-merged_df1['スピード指数順位分布_1着_stdtime1'].fillna(merged_df1['スピード指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# 総合指数：基準タイム１差分\n",
    "merged_df1['総合指数上位差分']=merged_df1['総合指数']-merged_df1['総合指数_stdtime1'].fillna(merged_df1['総合指数_stdtime2'])\n",
    "merged_df1['総合指数勝馬差分']=merged_df1['総合指数']-merged_df1['総合指数_1着_stdtime1'].fillna(merged_df1['総合指数_1着_stdtime2'])\n",
    "\n",
    "# 総合指数偏差値：基準タイム１差分\n",
    "merged_df1['総合指数偏差値上位差分']=merged_df1['総合指数偏差値']-merged_df1['総合指数偏差値_stdtime1'].fillna(merged_df1['総合指数偏差値_stdtime2'])\n",
    "merged_df1['総合指数偏差値勝馬差分']=merged_df1['総合指数偏差値']-merged_df1['総合指数偏差値_1着_stdtime1'].fillna(merged_df1['総合指数偏差値_1着_stdtime2'])\n",
    "\n",
    "# 総合指数順位：基準タイム１差分\n",
    "merged_df1['総合指数順位上位差分']=merged_df1['総合指数順位']-merged_df1['総合指数順位_stdtime1'].fillna(merged_df1['総合指数順位_stdtime2'])\n",
    "merged_df1['総合指数順位勝馬差分']=merged_df1['総合指数順位']-merged_df1['総合指数順位_1着_stdtime1'].fillna(merged_df1['総合指数順位_1着_stdtime2'])\n",
    "\n",
    "# 総合指数順位分布：基準タイム１差分\n",
    "merged_df1['総合指数順位分布上位差分']=merged_df1['総合指数順位分布']-merged_df1['総合指数順位分布_stdtime1'].fillna(merged_df1['総合指数順位分布_stdtime2'])\n",
    "merged_df1['総合指数順位分布勝馬差分']=merged_df1['総合指数順位分布']-merged_df1['総合指数順位分布_1着_stdtime1'].fillna(merged_df1['総合指数順位分布_1着_stdtime2'])\n",
    "\n",
    "# PCI：基準タイム１差分\n",
    "merged_df1['PCI上位差分']=merged_df1['PCI']-merged_df1['PCI_stdtime1'].fillna(merged_df1['PCI_stdtime2'])\n",
    "merged_df1['PCI勝馬差分']=merged_df1['PCI']-merged_df1['PCI_1着_stdtime1'].fillna(merged_df1['PCI_1着_stdtime2'])\n",
    "\n",
    "# 初角_4角差：基準タイム１差分\n",
    "merged_df1['初角_4角差上位差分']=merged_df1['初角_4角差']-merged_df1['初角_4角差_stdtime1'].fillna(merged_df1['初角_4角差_stdtime2'])\n",
    "merged_df1['初角_4角差勝馬差分']=merged_df1['初角_4角差']-merged_df1['初角_4角差_1着_stdtime1'].fillna(merged_df1['初角_4角差_1着_stdtime2'])\n",
    "\n",
    "# 4角_入線順位差：基準タイム１差分\n",
    "merged_df1['4角_入線順位差上位差分']=merged_df1['4角_入線順位差']-merged_df1['4角_入線順位差_stdtime1'].fillna(merged_df1['4角_入線順位差_stdtime2'])\n",
    "merged_df1['4角_入線順位差勝馬差分']=merged_df1['4角_入線順位差']-merged_df1['4角_入線順位差_1着_stdtime1'].fillna(merged_df1['4角_入線順位差_1着_stdtime2'])\n",
    "\n",
    "# ---ステップ５：33ラップを判定する\n",
    "# 33ラップ判定用関数\n",
    "def assign_label(row):\n",
    "    lap_value = row['33ラップ']\n",
    "    if pd.isna(lap_value):\n",
    "        return np.nan\n",
    "\n",
    "    candidates = {\n",
    "        -2: row['33ラップ-2_33lap'],\n",
    "        -1: row['33ラップ-1_33lap'],\n",
    "         0: row['33ラップ±0_33lap'],\n",
    "         1: row['33ラップ+1_33lap'],\n",
    "         2: row['33ラップ+2_33lap'],\n",
    "    }\n",
    "\n",
    "    # 参照側が全部NaNなら判定不能\n",
    "    if all(pd.isna(v) for v in candidates.values()):\n",
    "        return np.nan\n",
    "\n",
    "    # 差分（絶対値）が最小のスケールを選ぶ\n",
    "    best_scale = min(\n",
    "        candidates.keys(),\n",
    "        key=lambda k: abs(lap_value - candidates[k]) if pd.notna(candidates[k]) else np.inf\n",
    "    )\n",
    "\n",
    "    # 0スケール\n",
    "    if best_scale == 0:\n",
    "        if lap_value < 0:\n",
    "            return '持0'\n",
    "        elif lap_value > 0:\n",
    "            return '瞬0'\n",
    "        else:\n",
    "            return '総'\n",
    "\n",
    "    prefix = '瞬' if lap_value > 0 else '持'\n",
    "    suffix = f'+{best_scale}' if best_scale > 0 else f'{best_scale}'\n",
    "    return prefix + suffix\n",
    "\n",
    "# 33ラップを判定\n",
    "merged_df1['33ラップ判定'] = merged_df1.apply(assign_label, axis=1)\n",
    "\n",
    "# レースタイプラベル列の追加\n",
    "insert_pos = merged_df1.columns.get_loc('33ラップ判定') + 1\n",
    "\n",
    "# '33ラップ判定' の値 → レースタイプ の対応表\n",
    "race_type_map = {\n",
    "    # 瞬発力戦\n",
    "    '瞬+2': '瞬発力戦',\n",
    "    '瞬+1': '瞬発力戦',\n",
    "    '瞬0':  '瞬発力戦',\n",
    "\n",
    "    # 総合力戦\n",
    "    '瞬-1': '総合力戦',\n",
    "    '瞬-2': '総合力戦',\n",
    "    '総':   '総合力戦',\n",
    "    '持-1': '総合力戦',\n",
    "    '持-2': '総合力戦',\n",
    "\n",
    "    # 持久力戦\n",
    "    '持+2': '持久力戦',\n",
    "    '持+1': '持久力戦',\n",
    "    '持+0': '持久力戦',\n",
    "}\n",
    "\n",
    "ref = merged_df1['33ラップ判定']\n",
    "merged_df1.insert(insert_pos, 'レースタイプ', ref.map(race_type_map))\n",
    "\n",
    "# ラベル書き換え用のマッピング辞書\n",
    "label_mapping = {\n",
    "    '持-2': '0T持-2',\n",
    "    '持-1': '0T持-1',\n",
    "    '持0': '0U持0',\n",
    "    '持+1': '0V持+1',\n",
    "    '持+2': '0V持+2',\n",
    "    '瞬-2': '0S瞬-2',\n",
    "    '瞬-1': '0S瞬-1',\n",
    "    '瞬0': '0R瞬0',\n",
    "    '瞬+1': '0Q瞬+1',\n",
    "    '瞬+2': '0Q瞬+2',\n",
    "    '総': '02総'\n",
    "}\n",
    "\n",
    "# 書き換え\n",
    "merged_df1['レース印２'] = merged_df1['33ラップ判定'].replace(label_mapping)\n",
    "\n",
    "# ---ステップ６：レースレベル判定\n",
    "# レースレベル指数\n",
    "# レース強度指数の計算\n",
    "first_load  = merged_df1['通過3F_stdtime1'].fillna(merged_df1['通過3F_stdtime2']) - merged_df1['通過3F']\n",
    "\n",
    "middle_diff1 = merged_df1['中盤ラップ1_stdtime1'].fillna(merged_df1['中盤ラップ1_stdtime2']) - merged_df1['中盤ラップ1']\n",
    "middle_diff2 = merged_df1['中盤ラップ2_stdtime1'].fillna(merged_df1['中盤ラップ2_stdtime2']) - merged_df1['中盤ラップ2']\n",
    "\n",
    "middle_load = pd.concat([middle_diff1, middle_diff2], axis=1).mean(axis=1, skipna=True)\n",
    "\n",
    "last_load   = merged_df1['レース上り3F_stdtime1'].fillna(merged_df1['レース上り3F_stdtime2']) - merged_df1['レース上り3F']\n",
    "spurt_load  = merged_df1['最大加速ラップ_stdtime1'].fillna(merged_df1['最大加速ラップ_stdtime2']) - merged_df1['最大加速ラップ']\n",
    "goal_load   = merged_df1['ゴール前ラップ差_stdtime1'].fillna(merged_df1['ゴール前ラップ差_stdtime2']) - merged_df1['ゴール前ラップ差']\n",
    "\n",
    "merged_df1['レース強度指数'] = (\n",
    "    100\n",
    "    + first_load.fillna(0)\n",
    "    + middle_load.fillna(0)\n",
    "    + last_load.fillna(0)\n",
    "    + spurt_load.fillna(0)\n",
    "    + goal_load.fillna(0)\n",
    "    + merged_df1['馬場補正値'].fillna(0)\n",
    ")\n",
    "\n",
    "# ベース値（Std2優先 → なければ Std1）\n",
    "rating_base = merged_df1['レイティング_stdtime2'].fillna(\n",
    "    merged_df1['レイティング_stdtime1']\n",
    ")\n",
    "speed_base = merged_df1['総合指数_stdtime2'].fillna(\n",
    "    merged_df1['総合指数_stdtime1']\n",
    ")\n",
    "strength_base = merged_df1['レース強度指数_stdtime2'].fillna(\n",
    "    merged_df1['レース強度指数_stdtime1']\n",
    ")\n",
    "\n",
    "# 差分（NaN は 0 扱い）\n",
    "rating_diff = (merged_df1['レイティング平均値'] - rating_base).fillna(0)\n",
    "speed_diff  = (merged_df1['Top3総合指数'] - speed_base).fillna(0)\n",
    "strength_diff = (merged_df1['レース強度指数'] - strength_base).fillna(0)\n",
    "\n",
    "# レースレベル指数算出\n",
    "merged_df1['レースレベル指数'] = (rating_diff + speed_diff + strength_diff + 100).round(1)\n",
    "\n",
    "# レース強度指数：基準タイム１差分\n",
    "merged_df1['レース強度指数上位差分']=merged_df1['レース強度指数']-merged_df1['レース強度指数_stdtime1'].fillna(merged_df1['レース強度指数_stdtime2'])\n",
    "\n",
    "# 差分\n",
    "rl_m2 = (merged_df1['レースレベル指数'] - merged_df1['RL-2_racelevel']).abs()\n",
    "rl_m1 = (merged_df1['レースレベル指数'] - merged_df1['RL-1_racelevel']).abs()\n",
    "rl_0  = (merged_df1['レースレベル指数'] - merged_df1['RL±0_racelevel']).abs()\n",
    "rl_p1 = (merged_df1['レースレベル指数'] - merged_df1['RL+1_racelevel']).abs()\n",
    "rl_p2 = (merged_df1['レースレベル指数'] - merged_df1['RL+2_racelevel']).abs()\n",
    "\n",
    "# 5本を横に並べて「最小の列名」を取る（行ごと）\n",
    "diff_df = pd.concat([rl_m2, rl_m1, rl_0, rl_p1, rl_p2], axis=1)\n",
    "diff_df.columns = [-2, -1, 0, 1, 2]  # そのまま判定値にする\n",
    "\n",
    "# 「基準が無い行」判定（5本すべてNaN）\n",
    "no_ref = diff_df.isna().all(axis=1)\n",
    "\n",
    "# idxminを安定させるため NaN は無限大扱いにして最小を取る\n",
    "band = diff_df.fillna(np.inf).idxmin(axis=1)\n",
    "\n",
    "# レースレベル判定 列を追加\n",
    "insert_pos = merged_df1.columns.get_loc('レースレベル指数') + 1\n",
    "merged_df1.insert(insert_pos, 'レースレベル判定', band.where(~no_ref, np.nan).astype('Int64'))\n",
    "\n",
    "# レースレベル評価 列を追加\n",
    "band_to_grade = {2: 'A', 1: 'B', 0: 'C', -1: 'D', -2: 'E'}\n",
    "insert_pos = merged_df1.columns.get_loc('レースレベル判定') + 1\n",
    "merged_df1.insert(insert_pos, 'レースレベル評価', merged_df1['レースレベル判定'].map(band_to_grade))\n",
    "\n",
    "# レース印３ 列を追加\n",
    "rank_to_label = {'A': '05A', 'B': '07B', 'C': '01C', 'D': '00D', 'E': '03E'}\n",
    "merged_df1['レース印３'] = merged_df1['レースレベル評価'].replace(rank_to_label)\n",
    "\n",
    "# サフィックス付き列を削除\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_stdtime1', '_stdtime2', '_paceindex', '_33lap', '_centralscore1', '_centralscore2', '_racelevel')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "merged_df1 = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "# ---ステップ７：指数系データのcsvファイル保存\n",
    "# 各指数をインポート用ファイルに加工して保存\n",
    "# テン指数\n",
    "imp_df1 = merged_df1[['target_horseid','テン指数']]\n",
    "# 上り指数\n",
    "imp_df2 = merged_df1[['target_horseid','上り指数']]\n",
    "# スピード指数\n",
    "imp_df3 = merged_df1[['target_horseid','スピード指数']]\n",
    "# 総合指数\n",
    "imp_df4 = merged_df1[['target_horseid','総合指数']]\n",
    "# 33ラップ判定\n",
    "imp_df5 = merged_df1[['target_raceid','レース印２']].drop_duplicates('target_raceid')\n",
    "# レースレベル判定\n",
    "imp_df6 = merged_df1[['target_raceid','レース印３']].drop_duplicates('target_raceid')\n",
    "\n",
    "output_df1 = pd.read_csv(output_filepath1, encoding='cp932')\n",
    "output_df2 = pd.read_csv(output_filepath2, encoding='cp932')\n",
    "output_df3 = pd.read_csv(output_filepath3, encoding='cp932')\n",
    "output_df4 = pd.read_csv(output_filepath4, encoding='cp932')\n",
    "output_df5 = pd.read_csv(output_filepath5, encoding='cp932')\n",
    "output_df6 = pd.read_csv(output_filepath6, encoding='cp932')\n",
    "\n",
    "# 結合\n",
    "output_df1 = pd.concat([output_df1, imp_df1], ignore_index=True)\n",
    "output_df2 = pd.concat([output_df2, imp_df2], ignore_index=True)\n",
    "output_df3 = pd.concat([output_df3, imp_df3], ignore_index=True)\n",
    "output_df4 = pd.concat([output_df4, imp_df4], ignore_index=True)\n",
    "output_df5 = pd.concat([output_df5, imp_df5], ignore_index=True)\n",
    "output_df6 = pd.concat([output_df6, imp_df6], ignore_index=True)\n",
    "\n",
    "# 重複削除（最新の行を残す）\n",
    "output_df1 = output_df1.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "output_df2 = output_df2.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "output_df3 = output_df3.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "output_df4 = output_df4.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "output_df5 = output_df5.drop_duplicates(subset=['target_raceid'], keep='last')\n",
    "output_df6 = output_df6.drop_duplicates(subset=['target_raceid'], keep='last')\n",
    "\n",
    "# 保存\n",
    "output_df1.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "output_df2.to_csv(output_filepath2, index=False, encoding='cp932')\n",
    "output_df3.to_csv(output_filepath3, index=False, encoding='cp932')\n",
    "output_df4.to_csv(output_filepath4, index=False, encoding='cp932')\n",
    "output_df5.to_csv(output_filepath5, index=False, encoding='cp932')\n",
    "output_df6.to_csv(output_filepath6, index=False, encoding='cp932')\n",
    "\n",
    "# 年度列を追加して保存\n",
    "# 年度列を追加（target_raceid,target_horseid先頭4桁が年）\n",
    "output_df1['year'] = pd.to_datetime(\n",
    "    output_df1['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df2['year'] = pd.to_datetime(\n",
    "    output_df2['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df3['year'] = pd.to_datetime(\n",
    "    output_df3['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df4['year'] = pd.to_datetime(\n",
    "    output_df4['target_horseid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df5['year'] = pd.to_datetime(\n",
    "    output_df5['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "output_df6['year'] = pd.to_datetime(\n",
    "    output_df6['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "# 年度別にファイル分割\n",
    "for year, df in output_df1.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir1}First_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df2.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir2}Spurt_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df3.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir3}Speed_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df4.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir4}Total_Score_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df5.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir5}33Lap_Category_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "for year, df in output_df6.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        f'{output_dir6}Race_Level_Master_{year}.csv',\n",
    "        index=False, encoding='cp932'\n",
    "    )\n",
    "\n",
    "# ---ステップ８：成績データの結合\n",
    "# 成績データの列の並び替え\n",
    "header_df = pd.read_csv(header_filepath, header = None, encoding='cp932')\n",
    "column_list = header_df[0].tolist()\n",
    "merged_df1 = merged_df1[column_list]\n",
    "\n",
    "# マスタ成績ファイルを開いてmerged_df1を縦結合\n",
    "master_df = pd.read_csv(master_filepath, encoding='cp932')\n",
    "\n",
    "# 結合\n",
    "master_df = pd.concat([master_df, merged_df1], ignore_index=True)\n",
    "\n",
    "# 重複削除（最新の行を残す）\n",
    "master_df = master_df.drop_duplicates(subset=['target_horseid'], keep='last')\n",
    "\n",
    "# ---ステップ９：馬の持久力/瞬発力タイプ判定をして保存\n",
    "# master_dfをコピーして１~３着だけにする\n",
    "merge_key6 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)','馬場分類']\n",
    "\n",
    "# 馬名も含めて抽出\n",
    "horsetype_df = master_df[master_df['入線順位'].between(1, 3)].copy()\n",
    "horsetype_df = horsetype_df[['target_raceid', '血統登録番号', '馬名', 'PCI3', 'PCI'] + merge_key6].copy()\n",
    "\n",
    "# 基準タイムファイル１から基準PCI3を取ってマージ\n",
    "std1_df = base_time_df1[merge_key6 + ['PCI3_stdtime1']].copy()\n",
    "horsetype_df = pd.merge(horsetype_df, std1_df, on=merge_key6, how='left')\n",
    "\n",
    "# 不要なデータフレームをクリア\n",
    "del std1_df\n",
    "\n",
    "# レース性質（基準比）と、馬のレース内差分を合算\n",
    "# （※この計算式は前回のままでも動きますが、シンプルにするなら horsetype_df['PCI'] - horsetype_df['PCI3_stdtime1'] でも同じ結果です）\n",
    "horsetype_df['基準PCI3差分'] = horsetype_df['PCI3'] - horsetype_df['PCI3_stdtime1']\n",
    "horsetype_df['レースPCI3差分'] = horsetype_df['PCI'] - horsetype_df['PCI3']\n",
    "horsetype_df['PCI判定スコア'] = horsetype_df['基準PCI3差分'] + horsetype_df['レースPCI3差分']\n",
    "\n",
    "# 馬ごとに集計：スコアは「中央値」、馬名は「最後のもの（最新）」を取得\n",
    "# ※ここで horsetype_df 自体が「集計後のデータ」に上書き\n",
    "horsetype_df = horsetype_df.groupby('血統登録番号', as_index=False).agg({\n",
    "    'PCI判定スコア': 'median',\n",
    "    '馬名': 'last'\n",
    "})\n",
    "\n",
    "# 'タイプ' 列を追加して判定（マイナス=持、プラス=瞬）\n",
    "horsetype_df['タイプ'] = ''\n",
    "horsetype_df.loc[horsetype_df['PCI判定スコア'] < 0, 'タイプ'] = '0'\n",
    "horsetype_df.loc[horsetype_df['PCI判定スコア'] > 0, 'タイプ'] = '1'\n",
    "\n",
    "# 今日の日付を yymmdd で作る\n",
    "today_yymmdd = datetime.now().strftime(\"%y%m%d\")\n",
    "\n",
    "# ★「0/1が入った馬だけ」出力（中央値0や判定不能は除外）\n",
    "horsetype_df = horsetype_df[horsetype_df['タイプ'].isin(['0', '1'])].copy()\n",
    "\n",
    "# 登録日\n",
    "horsetype_df['登録日'] = today_yymmdd\n",
    "\n",
    "# 血統登録番号の整形\n",
    "horsetype_df['血統登録番号'] = horsetype_df['血統登録番号'].astype(str).str.strip()\n",
    "\n",
    "# 列順を整えて完了\n",
    "checkhorse_df = horsetype_df[['馬名', 'タイプ', '登録日', '血統登録番号']].copy()\n",
    "\n",
    "# 馬タイプをcsvファイル保存\n",
    "checkhorse_df.to_csv(output_filepath7, index=False, encoding='cp932')\n",
    "\n",
    "# ---ステップ１０：成績データファイルを保存\n",
    "master_df.to_csv(master_filepath, index=False, encoding='cp932')\n",
    "\n",
    "# 不要なデータフレームのクリア\n",
    "del base_time_df1\n",
    "del base_time_df2\n",
    "del pace_medians_df\n",
    "del lap33_df\n",
    "del racelevel_df\n",
    "del horsetype_df\n",
    "del master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 過去n走分の特徴量を出力する\n",
    "## 2017~2024年の特徴量を出力する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] input: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2023_reordered.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "past_numeric_chunks: 100%|██████████| 4/4 [17:36<00:00, 264.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Horse\\horse_past_numeric_snapshot.csv\n",
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Horse\\horse_runningstyle_snapshot.csv\n",
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Horse\\horse_blinker_flags_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "horse_last5: 100%|██████████| 39833/39833 [03:50<00:00, 172.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Horse\\horse_last5_perf_snapshot.csv\n",
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Blinker\\Horse\\blinker_performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blood_keys:  25%|██▌       | 1/4 [00:06<00:19,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Sire\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blood_keys:  50%|█████     | 2/4 [00:09<00:09,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\SireLine\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blood_keys:  75%|███████▌  | 3/4 [00:25<00:09,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Sire_BMS\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blood_keys: 100%|██████████| 4/4 [00:38<00:00,  9.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\SireLine_BMS\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  10%|█         | 1/10 [00:11<01:47, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Breeder\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  20%|██        | 2/10 [00:25<01:43, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Owner\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  30%|███       | 3/10 [00:36<01:22, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Trainer\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  40%|████      | 4/10 [00:42<00:57,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Jockey\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  50%|█████     | 5/10 [01:00<01:02, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Breeder_Owner\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  60%|██████    | 6/10 [01:20<01:01, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Breeder_Trainer\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  70%|███████   | 7/10 [01:43<00:52, 17.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Breeder_Jockey\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  80%|████████  | 8/10 [02:03<00:36, 18.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Owner_Trainer\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys:  90%|█████████ | 9/10 [02:26<00:19, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Owner_Jockey\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "related_keys: 100%|██████████| 10/10 [02:46<00:00, 16.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Trainer_Jockey\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "course_keys:  50%|█████     | 1/2 [00:09<00:09,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Trainer_Course\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "course_keys: 100%|██████████| 2/2 [00:17<00:00,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Jockey_Course\\performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blinker_rel_keys:  33%|███▎      | 1/3 [00:00<00:00,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Blinker\\Trainer\\blinker_performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blinker_rel_keys:  67%|██████▋   | 2/3 [00:00<00:00,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Blinker\\Jockey\\blinker_performance_snapshot.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "blinker_rel_keys: 100%|██████████| 3/3 [00:01<00:00,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] saved: G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\20_Data_Features\\Blinker\\Trainer_Jockey\\blinker_performance_snapshot.csv\n",
      "[info] done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import importlib.util\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "    \n",
    "script_path = Path(r\"G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\50_SourceCode\\add_past_features.py\")\n",
    "spec = importlib.util.spec_from_file_location(\"add_past_features\", script_path)\n",
    "mod = importlib.util.module_from_spec(spec)\n",
    "\n",
    "sys.modules[spec.name] = mod\n",
    "spec.loader.exec_module(mod)\n",
    "\n",
    "mod.run(\n",
    "    input_path=r\"G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2024_tmp.csv\",\n",
    "    surface_col=\"芝・ダート\",\n",
    "    surface_turf_value=\"芝\",\n",
    "    surface_dirt_value=\"ダート\",\n",
    "    course_label_col=\"コースラベル\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ↓アーカイブ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 列の並べ替え"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 成績データファイルを定義\n",
    "master_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2023.csv'\n",
    "header_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\50_SourceCode\\ResultData_Header.csv'\n",
    "output_filepath = r'G:\\マイドライブ\\20_HOBBY\\20_KEIBA\\10_Data_Source\\10_Export_Data\\Result_Data\\Processed\\Race_Result_Master_2023_temp.csv'\n",
    "\n",
    "master_df = pd.read_csv(master_filepath, encoding= 'cp932')\n",
    "header_df = pd.read_csv(header_filepath ,header=None,encoding= 'cp932')\n",
    "\n",
    "column_list = header_df[0].tolist()\n",
    "\n",
    "master_df = master_df.reindex(columns = column_list)\n",
    "\n",
    "master_df.to_csv(output_filepath, index = False,encoding='cp932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_19984\\1735542871.py:44: DtypeWarning: Columns (20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(master_filipath, encoding='cp932').copy()\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_19984\\1735542871.py:185: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['OH-4' 'OH-4' 'OH-4' ... 'OI-12' 'OI-12' 'OI-12']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  left.update(right, overwrite=OVERWRITE)\n",
      "c:\\Users\\rotte\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\rotte\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\rotte\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\rotte\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\rotte\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\rotte\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "c:\\Users\\rotte\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:1214: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_19984\\1735542871.py:645: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(remove_outliers)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "# 元になる成績データファイルのパス\n",
    "master_filipath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master_org.csv'\n",
    "\n",
    "# 成績データにマッピングするデータファイルのパス\n",
    "# 初角位置\n",
    "mapping_filepath1 = r'D:\\Keiba\\00_ImportData\\80_First_Corner_Position\\First_Corner_Position_Master.csv'\n",
    "# 2角位置\n",
    "mapping_filepath2 = r'D:\\Keiba\\00_ImportData\\90_Second_Corner_Position\\Second_Corner_Position_Master.csv'\n",
    "# 3角位置\n",
    "mapping_filepath3 = r'D:\\Keiba\\00_ImportData\\100_Third_Corner_Position\\Third_Corner_Position_Master.csv'\n",
    "# 4角位置\n",
    "mapping_filepath4 = r'D:\\Keiba\\00_ImportData\\110_Fourth_Corner_Position\\Fourth_Corner_Position_Master.csv'\n",
    "# 上り位置\n",
    "mapping_filepath5 = r'D:\\Keiba\\00_ImportData\\120_Spurt_Position\\Spurt_Position_Master.csv'\n",
    "# 馬場指数\n",
    "mapping_filepath6 = r'D:\\Keiba\\00_ImportData\\140_Track_Condition\\Track_Condition_Master.csv'\n",
    "# 前半3Fタイム\n",
    "mapping_filepath7 = r'D:\\Keiba\\00_ImportData\\180_First3F_Lap\\First3F_Lap_Master.csv'\n",
    "# レイティング\n",
    "mapping_filepath8 = r'D:\\Keiba\\00_ImportData\\170_Rating_Score\\Rating_Score_Master.csv'\n",
    "\n",
    "# 保存先フォルダのパス\n",
    "# 加工後の成績データファイルの保存先パス\n",
    "output_filepath1 = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "# 基準タイムデータファイル1の保存先パス\n",
    "output_filepath2 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master1.csv'\n",
    "# 基準タイムデータファイル2の保存先パス\n",
    "output_filepath3 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master2.csv'\n",
    "# ペース係数データファイルの保存先パス\n",
    "output_filepath4 = r'D:\\Keiba\\20_IndexData\\Pace_Coefficient_Master.csv'\n",
    "# 基準33ラップファイルの保存先パス\n",
    "output_filepath5 = r'D:\\Keiba\\20_IndexData\\Base_33Lap_Master.csv'\n",
    "\n",
    "# 成績データファイルとマッピングファイルの読み込み\n",
    "df1 = pd.read_csv(master_filipath, encoding='cp932').copy()\n",
    "df2 = pd.read_csv(mapping_filepath1, encoding='cp932').copy()\n",
    "df3 = pd.read_csv(mapping_filepath2, encoding='cp932').copy()\n",
    "df4 = pd.read_csv(mapping_filepath3, encoding='cp932').copy()\n",
    "df5 = pd.read_csv(mapping_filepath4, encoding='cp932').copy()\n",
    "df6 = pd.read_csv(mapping_filepath5, encoding='cp932').copy()\n",
    "df7 = pd.read_csv(mapping_filepath6, encoding='cp932').copy()\n",
    "df8 = pd.read_csv(mapping_filepath7, encoding='cp932').copy()\n",
    "df9 = pd.read_csv(mapping_filepath8, encoding='cp932').copy()\n",
    "\n",
    "# カラムの整理\n",
    "# df1の列名を変更\n",
    "rename_map = {\n",
    "    'レースID(新)': 'target_raceid',\n",
    "    'レースID(新).1': 'target_horseid',\n",
    "    '上り3F': 'レース上り3F',\n",
    "    '上り4F': 'レース上り4F',\n",
    "    '上り5F': 'レース上り5F',\n",
    "    '外部指数1':'レイティング',\n",
    "    '外部指数順1':'レイティング順位',\n",
    "    '外部指数2':'テン指数',\n",
    "    '外部指数順2':'テン指数順位',\n",
    "    '外部指数3':'上り指数',\n",
    "    '外部指数順3':'上り指数順位',\n",
    "    '外部指数4':'スピード指数',\n",
    "    '外部指数順4':'スピード指数順位',\n",
    "    '上り3F.1':'上り3F'\n",
    "}\n",
    "\n",
    "# df1の列名に対してrename_mapを適用\n",
    "cols = list(df1.columns)\n",
    "seen = set()\n",
    "for i, c in enumerate(cols):\n",
    "    if c in rename_map and c not in seen:\n",
    "        cols[i] = rename_map[c]\n",
    "        seen.add(c)\n",
    "df1.columns = cols\n",
    "\n",
    "# 配当金額の列を作成する\n",
    "# 列から取り出す金額の数を定義\n",
    "target_cols = {\n",
    "    '単勝配当表記': ('単勝', 1),\n",
    "    '複勝配当表記': ('複勝', 3),\n",
    "    '枠連配当表記': ('枠連', 1),\n",
    "    '馬連配当表記': ('馬連', 1),\n",
    "    'ワイド配当表記': ('ワイド', 3),\n",
    "    '馬単配当表記': ('馬単', 1),\n",
    "    '３連複配当表記': ('３連複', 1),\n",
    "    '３連単配当表記': ('３連単', 1),\n",
    "}\n",
    "\n",
    "# 金額を取り出す正規表現パターン\n",
    "pattern = re.compile(r'[\\\\¥]\\s*([0-9,]+)(?=\\s*(?:\\(|/|$))')\n",
    "\n",
    "def pick_amounts(text, take=1):\n",
    "    if pd.isna(text):\n",
    "        return [np.nan]*take\n",
    "    s = str(text)\n",
    "    found = pattern.findall(s)\n",
    "    nums = []\n",
    "    for x in found:\n",
    "        try:\n",
    "            nums.append(int(x.replace(',', '')))\n",
    "        except:\n",
    "            # 変な値が来てもスルー\n",
    "            continue\n",
    "    # 必要な個数だけ先頭から取り、足りなければNaNで埋める\n",
    "    nums = nums[:take]\n",
    "    if len(nums) < take:\n",
    "        nums += [np.nan]*(take - len(nums))\n",
    "    return nums\n",
    "\n",
    "for src_col, (base_name, take) in target_cols.items():\n",
    "    if src_col not in df1.columns:\n",
    "        # その列が無い場合はスキップ\n",
    "        continue\n",
    "\n",
    "    # 値を取り出す\n",
    "    values = df1[src_col].apply(lambda x: pick_amounts(x, take))\n",
    "\n",
    "    # 1個だけなら「単勝」のように1列、3個なら「複勝1, 複勝2, 複勝3」の3列を作る\n",
    "    if take == 1:\n",
    "        col_name = base_name\n",
    "        df1[col_name] = values.apply(lambda v: v[0] if isinstance(v, list) else np.nan)\n",
    "        # Convert to integer, coercing errors to NaN\n",
    "        df1[col_name] = pd.to_numeric(df1[col_name], errors='coerce').astype('Int64')\n",
    "    else:\n",
    "        for i in range(take):\n",
    "            col_name = f'{base_name}{i+1}'\n",
    "            df1[col_name] = values.apply(lambda v: v[i] if isinstance(v, list) and len(v) > i else np.nan)\n",
    "            # Convert to integer, coercing errors to NaN\n",
    "            df1[col_name] = pd.to_numeric(df1[col_name], errors='coerce').astype('Int64')\n",
    "\n",
    "#　種牡馬名のspace削除\n",
    "df1['種牡馬'] = df1['種牡馬'].astype(str).str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# 血統データの列を追加\n",
    "df1['父×母父系統'] = df1['種牡馬'].astype(str) + '×' + df1['母の父タイプ名'].astype(str)\n",
    "df1['父系統×母父系統'] = df1['種牡馬タイプ名'].astype(str) + '×' + df1['母の父タイプ名'].astype(str)\n",
    "\n",
    "# マッピング対象の値をdf1の別列に代入\n",
    "if '前半3F' not in df1.columns:\n",
    "    df1['前半3F'] = pd.NA\n",
    "OVERWRITE = True  # 既存も上書きする → Falseなら空欄だけ埋める\n",
    "\n",
    "# キーの型を揃える（数字/ゼロ埋めブレ防止）\n",
    "for c in ['target_horseid', 'target_raceid']:\n",
    "    if c in df1: df1[c] = df1[c].astype(str)\n",
    "\n",
    "for d in [df2, df3, df4, df5, df6, df7, df8, df9]:\n",
    "    for c in ['target_horseid', 'target_raceid']:\n",
    "        if c in d: d[c] = d[c].astype(str)\n",
    "\n",
    "# 初角位置の代入\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df2[['target_horseid','馬印4']].dropna(subset=['馬印4']).set_index('target_horseid')\n",
    "left.update(right, overwrite=OVERWRITE)\n",
    "df1 = left.reset_index()\n",
    "# 2角位置の代入\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df3[['target_horseid','馬印5']].dropna(subset=['馬印5']).set_index('target_horseid')\n",
    "left.update(right, overwrite=OVERWRITE)\n",
    "df1 = left.reset_index()\n",
    "# 3角位置の代入\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df4[['target_horseid','馬印6']].dropna(subset=['馬印6']).set_index('target_horseid')\n",
    "left.update(right, overwrite=OVERWRITE)\n",
    "df1 = left.reset_index()\n",
    "# 4角位置の代入\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df5[['target_horseid','馬印7']].dropna(subset=['馬印7']).set_index('target_horseid')\n",
    "left.update(right, overwrite=OVERWRITE)\n",
    "df1 = left.reset_index()\n",
    "# 上り位置の代入\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df6[['target_horseid','馬印3']].dropna(subset=['馬印3']).set_index('target_horseid')\n",
    "left.update(right, overwrite=OVERWRITE)\n",
    "df1 = left.reset_index()\n",
    "# 馬場指数の代入\n",
    "left  = df1.set_index('target_raceid')\n",
    "right = df7[['target_raceid','レース印']].dropna(subset=['レース印']).set_index('target_raceid')\n",
    "left.update(right, overwrite=OVERWRITE)\n",
    "df1 = left.reset_index()\n",
    "# 前半3Fタイムの代入\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df8[['target_horseid','前半3F']].dropna(subset=['前半3F']).set_index('target_horseid')\n",
    "left.update(right, overwrite=OVERWRITE)\n",
    "df1 = left.reset_index()\n",
    "# レイティングの代入\n",
    "left  = df1.set_index('target_horseid')\n",
    "right = df9[['target_horseid','レイティング']].dropna(subset=['レイティング']).set_index('target_horseid')\n",
    "left.update(right, overwrite=OVERWRITE)\n",
    "df1 = left.reset_index()\n",
    "\n",
    "# --- 関数群 ---\n",
    "def calculate_33_lap(df1):\n",
    "    \"\"\"距離ごとに33ラップを計算する\"\"\"\n",
    "    rap_33 = []\n",
    "    distance_to_lap_range = {\n",
    "        1000: (0, 3),\n",
    "        1150: (0, 3),  # 1150mは後で補正\n",
    "        1200: (0, 3),\n",
    "        1300: (1, 4),\n",
    "        1400: (1, 4),\n",
    "        1500: (2, 5),\n",
    "        1600: (2, 5),\n",
    "        1700: (3, 6),\n",
    "        1800: (3, 6),\n",
    "        1900: (4, 7),\n",
    "        2000: (4, 7),\n",
    "        2100: (5, 8),\n",
    "        2200: (5, 8),\n",
    "        2300: (6, 9),\n",
    "        2400: (6, 9),\n",
    "        2500: (7, 10),\n",
    "        2600: (7, 10),\n",
    "        2700: (8, 11),\n",
    "        2800: (8, 11),\n",
    "        2900: (9, 12),\n",
    "        3000: (9, 12),\n",
    "        3100: (10, 13),\n",
    "        3200: (10, 13),\n",
    "        3300: (11, 14),\n",
    "        3400: (11, 14),\n",
    "        3500: (12, 15),\n",
    "        3600: (12, 15),\n",
    "    }\n",
    "    for _, row in df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_lap_range:\n",
    "            start, end = distance_to_lap_range[distance]\n",
    "            sum_6to4 = sum(lap_times[start:end])\n",
    "        elif distance == 1150:\n",
    "            sum_6to4 = round(lap_times[0] * 1.25, 1) + lap_times[1] + lap_times[2] if len(lap_times) >= 3 else None\n",
    "        else:\n",
    "            sum_6to4 = None\n",
    "        sum_3to1 = row['レース上り3F'] if 'レース上り3F' in row and not pd.isna(row['レース上り3F']) else None\n",
    "        rap_33_value = sum_6to4 - sum_3to1 if not pd.isna(sum_6to4) and not pd.isna(sum_3to1) else None\n",
    "        rap_33.append(rap_33_value)\n",
    "    df1['33ラップ'] = rap_33\n",
    "    return df1\n",
    "\n",
    "def calculate_middle_lap(df1):\n",
    "    \"\"\"距離ごとに中盤ラップ1・2を計算する\"\"\"\n",
    "    middle_lap1 = []\n",
    "    middle_lap2 = []\n",
    "    distance_to_mid_lap = {\n",
    "        1000: (2, 4, None, None),\n",
    "        1150: (2, 4, None, None),\n",
    "        1200: (2, 4, None, None),\n",
    "        1300: (2, 4, None, None),\n",
    "        1400: (2, 4, None, None),\n",
    "        1500: (3, 5, None, None),\n",
    "        1600: (3, 5, None, None),\n",
    "        1700: (3, 6, None, None),\n",
    "        1800: (3, 6, None, None),\n",
    "        1900: (3, 7, None, None),\n",
    "        2000: (3, 7, None, None),\n",
    "        2100: (3, 5, 5, 8),\n",
    "        2200: (3, 5, 5, 8),\n",
    "        2300: (3, 5, 5, 8),\n",
    "        2400: (3, 6, 6, 9),\n",
    "        2500: (3, 6, 6, 9),\n",
    "        2600: (3, 7, 7, 10),\n",
    "        3000: (3, 8, 8, 12),\n",
    "        3200: (3, 8, 8, 13),\n",
    "        3400: (3, 9, 9, 14),\n",
    "        3600: (3, 9, 9, 15),\n",
    "    }\n",
    "    for _, row in df1.iterrows():\n",
    "        distance = row['距離']\n",
    "        lap_times = [row[f'Lap{str(i+1).zfill(2)}'] for i in range(25)]\n",
    "        lap_times = [t for t in lap_times if not pd.isna(t)]\n",
    "        if distance in distance_to_mid_lap:\n",
    "            mid1_start, mid1_end, mid2_start, mid2_end = distance_to_mid_lap[distance]\n",
    "            mid1 = sum(lap_times[mid1_start:mid1_end]) if mid1_start is not None else None\n",
    "            mid2 = sum(lap_times[mid2_start:mid2_end]) if mid2_start is not None else None\n",
    "        else:\n",
    "            mid1 = None\n",
    "            mid2 = None\n",
    "        middle_lap1.append(mid1)\n",
    "        middle_lap2.append(mid2)\n",
    "    df1['中盤ラップ1'] = middle_lap1\n",
    "    df1['中盤ラップ2'] = middle_lap2\n",
    "    return df1\n",
    "\n",
    "def calculate_lap_features(df1):\n",
    "    \"\"\"\n",
    "    Lap01～Lap25 を使って\n",
    "      ・最大加速（隣接ラップ差分の最小値）\n",
    "      ・ゴール前ラップ差（ラスト1F - ラスト2F）\n",
    "    を計算して df に列を追加する。\n",
    "    \"\"\"\n",
    "    lap_cols = [f'Lap{str(i).zfill(2)}' for i in range(1, 26)]\n",
    "\n",
    "    def _calc_row(row):\n",
    "        # その馬のラップ一覧（NaN は除外）\n",
    "        laps = []\n",
    "        for c in lap_cols:\n",
    "            if c in row.index and pd.notna(row[c]):\n",
    "                laps.append(row[c])\n",
    "\n",
    "        # ラップが1つ以下ならどっちも計算不能\n",
    "        if len(laps) < 2:\n",
    "            return pd.Series({'最大加速ラップ': np.nan, 'ゴール前ラップ差': np.nan})\n",
    "\n",
    "        laps = np.array(laps, dtype=float)\n",
    "\n",
    "        # 隣り合う差分（後ろ - 前）\n",
    "        diffs = np.diff(laps)   # 例：Lap02-Lap01, Lap03-Lap02, ...\n",
    "\n",
    "        # 最大加速 = 最もマイナスが大きい差分（＝最小値）\n",
    "        max_accel = diffs.min() if len(diffs) > 0 else np.nan\n",
    "\n",
    "        # 終盤ラップ差 = ラスト1F - ラスト2F\n",
    "        last_diff = laps[-1] - laps[-2] if len(laps) >= 2 else np.nan\n",
    "\n",
    "        return pd.Series({\n",
    "            '最大加速ラップ': max_accel if pd.notna(max_accel) else np.nan,\n",
    "            'ゴール前ラップ差': last_diff if pd.notna(last_diff) else np.nan\n",
    "        })\n",
    "\n",
    "    new_cols = df1.apply(_calc_row, axis=1)\n",
    "    df1['最大加速ラップ'] = new_cols['最大加速ラップ'].round(1)\n",
    "    df1['ゴール前ラップ差'] = new_cols['ゴール前ラップ差'].round(1)\n",
    "\n",
    "    return df1\n",
    "\n",
    "def calculate_days_since_birth(df1):\n",
    "    \"\"\"生後日数を計算する\"\"\"\n",
    "    birth_days = []\n",
    "    for _, row in df1.iterrows():\n",
    "        race_date = datetime.strptime(row['日付S'], '%Y.%m.%d')\n",
    "        birth_str = row['誕生日'].replace(\" \", \"\").replace(\"日\", \"\").replace(\"-\", \"\")\n",
    "        birth_month, birth_day = map(int, birth_str.replace(\"月\", \" \").split())\n",
    "        birth_year = race_date.year - row['年齢']\n",
    "        try:\n",
    "            birth_date = datetime(birth_year, birth_month, birth_day)\n",
    "        except ValueError:\n",
    "            birth_date = datetime(birth_year, 2, 28)\n",
    "        days_old = (race_date - birth_date).days\n",
    "        birth_days.append(days_old)\n",
    "    df1['生後日数'] = birth_days\n",
    "    return df1\n",
    "\n",
    "def calculate_distance_diff(df1):\n",
    "    \"\"\"前走距離との差を計算する\"\"\"\n",
    "    df1['前走距離差'] = df1['距離'] - df1['前走距離']\n",
    "    return df1\n",
    "\n",
    "def calculate_firsthalf_diff(df1):\n",
    "    \"\"\"1角から4角位置の差分を計算\"\"\"\n",
    "    df1['1角_4角差'] = df1.apply(lambda row: row['通過3'] - row['通過4'] if pd.isna(row['通過1']) else row['通過1'] - row['通過4'], axis=1).fillna(0)\n",
    "    return df1\n",
    "\n",
    "def calculate_goal_diff(df1):\n",
    "    \"\"\"4角位置から入線順位の差分を計算\"\"\"\n",
    "    df1['入線順位'] = df1['入線順位'].apply(lambda x: df1['頭数'][df1['入線順位'] == x].values[0] if x == 0 else x)\n",
    "    df1['4角_入線順位差'] = df1['通過4'].fillna(0) - df1['入線順位'].fillna(0)\n",
    "    return df1\n",
    "\n",
    "def calculate_sideposition(df1):\n",
    "    \"\"\"サイドポジションの平均を計算する\"\"\"\n",
    "    cols = ['馬印4', '馬印5', '馬印6', '馬印7']\n",
    "    df1['サイドポジション平均'] = df1[cols].mean(axis=1)\n",
    "    return df1\n",
    "\n",
    "def calculate_totalprize(df1):\n",
    "    \"\"\"獲得賞金を計算する\"\"\"\n",
    "    df1['獲得賞金'] = df1['賞金'].fillna(0) + df1['付加賞金'].fillna(0)\n",
    "    return df1\n",
    "\n",
    "def convert_time_to_seconds(time_str):\n",
    "    \"\"\"タイム表記を秒数に変換\"\"\"\n",
    "    try:\n",
    "        parts = time_str.split(\".\")\n",
    "        if len(parts) == 3:\n",
    "            minutes, seconds, tenths = map(int, parts)\n",
    "            total_seconds = minutes * 60 + seconds + tenths * 0.1\n",
    "        else:\n",
    "            return np.nan\n",
    "        return total_seconds\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def remove_plus_sign(value):\n",
    "    \"\"\"数値データから `+` を削除して変換\"\"\"\n",
    "    try:\n",
    "        return float(str(value).replace(\"+\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def extract_weight(value):\n",
    "    \"\"\"斤量の数値部分だけを抽出\"\"\"\n",
    "    try:\n",
    "        match = re.search(r'\\d+', str(value))\n",
    "        return int(match.group()) if match else np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_corner_loss(row):\n",
    "    \"\"\"コーナーロスを計算\"\"\"\n",
    "    corner_positions = [\n",
    "        row.get('馬印4', 1) - 1,\n",
    "        row.get('馬印5', 1) - 1,\n",
    "        row.get('馬印6', 1) - 1,\n",
    "        row.get('馬印7', 1) - 1\n",
    "    ]\n",
    "    total_distance_loss = sum(corner_positions) * 1.5  # m単位\n",
    "    finish_time_seconds = row['タイムS']\n",
    "    distance_m = row['距離']\n",
    "    if pd.isna(finish_time_seconds) or pd.isna(distance_m) or finish_time_seconds == 0:\n",
    "        return np.nan\n",
    "    avg_speed = distance_m / finish_time_seconds if finish_time_seconds > 0 else np.nan\n",
    "    corner_loss = total_distance_loss / avg_speed if avg_speed > 0 else 0\n",
    "    return round(corner_loss, 2)\n",
    "\n",
    "# 各列の型変換\n",
    "df1['レース印'] = df1['レース印'].astype(str).str.extract(r'(-?\\d+)')[0].astype('Int64')\n",
    "df1['体重'] = pd.to_numeric(df1['体重'], errors='coerce')\n",
    "df1['Ave-3F'] = pd.to_numeric(df1['Ave-3F'], errors='coerce')\n",
    "df1['上り3F'] = pd.to_numeric(df1['上り3F'], errors='coerce')\n",
    "\n",
    "for col in ['前後3F差', '前後4F差', '前後5F差', '増減']:\n",
    "    df1[col] = df1[col].apply(remove_plus_sign)\n",
    "\n",
    "for corner_col in ['馬印4', '馬印5', '馬印6', '馬印7']:\n",
    "    df1[corner_col] = pd.to_numeric(df1[corner_col], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "df1['タイムS'] = df1['タイムS'].apply(convert_time_to_seconds)\n",
    "\n",
    "df1['斤量'] = df1['斤量'].apply(extract_weight)\n",
    "\n",
    "# 各種計算関数を順次実行\n",
    "df1 = calculate_33_lap(df1)\n",
    "df1 = calculate_middle_lap(df1)\n",
    "df1 = calculate_lap_features(df1)\n",
    "df1 = calculate_days_since_birth(df1)\n",
    "df1 = calculate_distance_diff(df1)\n",
    "df1 = calculate_firsthalf_diff(df1)\n",
    "df1 = calculate_goal_diff(df1)\n",
    "df1 = calculate_sideposition(df1)\n",
    "df1 = calculate_totalprize(df1)\n",
    "\n",
    "df1['-3Fタイム'] = df1['-3Fタイム'].apply(convert_time_to_seconds)\n",
    "df1['基準斤量'] = df1['斤量'] - df1['馬齢斤量差']\n",
    "df1['コーナーロス'] = df1.apply(calculate_corner_loss, axis=1)\n",
    "df1['補正走破タイム'] = df1['タイムS'] - df1['コーナーロス']\n",
    "df1['スローorハイ関数'] = df1['Ave-3F'] - df1['上り3F']\n",
    "\n",
    "# マージ用の列作成処理\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 115:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 範囲定義\n",
    "ranges = [\n",
    "    (-np.inf, -4.6), (-4.6, -3.6), (-3.6, -2.6), (-2.6, -1.6), (-1.6, -0.6),\n",
    "    (-0.6, 0.6), (0.6, 1.6), (1.6, 2.6), (2.6, 3.6), (3.6, 4.6), (4.6, np.inf)\n",
    "]\n",
    "\n",
    "# 区間ラベル\n",
    "def assign_range(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        if i < len(ranges) - 1:\n",
    "            if lower <= value < upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "        else:\n",
    "            # 最終区間（4.6～inf）は右も含める\n",
    "            if lower <= value <= upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "    return np.nan  # 念のため\n",
    "\n",
    "# 馬場分類・競走種別・クラス分類の列を作成する\n",
    "df1['馬場分類'] = df1['馬場状態'].replace({'良': '良・稍重','稍': '良・稍重','重': '重・不良','不': '重・不良'})\n",
    "df1['競走種別'] = df1['年齢限定(競走種別コード)'].apply(categorize_race_type)\n",
    "df1['クラス分類'] = df1['クラスコード'].apply(categorize_class_code)\n",
    "df1['スローorハイ関数範囲'] = df1['スローorハイ関数'].apply(assign_range)\n",
    "\n",
    "# --- 集計設定 ---\n",
    "agg_cols1 = {\n",
    "    'レースPCI': 'median',\n",
    "    'PCI3': 'median',\n",
    "    'PCI': 'median',\n",
    "    '通過3F': 'median',\n",
    "    '通過4F': 'median',\n",
    "    '通過5F': 'median',\n",
    "    'レース上り3F': 'median',\n",
    "    'レース上り4F': 'median',\n",
    "    'レース上り5F': 'median',\n",
    "    '中盤ラップ1': 'median',\n",
    "    '中盤ラップ2': 'median',\n",
    "    '33ラップ': 'median',\n",
    "    '最大加速ラップ': 'median',\n",
    "    'ゴール前ラップ差': 'median',\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '-3F差': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '1角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "agg_cols2 = {\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '-3F差': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '1角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "# --- 基準タイム算出処理1 ---\n",
    "# 1勝クラス・2勝クラスのみ対象\n",
    "base_df1 = df1[df1['クラスコード'].isin([23, 43])].copy()\n",
    "\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops1 = base_df1[base_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st1 = base_df1[base_df1['入線順位'] == 1].copy()\n",
    "\n",
    "# クラス分類の統一\n",
    "df_tops1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "df_1st1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "\n",
    "# グループ化キー\n",
    "group_cols1 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)','馬場分類', 'クラス分類']\n",
    "\n",
    "# --- 集計処理 ---\n",
    "base_time_tops1 = df_tops1.groupby(group_cols1, dropna=False).agg(agg_cols1).reset_index()\n",
    "base_time_1st1 = df_1st1.groupby(group_cols1, dropna=False).agg(agg_cols2).reset_index()\n",
    "base_time_1st1 = base_time_1st1.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "\n",
    "# --- 結合 ---\n",
    "base_time_df1 = pd.merge(base_time_tops1, base_time_1st1, on=group_cols1, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df1['距離係数'] = (1 / base_time_df1['タイムS']) * 100\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "\n",
    "df_tops2 = df1[df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st2 = df1[df1['入線順位'] == 1].copy()\n",
    "\n",
    "# グループ化キー\n",
    "group_cols2 = ['場所', '芝・ダート', '距離','トラックコード(JV)', '競走種別', 'クラス分類', '馬場分類']\n",
    "\n",
    "base_time_tops2 = df_tops2.groupby(group_cols2).agg(agg_cols1).reset_index()\n",
    "base_time_1st2 = df_1st2.groupby(group_cols2).agg(agg_cols2).reset_index()\n",
    "base_time_1st2 = base_time_1st2.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "base_time_df2 = pd.merge(base_time_tops2, base_time_1st2, on=group_cols2, how=\"left\")\n",
    "\n",
    "# --- ペース係数算出処理 ---\n",
    "\n",
    "# 外れ値除外（IQR）\n",
    "def remove_outliers(group):\n",
    "    Q1 = group['タイムS'].quantile(0.25)\n",
    "    Q3 = group['タイムS'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return group[(group['タイムS'] >= lower_bound) & (group['タイムS'] <= upper_bound)]\n",
    "\n",
    "# 区間ラベル\n",
    "def assign_range(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    for i, (lower, upper) in enumerate(ranges):\n",
    "        if i < len(ranges) - 1:\n",
    "            if lower <= value < upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "        else:\n",
    "            # 最終区間（4.6～inf）は右も含める\n",
    "            if lower <= value <= upper:\n",
    "                return f\"{lower}～{upper}\"\n",
    "    return np.nan  # 念のため\n",
    "\n",
    "# グルーピング＆IQR除外\n",
    "pace_df = (\n",
    "    df1.groupby(['場所', '芝・ダート', '距離','トラックコード(JV)'])\n",
    "       .apply(remove_outliers)\n",
    "       .reset_index(drop=True)\n",
    "       .copy()\n",
    ")\n",
    "\n",
    "# 区間ラベリング\n",
    "pace_df['スローorハイ関数範囲'] = pace_df['スローorハイ関数'].apply(assign_range)\n",
    "\n",
    "# 区間別の中央値（タイムS & スローorハイ関数）\n",
    "grouped_medians = pace_df.groupby(\n",
    "    ['場所', '芝・ダート', '距離','トラックコード(JV)', 'スローorハイ関数範囲']\n",
    ").agg({\n",
    "    'タイムS': 'median',\n",
    "    'スローorハイ関数': 'median'\n",
    "}).reset_index()\n",
    "\n",
    "# --- ベースライン作成 ---\n",
    "# 優先：-0.6～0.6（中庸帯）\n",
    "# 代用：0.6～1.6 / -1.6～-0.6 の平均 → どちらか片方だけでも可\n",
    "baseline_medians = {}\n",
    "for (location, turf_dirt, distance,track_code), group_df in grouped_medians.groupby(['場所', '芝・ダート', '距離','トラックコード(JV)']):\n",
    "    baseline_row = group_df[group_df['スローorハイ関数範囲'] == '-0.6～0.6']\n",
    "    if not baseline_row.empty:\n",
    "        baseline_median = float(baseline_row['タイムS'].iloc[0])\n",
    "    else:\n",
    "        range_negative = group_df[group_df['スローorハイ関数範囲'] == '-1.6～-0.6']\n",
    "        range_positive = group_df[group_df['スローorハイ関数範囲'] == '0.6～1.6']\n",
    "        if not range_negative.empty and not range_positive.empty:\n",
    "            baseline_median = (float(range_negative['タイムS'].median()) +\n",
    "                               float(range_positive['タイムS'].median())) / 2.0\n",
    "        elif not range_negative.empty:\n",
    "            baseline_median = float(range_negative['タイムS'].median())\n",
    "        elif not range_positive.empty:\n",
    "            baseline_median = float(range_positive['タイムS'].median())\n",
    "        else:\n",
    "            baseline_median = np.nan\n",
    "    baseline_medians[(location, turf_dirt, distance,track_code)] = baseline_median\n",
    "\n",
    "# ベースラインとの差（スローorハイ関数差指数）\n",
    "def calculate_difference(row):\n",
    "    key = (row['場所'], row['芝・ダート'], row['距離'],row['トラックコード(JV)'])\n",
    "    baseline_time = baseline_medians.get(key, np.nan)\n",
    "    return row['タイムS'] - baseline_time if not pd.isna(baseline_time) else np.nan\n",
    "\n",
    "grouped_medians['スローorハイ関数差指数'] = grouped_medians.apply(calculate_difference, axis=1)\n",
    "\n",
    "# 係数計算（0除算・NaN安全＋クリップ）\n",
    "def calculate_pace_adjustment_coefficient(row):\n",
    "    val = row['スローorハイ関数']\n",
    "    diff = row['スローorハイ関数差指数']\n",
    "    if pd.notna(val) and val != 0 and pd.notna(diff):\n",
    "        coefficient = round(diff / val, 2)\n",
    "        return float(np.clip(coefficient, -3, 3))\n",
    "    return 0.0\n",
    "\n",
    "grouped_medians['ペース補正係数'] = grouped_medians.apply(calculate_pace_adjustment_coefficient, axis=1)\n",
    "\n",
    "# --- 基準33ラップ算出処理 ---\n",
    "lap33_df = (\n",
    "    df1\n",
    "      .dropna(subset=['33ラップ'])  # まず欠損を除外\n",
    "      .groupby(['場所', '芝・ダート', '距離', 'トラックコード(JV)'], dropna=False)['33ラップ']\n",
    "      .agg(['mean', 'std'])  # mean と std を同時に集計\n",
    "      .reset_index()\n",
    ").copy()\n",
    "\n",
    "# 近似Zスコア用の基準値を計算\n",
    "lap33_df['33ラップ±0'] = lap33_df['mean'].round(2)\n",
    "lap33_df['33ラップ+1'] = (lap33_df['mean'] + lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ-1'] = (lap33_df['mean'] - lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ+2'] = (lap33_df['mean'] + 2 * lap33_df['std']).round(2)\n",
    "lap33_df['33ラップ-2'] = (lap33_df['mean'] - 2 * lap33_df['std']).round(2)\n",
    "\n",
    "# 必要なカラムだけ残す\n",
    "lap33_df = lap33_df[\n",
    "    ['場所', '芝・ダート', '距離', 'トラックコード(JV)',\n",
    "     '33ラップ-2', '33ラップ-1', '33ラップ±0', '33ラップ+1', '33ラップ+2',\n",
    "     'mean', 'std']\n",
    "]\n",
    "\n",
    "# CSV出力\n",
    "df1.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "base_time_df1.to_csv(output_filepath2, index=False, encoding='cp932')\n",
    "base_time_df2.to_csv(output_filepath3, index=False, encoding='cp932')\n",
    "grouped_medians.to_csv(output_filepath4, index=False, encoding='cp932')\n",
    "lap33_df.to_csv(output_filepath5, index=False, encoding='cp932')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 成績データへ指数の追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_19984\\171397495.py:33: DtypeWarning: Columns (21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(master_filepath, encoding='CP932').copy()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 指数追加用成績データファイルのパス\n",
    "master_filepath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "\n",
    "# 参照用基準タイムファイルのパス\n",
    "ref_filepath1 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master1.csv'\n",
    "ref_filepath2 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master2.csv'\n",
    "ref_filepath3 = r'D:\\Keiba\\20_IndexData\\Pace_Coefficient_Master.csv'\n",
    "ref_filepath4 = r'D:\\Keiba\\20_IndexData\\Base_33Lap_Master.csv'\n",
    "\n",
    "# 派生マスタcsvファイルのパス\n",
    "output_filepath1 = r'D:\\Keiba\\00_ImportData\\160_33Lap_Category\\33Lap_Category_Master.csv'\n",
    "\n",
    "# 共通関数：参照側DFのキー以外の列にサフィックスを付ける\n",
    "def prepare_ref_df(df_ref, merge_keys, suffix):\n",
    "    \"\"\"\n",
    "    マージ用の参照DFの列名に suffix を付ける（キー列以外すべて）\n",
    "    \"\"\"\n",
    "    df_ref = df_ref.copy()\n",
    "    rename_map = {\n",
    "        c: f\"{c}{suffix}\"\n",
    "        for c in df_ref.columns\n",
    "        if c not in merge_keys\n",
    "    }\n",
    "    df_ref = df_ref.rename(columns=rename_map)\n",
    "    return df_ref\n",
    "\n",
    "# ファイルを開く\n",
    "df1 = pd.read_csv(master_filepath, encoding='CP932').copy()\n",
    "df2 = pd.read_csv(ref_filepath1, encoding='CP932').copy()\n",
    "df3 = pd.read_csv(ref_filepath2, encoding='CP932').copy()\n",
    "df4 = pd.read_csv(ref_filepath3, encoding='CP932').copy()\n",
    "df5 = pd.read_csv(ref_filepath4, encoding='CP932').copy()\n",
    "\n",
    "# マージキー\n",
    "merge_key1 = ['場所','芝・ダート','距離','トラックコード(JV)','馬場分類']\n",
    "merge_key2 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類','馬場分類']\n",
    "merge_key3 = ['場所','芝・ダート','距離','トラックコード(JV)','スローorハイ関数範囲']\n",
    "merge_key4 = ['場所','芝・ダート','距離','トラックコード(JV)']\n",
    "\n",
    "# 参照側の列名にsuffixを付けてからマージ\n",
    "df2_pre = prepare_ref_df(df2, merge_key1, '_stdtime1')\n",
    "df3_pre = prepare_ref_df(df3, merge_key2, '_stdtime2')\n",
    "df4_pre = prepare_ref_df(df4, merge_key3, '_paceindex')\n",
    "df5_pre = prepare_ref_df(df5, merge_key4, '_33lap')\n",
    "\n",
    "# df1へその他データフレームをマージ\n",
    "merged_df1 = pd.merge(df1, df2_pre, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, df3_pre, on=merge_key2, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, df4_pre, on=merge_key3, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, df5_pre, on=merge_key4, how='left')\n",
    "\n",
    "# 各指数算出の前処理\n",
    "merged_df1['平均3F補正値'] = merged_df1['Ave-3F_stdtime1'] - merged_df1['Ave-3F']\n",
    "merged_df1['馬場指数'] = merged_df1['レース印'] / 10\n",
    "merged_df1['斤量補正値'] = merged_df1['斤量'] - merged_df1['基準斤量']\n",
    "merged_df1['クラス補正値'] = merged_df1['タイムS_stdtime1'] - merged_df1['タイムS_stdtime2']\n",
    "merged_df1['ペース補正値'] = merged_df1['スローorハイ関数'] * merged_df1['ペース補正係数_paceindex']\n",
    "\n",
    "merged_df1['初角位置'] = merged_df1['通過1'].fillna(merged_df1['通過2']) # 1角がない場合は2角で補完\n",
    "merged_df1['初角位置'] = merged_df1['初角位置'].fillna(merged_df1['通過3']) # 2角がない場合は3角で補完\n",
    "merged_df1['初角位置'] = merged_df1['初角位置'].fillna(merged_df1['通過4']) # 3角がない場合は4角で補完\n",
    "\n",
    "# テン指数の計算\n",
    "merged_df1['テン指数'] = round((\n",
    "(merged_df1['前半3F_stdtime1'].fillna(merged_df1['前半3F_stdtime2']) - merged_df1['前半3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数'] - merged_df1['初角位置'] + 1) / merged_df1['頭数']) # 初角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# 上り指数の計算\n",
    "merged_df1['上り指数'] = round((\n",
    "(merged_df1['レース上り3F_stdtime1'].fillna(merged_df1['レース上り3F_stdtime2']) - merged_df1['レース上り3F']) # 基準タイムとの比較評価\n",
    "+ ((merged_df1['頭数']) - merged_df1['入線順位'] + 1) / merged_df1['頭数'] # 着順評価\n",
    "+ (merged_df1['通過4'] - merged_df1['入線順位']) / merged_df1['頭数'] # ポジション押し上げ力評価\n",
    "+ (merged_df1['頭数'] - merged_df1['通過4'] + 1) / merged_df1['頭数'] # 4角の位置取り評価\n",
    "+ 50\n",
    "), 1)\n",
    "\n",
    "# スピード指数の計算\n",
    "merged_df1['スピード指数'] = round((\n",
    "    (((merged_df1['タイムS'].fillna(0))\n",
    "     - (merged_df1['補正走破タイム'].fillna(0)))\n",
    "      * merged_df1['距離係数_stdtime1'].fillna(0))\n",
    "  + merged_df1['馬場指数'].fillna(0)\n",
    "  + merged_df1['平均3F補正値'].fillna(0)\n",
    "  + merged_df1['斤量補正値'].fillna(0)\n",
    "  + merged_df1['クラス補正値'].fillna(0)\n",
    "  + merged_df1['ペース補正値'].fillna(0)\n",
    "  + 100\n",
    "), 1)\n",
    "\n",
    "# 総合指数の計算\n",
    "merged_df1['総合指数'] = round(\n",
    "    (merged_df1['スピード指数'].fillna(0) + merged_df1['補正タイム'].fillna(0) + merged_df1['補9'].fillna(0)) / 3, 1\n",
    ")\n",
    "\n",
    "# 総合指数の代表値(1着～3着)をdf1へ追加\n",
    "central_score_df1 = merged_df1[merged_df1['入線順位'].between(1, 3)].copy()\n",
    "central_score_df1 = central_score_df1.groupby('target_raceid' ,as_index = False)['総合指数'].mean()\n",
    "central_score_df1.rename(columns={'総合指数': 'Top3総合指数'}, inplace=True)\n",
    "central_score_df1['Top3総合指数'] = round(central_score_df1['Top3総合指数'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df1, on='target_raceid', how='left',suffixes=('', '_centralscore1')).copy()\n",
    "\n",
    "# レイティングの平均値をdf1へ追加\n",
    "merged_df1['レイティング'] = pd.to_numeric(merged_df1['レイティング'], errors='coerce')\n",
    "central_score_df2 = df1.groupby('target_raceid' ,as_index = False)['レイティング'].mean().copy()\n",
    "central_score_df2.rename(columns={'レイティング': 'レイティング平均値'}, inplace=True)\n",
    "central_score_df2['レイティング平均値'] = round(central_score_df2['レイティング平均値'], 1)\n",
    "merged_df1 = pd.merge(merged_df1, central_score_df2, on='target_raceid', how='left' ,suffixes=('', '_centralscore2')).copy()\n",
    "\n",
    "# 基準総合指数と総合指数の差分をdf1へ追加\n",
    "merged_df1['基準総合指数差分'] = merged_df1['総合指数'] - merged_df1['Top3総合指数']\n",
    "\n",
    "# レイティング平均値とレイティングの差分を追加\n",
    "merged_df1['平均レイティング差分'] = merged_df1['レイティング'] - merged_df1['レイティング平均値']\n",
    "\n",
    "# レースごと（target_raceidごと）に大きい順で順位をつける\n",
    "# 同点は同順位にして、次は飛ばさない（例：1位,1位,2位,3位…）＝ \"dense\" 方式\n",
    "merged_df1['レイティング順位'] = merged_df1.groupby('target_raceid')['レイティング'].rank(ascending=False, method='dense').astype('Int64')\n",
    "merged_df1['テン指数順位']     = merged_df1.groupby('target_raceid')['テン指数']    .rank(ascending=False, method='dense').astype('Int64')\n",
    "merged_df1['上り指数順位']   = merged_df1.groupby('target_raceid')['上り指数']  .rank(ascending=False, method='dense').astype('Int64')\n",
    "merged_df1['スピード指数順位'] = merged_df1.groupby('target_raceid')['スピード指数'].rank(ascending=False, method='dense').astype('Int64')\n",
    "merged_df1['総合指数順位']     = merged_df1.groupby('target_raceid')['総合指数']    .rank(ascending=False, method='dense').astype('Int64')\n",
    "\n",
    "# 33ラップの判定処理\n",
    "merged_df1['33ラップ-2_差分'] = abs(merged_df1['33ラップ'] - merged_df1['33ラップ-2_33lap'])\n",
    "merged_df1['33ラップ-1_差分'] = abs(merged_df1['33ラップ'] - merged_df1['33ラップ-1_33lap'])\n",
    "merged_df1['33ラップ±0_差分'] = abs(merged_df1['33ラップ'] - merged_df1['33ラップ±0_33lap'])\n",
    "merged_df1['33ラップ+1_差分'] = abs(merged_df1['33ラップ'] - merged_df1['33ラップ+1_33lap'])\n",
    "merged_df1['33ラップ+2_差分'] = abs(merged_df1['33ラップ'] - merged_df1['33ラップ+2_33lap'])\n",
    "\n",
    "# 33ラップ判定用関数\n",
    "def assign_label(row):\n",
    "  lap_value = row['33ラップ']\n",
    "\n",
    "  # 33ラップが欠損なら何も判定しない\n",
    "  if pd.isna(lap_value):\n",
    "    return np.nan\n",
    "\n",
    "  # 差分辞書\n",
    "  diffs = {\n",
    "      '33ラップ-2_差分': row['33ラップ-2_差分'],\n",
    "      '33ラップ-1_差分': row['33ラップ-1_差分'],\n",
    "      '33ラップ±0_差分': row['33ラップ±0_差分'],\n",
    "      '33ラップ+1_差分': row['33ラップ+1_差分'],\n",
    "      '33ラップ+2_差分': row['33ラップ+2_差分']\n",
    "  }\n",
    "\n",
    "  # 全部NaNならこれも判定不能にする\n",
    "  if all(pd.isna(v) for v in diffs.values()):\n",
    "      return np.nan\n",
    "\n",
    "  # 最小差分キーを取得\n",
    "  min_key = min(diffs, key=diffs.get)\n",
    "\n",
    "  # キーの数値マッピング\n",
    "  mapping = {\n",
    "      '33ラップ-2_差分':-2,\n",
    "      '33ラップ-1_差分':-1,\n",
    "      '33ラップ±0_差分':0,\n",
    "      '33ラップ+1_差分':1,\n",
    "      '33ラップ+2_差分':2\n",
    "  }\n",
    "\n",
    "  scale = mapping[min_key]\n",
    "\n",
    "  # 0スケールの場合\n",
    "  if scale == 0:\n",
    "        if lap_value < 0:\n",
    "            return '持0'\n",
    "        elif lap_value > 0:\n",
    "            return '瞬0'\n",
    "        else:\n",
    "            return '総'\n",
    "\n",
    "  # 0以外の場合\n",
    "  prefix = '瞬' if lap_value > 0 else '持'\n",
    "  if scale > 0:\n",
    "      suffix = f'+{scale}'\n",
    "  else:\n",
    "      suffix = f'{scale}'\n",
    "\n",
    "  return prefix + suffix\n",
    "\n",
    "# 33ラップを判定\n",
    "merged_df1['33ラップ判定'] = merged_df1.apply(assign_label, axis=1)\n",
    "\n",
    "# ラベル書き換え用のマッピング辞書\n",
    "label_mapping = {\n",
    "    '持-2': '0T持-2',\n",
    "    '持-1': '0T持-1',\n",
    "    '持0': '0U持0',\n",
    "    '持+1': '0V持+1',\n",
    "    '持+2': '0V持+2',\n",
    "    '瞬-2': '0S瞬-2',\n",
    "    '瞬-1': '0S瞬-1',\n",
    "    '瞬0': '0R瞬0',\n",
    "    '瞬+1': '0Q瞬+1',\n",
    "    '瞬+2': '0Q瞬+2',\n",
    "    '総': '02総'\n",
    "}\n",
    "\n",
    "# 書き換え\n",
    "merged_df1['レース印２'] = merged_df1['33ラップ判定'].replace(label_mapping)\n",
    "\n",
    "# レース強度指数の計算\n",
    "merged_df1['前半負荷'] = merged_df1['通過3F_stdtime1'].fillna(merged_df1['通過3F_stdtime2']) - merged_df1['通過3F']\n",
    "merged_df1['中盤1差'] = merged_df1['中盤ラップ1_stdtime1'].fillna(merged_df1['中盤ラップ1_stdtime2']) - merged_df1['中盤ラップ1']\n",
    "merged_df1['中盤2差'] = merged_df1['中盤ラップ2_stdtime1'].fillna(merged_df1['中盤ラップ2_stdtime2']) - merged_df1['中盤ラップ2']\n",
    "merged_df1['中盤負荷'] = merged_df1[['中盤1差', '中盤2差']].mean(axis=1, skipna=True)\n",
    "merged_df1['終盤負荷'] = merged_df1['レース上り3F_stdtime1'].fillna(merged_df1['レース上り3F_stdtime2']) - merged_df1['レース上り3F']\n",
    "merged_df1['加速度負荷'] = merged_df1['最大加速ラップ_stdtime1'].fillna(merged_df1['最大加速ラップ_stdtime2']) - merged_df1['最大加速ラップ']\n",
    "merged_df1['ゴール前負荷'] = merged_df1['ゴール前ラップ差_stdtime1'].fillna(merged_df1['ゴール前ラップ差_stdtime2']) - merged_df1['ゴール前ラップ差']\n",
    "merged_df1['馬場補正値'] = merged_df1['馬場指数'].fillna(0) * 0.1\n",
    "\n",
    "merged_df1['レース強度指数'] = (\n",
    "    100\n",
    "    + merged_df1['前半負荷'].fillna(0)\n",
    "    + merged_df1['中盤負荷'].fillna(0)\n",
    "    + merged_df1['終盤負荷'].fillna(0)\n",
    "    + merged_df1['加速度負荷'].fillna(0)\n",
    "    + merged_df1['ゴール前負荷'].fillna(0)\n",
    "    + merged_df1['馬場補正値'].fillna(0)\n",
    ")\n",
    "\n",
    "# サフィックス付き列を削除して保存\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_1着','_stdtime1', '_stdtime2', '_paceindex', '_33lap', '_centralscore1', '_centralscore2','_差分')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "clean_df = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "# インポート用ファイルの定義（レース単位）\n",
    "import_columns = ['target_raceid', 'レース印２']\n",
    "import_df = clean_df[import_columns].copy()\n",
    "\n",
    "# target_raceid で重複削除（最後の値を残す）\n",
    "import_df = import_df.drop_duplicates(subset='target_raceid', keep='last')\n",
    "\n",
    "# year列を追加（target_raceid の先頭4桁）\n",
    "import_df['year'] = pd.to_datetime(\n",
    "    import_df['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "# 成績データを上書き保存\n",
    "clean_df.to_csv(master_filepath, index=False, encoding='cp932')\n",
    "\n",
    "# レース印２のインポート用まとめファイル\n",
    "import_df.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "\n",
    "# 年度別ファイルに分割して保存\n",
    "for year, df_y in import_df.groupby('year'):\n",
    "    df_y.drop(columns='year').to_csv(\n",
    "        rf\"D:\\Keiba\\00_ImportData\\160_33Lap_Category\\33Lap_Category_Master_{int(year)}.csv\",\n",
    "        index=False,\n",
    "        encoding='cp932'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・基準タイムファイルへ列追加1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_19984\\868928031.py:14: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(master_filipath, encoding='CP932').copy()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 参照用成績データファイルのパス\n",
    "master_filipath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "\n",
    "# 更新ファイルのパス\n",
    "output_filepath1 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master1.csv'\n",
    "output_filepath2 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master2.csv'\n",
    "\n",
    "# ファイルを開く\n",
    "df1 = pd.read_csv(master_filipath, encoding='CP932').copy()\n",
    "\n",
    "# --- 集計設定 ---\n",
    "agg_cols1 = {\n",
    "    'レースPCI': 'median',\n",
    "    'PCI3': 'median',\n",
    "    'PCI': 'median',\n",
    "    '通過3F': 'median',\n",
    "    '通過4F': 'median',\n",
    "    '通過5F': 'median',\n",
    "    'レース上り3F': 'median',\n",
    "    'レース上り4F': 'median',\n",
    "    'レース上り5F': 'median',\n",
    "    '中盤ラップ1': 'median',\n",
    "    '中盤ラップ2': 'median',\n",
    "    '33ラップ': 'median',\n",
    "    '最大加速ラップ': 'median',\n",
    "    'ゴール前ラップ差': 'median',\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング順位':'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '-3F差': 'median',\n",
    "    'テン指数': 'median',\n",
    "    'テン指数順位': 'median',\n",
    "    '上り指数': 'median',\n",
    "    '上り指数順位': 'median',\n",
    "    'スピード指数': 'median',\n",
    "    'スピード指数順位': 'median',\n",
    "    '総合指数': 'median',\n",
    "    '総合指数順位': 'median',\n",
    "    'レース強度指数': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '1角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "agg_cols2 = {\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング順位':'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '-3F差': 'median',\n",
    "    'テン指数': 'median',\n",
    "    'テン指数順位': 'median',\n",
    "    '上り指数': 'median',\n",
    "    '上り指数順位': 'median',\n",
    "    'スピード指数': 'median',\n",
    "    'スピード指数順位': 'median',\n",
    "    '総合指数': 'median',\n",
    "    '総合指数順位': 'median',\n",
    "    'レース強度指数': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '1角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "# --- 基準タイム算出処理1 ---\n",
    "# 1勝クラス・2勝クラスのみ対象\n",
    "base_df1 = df1[df1['クラスコード'].isin([23, 43])].copy()\n",
    "\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops1 = base_df1[base_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st1 = base_df1[base_df1['入線順位'] == 1].copy()\n",
    "\n",
    "# クラス分類の統一\n",
    "df_tops1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "df_1st1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "\n",
    "# グループ化キー\n",
    "group_cols1 = ['場所', '芝・ダート', '距離','トラックコード(JV)', '馬場分類', 'クラス分類']\n",
    "\n",
    "# ---集計対象列（存在するものだけ）---\n",
    "num_cols1 = [c for c in agg_cols1.keys() if c in df_tops1.columns]\n",
    "num_cols1_1st = [c for c in agg_cols2.keys() if c in df_1st1.columns]\n",
    "\n",
    "# ---数値化：変換失敗は NaN に---\n",
    "df_tops1[num_cols1] = df_tops1[num_cols1].apply(pd.to_numeric, errors='coerce')\n",
    "df_1st1[num_cols1_1st] = df_1st1[num_cols1_1st].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# --- 集計処理 ---\n",
    "base_time_tops1 = df_tops1.groupby(group_cols1, dropna=False).agg(agg_cols1).reset_index()\n",
    "base_time_1st1 = df_1st1.groupby(group_cols1, dropna=False).agg(agg_cols2).reset_index()\n",
    "base_time_1st1 = base_time_1st1.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "\n",
    "# --- 結合 ---\n",
    "base_time_df1 = pd.merge(base_time_tops1, base_time_1st1, on=group_cols1, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df1['距離係数'] = (1 / base_time_df1['タイムS']) * 100\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops2 = df1[df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st2 = df1[df1['入線順位'] == 1].copy()\n",
    "\n",
    "# グループ化キー\n",
    "group_cols2 = ['場所', '芝・ダート', '距離','トラックコード(JV)', '競走種別', 'クラス分類', '馬場分類']\n",
    "\n",
    "base_time_tops2 = df_tops2.groupby(group_cols2).agg(agg_cols1).reset_index()\n",
    "base_time_1st2 = df_1st2.groupby(group_cols2).agg(agg_cols2).reset_index()\n",
    "base_time_1st2 = base_time_1st2.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "base_time_df2 = pd.merge(base_time_tops2, base_time_1st2, on=group_cols2, how=\"left\")\n",
    "\n",
    "# CSV出力(基準タイムファイルの更新)\n",
    "base_time_df1.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "base_time_df2.to_csv(output_filepath2, index=False, encoding='cp932')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レースレベル指数の算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_19984\\2702594063.py:28: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(master_filepath, encoding='CP932').copy()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 指数追加用成績データファイルのパス\n",
    "master_filepath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "\n",
    "# 参照用基準タイムファイルのパス\n",
    "ref_filepath1 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master1.csv'\n",
    "ref_filepath2 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master2.csv'\n",
    "\n",
    "#  共通関数：参照側DFのキー以外の列にサフィックスを付ける\n",
    "def prepare_ref_df(df_ref, merge_keys, suffix):\n",
    "    \"\"\"\n",
    "    マージ用の参照DFの列名に suffix を付ける（キー列以外すべて）\n",
    "    \"\"\"\n",
    "    df_ref = df_ref.copy()\n",
    "    rename_map = {\n",
    "        c: f\"{c}{suffix}\"\n",
    "        for c in df_ref.columns\n",
    "        if c not in merge_keys\n",
    "    }\n",
    "    df_ref = df_ref.rename(columns=rename_map)\n",
    "    return df_ref\n",
    "\n",
    "# ファイルを開く\n",
    "df1 = pd.read_csv(master_filepath, encoding='CP932').copy()\n",
    "df2 = pd.read_csv(ref_filepath1, encoding='CP932').copy()\n",
    "df3 = pd.read_csv(ref_filepath2, encoding='CP932').copy()\n",
    "\n",
    "# マージキー\n",
    "merge_key1 = ['場所','芝・ダート','距離','トラックコード(JV)','馬場分類']\n",
    "merge_key2 = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類','馬場分類']\n",
    "\n",
    "# 参照側の列名にsuffixを付けてからマージ\n",
    "df2_pre = prepare_ref_df(df2, merge_key1, '_stdtime1')\n",
    "df3_pre = prepare_ref_df(df3, merge_key2, '_stdtime2')\n",
    "\n",
    "# df1へその他データフレームをマージ\n",
    "merged_df1 = pd.merge(df1, df2_pre, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, df3_pre, on=merge_key2, how='left')\n",
    "\n",
    "# レースレベル指数の算出\n",
    "rating_base = merged_df1['レイティング_stdtime2'].fillna(merged_df1['レイティング_stdtime1'])\n",
    "speed_base  = merged_df1['総合指数_stdtime2'].fillna(merged_df1['総合指数_stdtime1'])\n",
    "strength_base = merged_df1['レース強度指数_stdtime2'].fillna(merged_df1['レース強度指数_stdtime1'])\n",
    "\n",
    "rating_diff = (merged_df1['レイティング平均値'] - rating_base).fillna(0)\n",
    "speed_diff  = (merged_df1['Top3総合指数'] - speed_base).fillna(0)\n",
    "strength_diff = (merged_df1['レース強度指数'] - strength_base).fillna(0)\n",
    "\n",
    "merged_df1['レースレベル指数'] = (rating_diff + speed_diff + strength_diff + 100).round(1)\n",
    "\n",
    "# サフィックス付き列を削除して保存\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_1着','_stdtime1', '_stdtime2')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "clean_df = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "# csvファイル保存\n",
    "clean_df.to_csv(master_filepath, index=False, encoding='cp932')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レースレベル基準ファイルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_19984\\1610236460.py:6: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(master_filepath, encoding='cp932').copy()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 成績マスタの読み込み（レースレベル指数まで追加済みの状態）\n",
    "master_filepath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "df1 = pd.read_csv(master_filepath, encoding='cp932').copy()\n",
    "\n",
    "# レースレベル指数を数値にしておく（念のため）\n",
    "df1['レースレベル指数'] = pd.to_numeric(df1['レースレベル指数'], errors='coerce')\n",
    "\n",
    "# 分類キー\n",
    "group_key = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類']\n",
    "\n",
    "# --- 基準レースレベル算出処理 ---\n",
    "racelevel_df = (\n",
    "    df1\n",
    "      .dropna(subset=['レースレベル指数'])  # 欠損を除外\n",
    "      .groupby(group_key, dropna=False)['レースレベル指数']\n",
    "      .agg(['mean', 'std'])  # mean と std を同時に集計\n",
    "      .reset_index()\n",
    ").copy()\n",
    "\n",
    "# 近似Zスコア用の基準値を計算\n",
    "racelevel_df['RL±0'] = racelevel_df['mean'].round(2)\n",
    "racelevel_df['RL+1'] = (racelevel_df['mean'] + racelevel_df['std']).round(2)\n",
    "racelevel_df['RL-1'] = (racelevel_df['mean'] - racelevel_df['std']).round(2)\n",
    "racelevel_df['RL+2'] = (racelevel_df['mean'] + 2 * racelevel_df['std']).round(2)\n",
    "racelevel_df['RL-2'] = (racelevel_df['mean'] - 2 * racelevel_df['std']).round(2)\n",
    "\n",
    "# 必要なカラムだけ残す\n",
    "racelevel_df = racelevel_df[\n",
    "    group_key + ['RL-2','RL-1','RL±0','RL+1','RL+2','mean','std']\n",
    "].copy()\n",
    "\n",
    "# csvファイル保存\n",
    "output_filepath_level = r'D:\\Keiba\\20_IndexData\\Race_Level_Master.csv'\n",
    "racelevel_df.to_csv(output_filepath_level, index=False, encoding='cp932')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レースレベル判定ラベルを追加するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rotte\\AppData\\Local\\Temp\\ipykernel_19984\\3334226599.py:29: DtypeWarning: Columns (22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(master_filepath, encoding='CP932').copy()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 指数追加用成績データファイルのパス\n",
    "master_filepath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "\n",
    "# 参照用基準タイムファイルのパス\n",
    "ref_filepath1 = r'D:\\Keiba\\20_IndexData\\Race_Level_Master.csv'\n",
    "\n",
    "# 派生マスタcsvファイルのパス\n",
    "output_filepath1 = r'D:\\Keiba\\00_ImportData\\200_Race_Level\\Race_Level_Master.csv'\n",
    "\n",
    "# 共通関数：参照側DFのキー以外の列にサフィックスを付ける\n",
    "def prepare_ref_df(df_ref, merge_keys, suffix: str):\n",
    "    \"\"\"\n",
    "    マージ用の参照DFの列名に suffix を付ける（キー列以外すべて）\n",
    "    \"\"\"\n",
    "    df_ref = df_ref.copy()\n",
    "    rename_map = {\n",
    "        c: f\"{c}{suffix}\"\n",
    "        for c in df_ref.columns\n",
    "        if c not in merge_keys\n",
    "    }\n",
    "    return df_ref.rename(columns=rename_map)\n",
    "\n",
    "# ファイルを開く\n",
    "df1 = pd.read_csv(master_filepath, encoding='CP932').copy()\n",
    "df2 = pd.read_csv(ref_filepath1, encoding='CP932').copy()\n",
    "\n",
    "# マージキー\n",
    "group_key = ['場所','芝・ダート','距離','トラックコード(JV)','競走種別','クラス分類']\n",
    "\n",
    "# df2 側にサフィックスを付けてからマージ\n",
    "df2_pre = prepare_ref_df(df2, group_key, '_racelevel')\n",
    "\n",
    "merged_df1 = pd.merge(df1, df2_pre, on=group_key, how='left')\n",
    "\n",
    "merged_df1['RL-2_差分'] = (merged_df1['レースレベル指数'] - merged_df1['RL-2_racelevel']).abs()\n",
    "merged_df1['RL-1_差分'] = (merged_df1['レースレベル指数'] - merged_df1['RL-1_racelevel']).abs()\n",
    "merged_df1['RL±0_差分'] = (merged_df1['レースレベル指数'] - merged_df1['RL±0_racelevel']).abs()\n",
    "merged_df1['RL+1_差分'] = (merged_df1['レースレベル指数'] - merged_df1['RL+1_racelevel']).abs()\n",
    "merged_df1['RL+2_差分'] = (merged_df1['レースレベル指数'] - merged_df1['RL+2_racelevel']).abs()\n",
    "\n",
    "def assign_level_band(row):\n",
    "    value = row['レースレベル指数']\n",
    "\n",
    "    # 欠損は評価不能\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "\n",
    "    diffs = {\n",
    "        'RL-2_差分': row['RL-2_差分'],\n",
    "        'RL-1_差分': row['RL-1_差分'],\n",
    "        'RL±0_差分': row['RL±0_差分'],\n",
    "        'RL+1_差分': row['RL+1_差分'],\n",
    "        'RL+2_差分': row['RL+2_差分'],\n",
    "    }\n",
    "\n",
    "    # 全部 NaN なら判定不能\n",
    "    if all(pd.isna(v) for v in diffs.values()):\n",
    "        return np.nan\n",
    "\n",
    "    # 一番差分が小さいキーを取る\n",
    "    min_key = min(diffs, key=diffs.get)\n",
    "\n",
    "    mapping = {\n",
    "        'RL-2_差分': -2,\n",
    "        'RL-1_差分': -1,\n",
    "        'RL±0_差分':  0,\n",
    "        'RL+1_差分':  1,\n",
    "        'RL+2_差分':  2,\n",
    "    }\n",
    "    return mapping[min_key]\n",
    "\n",
    "# -2 ~ +2 のレースレベル判定\n",
    "merged_df1['レースレベル判定'] = merged_df1.apply(assign_level_band, axis=1)\n",
    "\n",
    "band_to_grade = {\n",
    "    2: 'A',\n",
    "    1: 'B',\n",
    "    0: 'C',\n",
    "    -1: 'D',\n",
    "    -2: 'E'\n",
    "}\n",
    "\n",
    "merged_df1['レースレベル評価'] = merged_df1['レースレベル判定'].map(band_to_grade)\n",
    "\n",
    "# 書き換え用のラベル定義\n",
    "rank_to_label = {'A': '05A', 'B': '07B', 'C': '01C', 'D': '00D', 'E': '03E'}\n",
    "\n",
    "# インポート用のレースレベル列を書き換え\n",
    "merged_df1['レース印３'] = merged_df1['レースレベル評価'].replace(rank_to_label)\n",
    "\n",
    "# サフィックス付き列を削除して保存\n",
    "# 削除するサフィックスを列挙\n",
    "suffixes_to_drop = ('_racelevel', '_差分')\n",
    "\n",
    "# サフィックスで判定して残す列だけ抜き出し\n",
    "clean_df = merged_df1.loc[:, [c for c in merged_df1.columns\n",
    "                              if not any(c.endswith(suf) for suf in suffixes_to_drop)]].copy()\n",
    "\n",
    "# インポート用ファイルの定義（レース単位に変更）\n",
    "import_columns = ['target_raceid', 'レース印３']\n",
    "import_df = clean_df[import_columns].copy()\n",
    "\n",
    "# target_raceid で重複削除（レース単位に1行だけ）\n",
    "import_df = import_df.drop_duplicates(subset='target_raceid', keep='last')\n",
    "\n",
    "# 年度列を追加（target_raceid先頭4桁が年）\n",
    "import_df['year'] = pd.to_datetime(\n",
    "    import_df['target_raceid'].astype(str).str.slice(0, 4),\n",
    "    format='%Y',\n",
    "    errors='coerce'\n",
    ").dt.year\n",
    "\n",
    "# 成績データの更新保存\n",
    "clean_df.to_csv(master_filepath, index=False, encoding='cp932')\n",
    "\n",
    "# インポート用まとめファイルの保存\n",
    "import_df.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "\n",
    "# 年度別にファイル分割\n",
    "for year, df in import_df.groupby('year'):\n",
    "    df.drop(columns='year').to_csv(\n",
    "        rf\"D:\\Keiba\\00_ImportData\\200_Race_Level\\Race_Level_Master_{year}.csv\",\n",
    "        index=False, encoding='cp932'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・基準タイムファイルへ列追加2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "# 参照用成績データファイルのパス\n",
    "master_filipath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "\n",
    "# 更新ファイルのパス\n",
    "output_filepath1 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master1.csv'\n",
    "output_filepath2 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master2.csv'\n",
    "\n",
    "# ファイルを開く\n",
    "df1 = pd.read_csv(master_filipath, encoding='CP932').copy()\n",
    "\n",
    "# --- 集計設定 ---\n",
    "agg_cols1 = {\n",
    "    'レースPCI': 'median',\n",
    "    'PCI3': 'median',\n",
    "    'PCI': 'median',\n",
    "    '通過3F': 'median',\n",
    "    '通過4F': 'median',\n",
    "    '通過5F': 'median',\n",
    "    'レース上り3F': 'median',\n",
    "    'レース上り4F': 'median',\n",
    "    'レース上り5F': 'median',\n",
    "    '中盤ラップ1': 'median',\n",
    "    '中盤ラップ2': 'median',\n",
    "    '33ラップ': 'median',\n",
    "    '最大加速ラップ': 'median',\n",
    "    'ゴール前ラップ差': 'median',\n",
    "    'レースレベル指数': 'median',\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング順位':'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '-3F差': 'median',\n",
    "    'テン指数': 'median',\n",
    "    'テン指数順位': 'median',\n",
    "    '上り指数': 'median',\n",
    "    '上り指数順位': 'median',\n",
    "    'スピード指数': 'median',\n",
    "    'スピード指数順位': 'median',\n",
    "    '総合指数': 'median',\n",
    "    '総合指数順位': 'median',\n",
    "    'レース強度指数': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '1角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "agg_cols2 = {\n",
    "    '生後日数': 'median',\n",
    "    '体重': 'median',\n",
    "    '斤量馬体重比': 'median',\n",
    "    '前走距離': 'median',\n",
    "    '前走距離差': 'median',\n",
    "    'レイティング': 'median',\n",
    "    'レイティング順位':'median',\n",
    "    'マイニング': 'median',\n",
    "    'マイニング順位': 'median',\n",
    "    '対戦型マイニング': 'median',\n",
    "    '対戦型マイニング順位': 'median',\n",
    "    '追切指数': 'median',\n",
    "    '追切指数順位': 'median',\n",
    "    'タイムS': 'median',\n",
    "    '補正走破タイム': 'median',\n",
    "    '-3Fタイム': 'median',\n",
    "    '前半3F': 'median',\n",
    "    '上り3F': 'median',\n",
    "    '上り3F順位': 'median',\n",
    "    'Ave-3F': 'median',\n",
    "    '-3F差': 'median',\n",
    "    'テン指数': 'median',\n",
    "    'テン指数順位': 'median',\n",
    "    '上り指数': 'median',\n",
    "    '上り指数順位': 'median',\n",
    "    'スピード指数': 'median',\n",
    "    'スピード指数順位': 'median',\n",
    "    '総合指数': 'median',\n",
    "    '総合指数順位': 'median',\n",
    "    'レース強度指数': 'median',\n",
    "    '通過1': 'median',\n",
    "    '通過2': 'median',\n",
    "    '通過3': 'median',\n",
    "    '通過4': 'median',\n",
    "    '1角_4角差': 'median',\n",
    "    '4角_入線順位差': 'median',\n",
    "    'サイドポジション平均': 'median'\n",
    "}\n",
    "\n",
    "# --- 基準タイム算出処理1 ---\n",
    "# 1勝クラス・2勝クラスのみ対象\n",
    "base_df1 = df1[df1['クラスコード'].isin([23, 43])].copy()\n",
    "\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops1 = base_df1[base_df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st1 = base_df1[base_df1['入線順位'] == 1].copy()\n",
    "\n",
    "# クラス分類の統一\n",
    "df_tops1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "df_1st1.loc[:, 'クラス分類'] = '1勝・2勝クラス'\n",
    "\n",
    "# グループ化キー\n",
    "group_cols1 = ['場所', '芝・ダート', '距離','トラックコード(JV)', '馬場分類', 'クラス分類']\n",
    "\n",
    "# ---集計対象列（存在するものだけ）---\n",
    "num_cols1 = [c for c in agg_cols1.keys() if c in df_tops1.columns]\n",
    "num_cols1_1st = [c for c in agg_cols2.keys() if c in df_1st1.columns]\n",
    "\n",
    "# ---数値化：変換失敗は NaN に---\n",
    "df_tops1[num_cols1] = df_tops1[num_cols1].apply(pd.to_numeric, errors='coerce')\n",
    "df_1st1[num_cols1_1st] = df_1st1[num_cols1_1st].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# --- 集計処理 ---\n",
    "base_time_tops1 = df_tops1.groupby(group_cols1, dropna=False).agg(agg_cols1).reset_index()\n",
    "base_time_1st1 = df_1st1.groupby(group_cols1, dropna=False).agg(agg_cols2).reset_index()\n",
    "base_time_1st1 = base_time_1st1.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "\n",
    "# --- 結合 ---\n",
    "base_time_df1 = pd.merge(base_time_tops1, base_time_1st1, on=group_cols1, how=\"left\")\n",
    "\n",
    "# --- 距離係数（速度換算） ---\n",
    "base_time_df1['距離係数'] = (1 / base_time_df1['タイムS']) * 100\n",
    "\n",
    "# --- 基準タイム算出処理2 ---\n",
    "# 1着～3着と1着馬のデータ抽出\n",
    "df_tops2 = df1[df1['入線順位'].between(1, 3)].copy()\n",
    "df_1st2 = df1[df1['入線順位'] == 1].copy()\n",
    "\n",
    "# グループ化キー\n",
    "group_cols2 = ['場所', '芝・ダート', '距離','トラックコード(JV)', '競走種別', 'クラス分類', '馬場分類']\n",
    "\n",
    "base_time_tops2 = df_tops2.groupby(group_cols2).agg(agg_cols1).reset_index()\n",
    "base_time_1st2 = df_1st2.groupby(group_cols2).agg(agg_cols2).reset_index()\n",
    "base_time_1st2 = base_time_1st2.rename(columns={col: f\"{col}_1着\" for col in agg_cols2.keys()})\n",
    "base_time_df2 = pd.merge(base_time_tops2, base_time_1st2, on=group_cols2, how=\"left\")\n",
    "\n",
    "# CSV出力(基準タイムファイルの更新)\n",
    "base_time_df1.to_csv(output_filepath1, index=False, encoding='cp932')\n",
    "base_time_df2.to_csv(output_filepath2, index=False, encoding='cp932')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・成績データへ基準タイムファイルとの差分データを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 成績データのファイルパス\n",
    "master_filepath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "\n",
    "# 基準タイムファイルパス\n",
    "ref_filepath1 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master1.csv'\n",
    "ref_filepath2 = r'D:\\Keiba\\20_IndexData\\Base_Time_Master2.csv'\n",
    "\n",
    "\n",
    "# 共通関数：参照DFのキー以外の列に suffix を付ける\n",
    "def prepare_ref_df(df_ref, merge_keys, suffix):\n",
    "    df_ref = df_ref.copy()\n",
    "    rename_map = {\n",
    "        c: f\"{c}{suffix}\"\n",
    "        for c in df_ref.columns\n",
    "        if c not in merge_keys\n",
    "    }\n",
    "    return df_ref.rename(columns=rename_map)\n",
    "\n",
    "# データ読み込み\n",
    "df1 = pd.read_csv(master_filepath, encoding='cp932').copy()\n",
    "df2 = pd.read_csv(ref_filepath1, encoding='cp932').copy()\n",
    "df3 = pd.read_csv(ref_filepath2, encoding='cp932').copy()\n",
    "\n",
    "# マージキー\n",
    "merge_key1 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)', '馬場分類']\n",
    "merge_key2 = ['場所', '芝・ダート', '距離', 'トラックコード(JV)', '競走種別', 'クラス分類', '馬場分類']\n",
    "\n",
    "# suffix をつけて準備\n",
    "df2_pre = prepare_ref_df(df2, merge_key1, '_stdtime1')\n",
    "df3_pre = prepare_ref_df(df3, merge_key2, '_stdtime2')\n",
    "\n",
    "# マージ実行\n",
    "merged_df1 = pd.merge(df1, df2_pre, on=merge_key1, how='left')\n",
    "merged_df1 = pd.merge(merged_df1, df3_pre, on=merge_key2, how='left')\n",
    "\n",
    "# 差分を辞書的に一括生成\n",
    "# 指数系（大きいほど強い → 自分 - 基準）\n",
    "index_like_cols = [\n",
    "    'マイニング', '対戦型マイニング', 'レイティング', '追切指数',\n",
    "    'テン指数', '上り指数', '補正タイム', '補9', 'スピード指数',\n",
    "    '総合指数', 'レース強度指数', 'レースレベル指数'\n",
    "]\n",
    "\n",
    "# タイム系（小さいほど強い → 基準 - 自分）\n",
    "time_like_cols = [\n",
    "    'タイムS', '補正走破タイム', '-3Fタイム',\n",
    "    '前半3F', '上り3F', 'Ave-3F'\n",
    "]\n",
    "\n",
    "# 指数：自分 - 基準\n",
    "for col in index_like_cols:\n",
    "    if f\"{col}_stdtime1\" in merged_df1:\n",
    "        merged_df1[f\"{col}差分1\"] = merged_df1[col] - merged_df1[f\"{col}_stdtime1\"]\n",
    "    if f\"{col}_stdtime2\" in merged_df1:\n",
    "        merged_df1[f\"{col}差分2\"] = merged_df1[col] - merged_df1[f\"{col}_stdtime2\"]\n",
    "\n",
    "# タイム：基準 - 自分\n",
    "for col in time_like_cols:\n",
    "    if f\"{col}_stdtime1\" in merged_df1:\n",
    "        merged_df1[f\"{col}差分1\"] = merged_df1[f\"{col}_stdtime1\"] - merged_df1[col]\n",
    "    if f\"{col}_stdtime2\" in merged_df1:\n",
    "        merged_df1[f\"{col}差分2\"] = merged_df1[f\"{col}_stdtime2\"] - merged_df1[col]\n",
    "\n",
    "# 基準タイム列（_stdtime1/_stdtime2）を削除して clean にする\n",
    "suffixes_to_drop = ('_1着', '_stdtime1', '_stdtime2')\n",
    "\n",
    "clean_df = merged_df1.loc[\n",
    "    :,\n",
    "    [c for c in merged_df1.columns if not any(c.endswith(suf) for suf in suffixes_to_drop)]\n",
    "].copy()\n",
    "\n",
    "# CSV 出力\n",
    "clean_df.to_csv(master_filepath, index=False, encoding='cp932')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ・特徴量を成績データへ追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#読み込みファイルパスの指定\n",
    "result_filepath = r'D:\\Keiba\\10_ExportData\\Race_Result_Master.csv'\n",
    "\n",
    "#ファイルを開く\n",
    "df = pd.read_csv(result_filepath, encoding='cp932').copy()\n",
    "\n",
    "# '日付S'がすでにdatetime型かどうかチェックし、変換が必要な場合のみ変換を実施する\n",
    "if not pd.api.types.is_datetime64_any_dtype(df['日付S']):\n",
    "\n",
    "    # format='%Y/%m/%d' を format='%Y-%m-%d'に変更(またはformat='mixed')\n",
    "    df['日付S'] = pd.to_datetime(df['日付S'].str.replace('.', '/'), format='%Y/%m/%d')\n",
    "\n",
    "# 過去 n 走特徴量の生成\n",
    "sort_keys = ['血統登録番号', '日付S', 'target_raceid', 'target_horseid']\n",
    "df = df.sort_values(sort_keys)\n",
    "\n",
    "metrics = [\n",
    "    'レイティング', 'テン指数', 'スピード指数', 'マイニング', '追切指数',\n",
    "    '総合指数', 'Top3総合指数', 'レース強度指数', 'レースレベル指数',\n",
    "    'PCI', 'ペース補正値', '賞金', '入線順位'\n",
    "]\n",
    "\n",
    "windows = [1, 5, 7]\n",
    "\n",
    "for n in windows:\n",
    "    shifted = df.groupby('血統登録番号')[metrics].shift(1)\n",
    "    rolled = (\n",
    "        shifted\n",
    "        .groupby(df['血統登録番号'])\n",
    "        .rolling(window=n, min_periods=1)\n",
    "        .agg(['mean', 'max', 'min', 'std'])\n",
    "    )\n",
    "    rolled.columns = [f'past{n}_{col}_{stat}' for col, stat in rolled.columns]\n",
    "    df = pd.concat([df, rolled.reset_index(level=0, drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/DataTables/30_IndexFiles/00_StandardTimes1_20241207.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/00_StandardTimes2_20241207.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/00_StandardTimes3_20241207.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/20_RaceLevels_20241207.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# 成績CSVファイルのパスを選択\n",
    "file_path = filedialog.askopenfilename(title=\"成績CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"成績CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# 1. 成績CSVファイルを開く\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# カラム名の辞書\n",
    "column_mappings = {\n",
    "    'Location': \"場所\",\n",
    "    'Turf_Dirt': \"芝・ダート\",\n",
    "    'Distance': \"距離\",\n",
    "    'Race_Type': \"競争種別コード\",\n",
    "    'Class_Code': \"クラスコード\",\n",
    "    'Track_Condition': \"馬場状態\",\n",
    "    'RPCI': \"レースペースチェンジ指数\",\n",
    "    'PCI3': \"上位馬ペースチェンジ指数\",\n",
    "    '33_Lap': \"33ラップ\",\n",
    "    'Middle_Lap1': \"中盤ラップ1\",\n",
    "    'Middle_Lap2': \"中盤ラップ2\",\n",
    "    '1st_Horse_Adjustment': '1着馬補正タイム',\n",
    "    '2nd_Horse_Adjustment': '2着馬補正タイム',\n",
    "    '3rd_Horse_Adjustment': '3着馬補正タイム',\n",
    "    '1st_Horse_Additional9': '1着馬補9',\n",
    "    '2nd_Horse_Additional9': '2着馬補9',\n",
    "    '3rd_Horse_Additional9': '3着馬補9',\n",
    "    '1st_Horse_Speed_Index': '1着馬スピード指数',\n",
    "    '2nd_Horse_Speed_Index': '2着馬スピード指数',\n",
    "    '3rd_Horse_Speed_Index': '3着馬スピード指数',\n",
    "    '1st_Horse_Finish_Time': \"1着馬走破タイム\",\n",
    "    '2nd_Horse_Finish_Time': \"2着馬走破タイム\",\n",
    "    '3rd_Horse_Finish_Time': \"3着馬走破タイム\",\n",
    "    '1st_Horse_PCI': \"1着馬ペースチェンジ指数\",\n",
    "    '2nd_Horse_PCI': \"2着馬ペースチェンジ指数\",\n",
    "    '3rd_Horse_PCI': \"3着馬ペースチェンジ指数\",\n",
    "    '1st_Horse_Average_3F': \"1着馬平均3F\",\n",
    "    '2nd_Horse_Average_3F': \"2着馬平均3F\",\n",
    "    '3rd_Horse_Average_3F': \"3着馬平均3F\",\n",
    "    '1st_Horse_First_3F': \"1着馬前半3F\",\n",
    "    '2nd_Horse_First_3F': \"2着馬前半3F\",\n",
    "    '3rd_Horse_First_3F': \"3着馬前半3F\",\n",
    "    '1st_Horse_Final_3F': \"1着馬上り3F\",\n",
    "    '2nd_Horse_Final_3F': \"2着馬上り3F\",\n",
    "    '3rd_Horse_Final_3F': \"3着馬上り3F\"\n",
    "}\n",
    "\n",
    "# 必要なカラムを抽出\n",
    "selected_columns = list(column_mappings.keys())\n",
    "df_selected = df[selected_columns].copy()\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# クラスコードの分類関数\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 114:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 馬場状態の分類関数\n",
    "def categorize_track_condition(condition):\n",
    "    if condition in ['良', '稍']:\n",
    "        return '良・稍'\n",
    "    elif condition in ['重', '不']:\n",
    "        return '重・不'\n",
    "    else:\n",
    "        return 'その他'\n",
    "\n",
    "# 新しいカテゴリカラムを追加\n",
    "df_selected['Race_Type_Category'] = df_selected['Race_Type'].apply(categorize_race_type)\n",
    "df_selected['Class_Code_Category'] = df_selected['Class_Code'].apply(categorize_class_code)\n",
    "df_selected['Track_Condition_Category'] = df_selected['Track_Condition'].apply(categorize_track_condition)\n",
    "\n",
    "# 1着馬から3着馬の補正タイムの平均を計算する新しいカラムを追加\n",
    "df_selected['Top3_Adjustment'] = df_selected[['1st_Horse_Adjustment', '2nd_Horse_Adjustment', '3rd_Horse_Adjustment']].mean(axis=1)\n",
    "\n",
    "# 1着馬から3着馬の補9の平均を計算する新しいカラムを追加\n",
    "df_selected['Top3_Adjustment9'] = df_selected[['1st_Horse_Additional9', '2nd_Horse_Additional9', '3rd_Horse_Additional9']].mean(axis=1)\n",
    "\n",
    "# 1着馬から3着馬のスピード指数の平均を計算する新しいカラムを追加\n",
    "df_selected['Top3_Speed_Index'] = df_selected[['1st_Horse_Speed_Index', '2nd_Horse_Speed_Index', '3rd_Horse_Speed_Index']].mean(axis=1)\n",
    "\n",
    "# 1着馬から3着馬の走破タイムの平均を計算する新しいカラムを追加\n",
    "df_selected['Top3_Finish_Time'] = df_selected[['1st_Horse_Finish_Time', '2nd_Horse_Finish_Time', '3rd_Horse_Finish_Time']].mean(axis=1)\n",
    "\n",
    "# 1着馬から3着馬の平均3Fを計算する新しいカラムを追加\n",
    "df_selected['Top3_Average_3F'] = df_selected[['1st_Horse_Average_3F', '2nd_Horse_Average_3F', '3rd_Horse_Average_3F']].mean(axis=1)\n",
    "\n",
    "# 1着馬から3着馬の前半3Fの平均を計算する新しいカラムを追加\n",
    "df_selected['Top3_First_3F'] = df_selected[['1st_Horse_First_3F', '2nd_Horse_First_3F', '3rd_Horse_First_3F']].mean(axis=1)\n",
    "\n",
    "# 1着馬から3着馬の後半3Fの平均を計算する新しいカラムを追加\n",
    "df_selected['Top3_Horse_Final_3F'] = df_selected[['1st_Horse_Final_3F', '2nd_Horse_Final_3F', '3rd_Horse_Final_3F']].mean(axis=1)\n",
    "\n",
    "# 各指数の重み付けを指定\n",
    "weights = {\n",
    "    'Top3_Adjustment': 0.2,\n",
    "    'Top3_Adjustment9': 0.4,\n",
    "    'Top3_Speed_Index': 0.4\n",
    "}\n",
    "\n",
    "# 各指数の平均を重み付けで計算\n",
    "df_selected['Unified_Score'] = (\n",
    "    df_selected['Top3_Adjustment'] * weights['Top3_Adjustment'] +\n",
    "    df_selected['Top3_Adjustment9'] * weights['Top3_Adjustment9'] +\n",
    "    df_selected['Top3_Speed_Index'] * weights['Top3_Speed_Index']\n",
    ")\n",
    "\n",
    "# グループ化 - 「場所」、「芝・ダート」、「距離」、「馬場状態」、「競争種別カテゴリ」、「クラスカテゴリ」でグループ化\n",
    "grouped1 = df_selected.groupby(['Location', 'Turf_Dirt', 'Distance', 'Track_Condition', 'Race_Type_Category', 'Class_Code_Category'])\n",
    "\n",
    "# グループ化 - 「場所」、「芝・ダート」、「距離」、「馬場状態カテゴリ」、「競争種別カテゴリ」、「クラスカテゴリ」でグループ化\n",
    "grouped2 = df_selected.groupby(['Location', 'Turf_Dirt', 'Distance', 'Track_Condition_Category', 'Race_Type_Category', 'Class_Code_Category'])\n",
    "\n",
    "# グループ化 - 「芝・ダート」、「距離」、「競争種別カテゴリ」、「クラスカテゴリ」でグループ化\n",
    "grouped3 = df_selected.groupby(['Turf_Dirt', 'Distance', 'Race_Type_Category', 'Class_Code_Category'])\n",
    "\n",
    "# 各グループごとのタイム系カラムの中央値をまとめる\n",
    "def aggregate_group(grouped):\n",
    "    return grouped.agg({\n",
    "        'RPCI': 'median',\n",
    "        '33_Lap': 'median',\n",
    "        'Middle_Lap1': 'median',\n",
    "        'Middle_Lap2': 'median',\n",
    "        '1st_Horse_PCI': 'median',\n",
    "        'PCI3': 'median',\n",
    "        '1st_Horse_Adjustment': 'median',\n",
    "        'Top3_Adjustment': 'median',\n",
    "        '1st_Horse_Additional9': 'median',\n",
    "        'Top3_Adjustment9': 'median',\n",
    "        '1st_Horse_Speed_Index': 'median',\n",
    "        'Top3_Speed_Index': 'median',\n",
    "        '1st_Horse_Finish_Time': 'median',\n",
    "        'Top3_Finish_Time': 'median',\n",
    "        '1st_Horse_Average_3F': 'median',\n",
    "        'Top3_Average_3F': 'median',\n",
    "        '1st_Horse_First_3F': 'median',\n",
    "        'Top3_First_3F': 'median',\n",
    "        '1st_Horse_Final_3F': 'median',\n",
    "        'Top3_Horse_Final_3F': 'median'\n",
    "    }).reset_index()\n",
    "\n",
    "grouped_median1 = aggregate_group(grouped1)\n",
    "grouped_median2 = aggregate_group(grouped2)\n",
    "grouped_median3 = aggregate_group(grouped3)\n",
    "\n",
    "# 基準タイムの中央値を計算する関数\n",
    "def get_median_times(group):\n",
    "    numeric_cols = group.select_dtypes(include='number').columns.tolist()\n",
    "    numeric_cols = [col for col in numeric_cols if col != 'Distance']\n",
    "\n",
    "    class_1 = group[group['Class_Code_Category'] == '1勝クラス']\n",
    "    class_2 = group[group['Class_Code_Category'] == '2勝クラス']\n",
    "\n",
    "    if not class_1.empty and not class_2.empty:\n",
    "        median_1 = class_1[numeric_cols].median()\n",
    "        median_2 = class_2[numeric_cols].median()\n",
    "        return (median_1 + median_2) / 2\n",
    "\n",
    "    return group[numeric_cols].median()\n",
    "\n",
    "# グループ化して基準データを取得\n",
    "standard_times = grouped_median2.groupby(['Location', 'Turf_Dirt', 'Distance', 'Track_Condition_Category']).apply(get_median_times).reset_index()\n",
    "\n",
    "# 基準データに'Distance_Index' カラムを追加\n",
    "standard_times['Distance_Index'] = (1 / standard_times['Top3_Finish_Time']) * 100\n",
    "\n",
    "# 基準レースレベル判定用のデータフレームを作成\n",
    "race_levels = grouped3['Unified_Score'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# スコアに基づく分類基準スコアを計算\n",
    "def calculate_thresholds(row):\n",
    "    mean = row['mean']\n",
    "    std = row['std']\n",
    "    thresholds = {\n",
    "        'A': mean + 2 * std,\n",
    "        'B': mean + 1 * std,\n",
    "        'C': mean,  # 真ん中\n",
    "        'D': mean - 1 * std,\n",
    "        'E': mean - 2 * std\n",
    "    }\n",
    "    return pd.Series(thresholds)\n",
    "\n",
    "thresholds_df = race_levels.apply(calculate_thresholds, axis=1)\n",
    "\n",
    "# 結合して最終的なデータフレームを作成\n",
    "race_levels = pd.concat([race_levels, thresholds_df], axis=1)\n",
    "\n",
    "# カラム名を調整\n",
    "race_levels = race_levels.rename(columns={\n",
    "    'mean': 'Unified_Score',\n",
    "    'A': 'A',\n",
    "    'B': 'B',\n",
    "    'C': 'C',\n",
    "    'D': 'D',\n",
    "    'E': 'E'\n",
    "})\n",
    "\n",
    "# 数値を丸める処理の関数化\n",
    "def round_columns(df, exclude_cols):\n",
    "    columns_to_round = df.select_dtypes(include='number').columns.tolist()\n",
    "    for col in exclude_cols:\n",
    "        if col in columns_to_round:\n",
    "            columns_to_round.remove(col)\n",
    "    df[columns_to_round] = df[columns_to_round].round(2)\n",
    "    \n",
    "# 数値の丸めを適用\n",
    "round_columns(grouped_median1, ['Distance'])\n",
    "round_columns(grouped_median2, ['Distance'])\n",
    "round_columns(standard_times, ['Distance'])\n",
    "round_columns(race_levels, ['Distance'])\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path1 = f'D:/Keiba/DataTables/30_IndexFiles/00_StandardTimes1_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "grouped_median1.to_csv(output_path1, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path1}に保存しました。\")\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path2 = f'D:/Keiba/DataTables/30_IndexFiles/00_StandardTimes2_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "grouped_median2.to_csv(output_path2, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path2}に保存しました。\")\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path3 = f'D:/Keiba/DataTables/30_IndexFiles/00_StandardTimes3_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "standard_times.to_csv(output_path3, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path3}に保存しました。\")\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path4 = f'D:/Keiba/DataTables/30_IndexFiles/20_RaceLevels_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "race_levels.to_csv(output_path4, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path4}に保存しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ペース係数を出力するコード\n",
    "\n",
    "## ・スピード指数の中で用いるペース補正の算出に使うコース別のペース係数ファイルを出力する\n",
    "\n",
    "###　処理の概要\n",
    "1. **csvファイルの読み込み**\n",
    "    - 'pandas'を使って、ある期間の1着馬から1.5秒以内にゴールした馬の成績が記録されたcsvファイルを読み込む。\n",
    "\n",
    "### 2. **データの前処理**\n",
    "\n",
    "#### a. **走破タイムの秒数への変換**\n",
    "- 走破タイム（`分.秒.10分の1秒`形式）を秒数（浮動小数点数）に変換する関数`convert_time_to_seconds`を適用。\n",
    "\n",
    "#### b. **馬場状態の分類**\n",
    "- 馬場状態を「良・稍」「重・不良」「その他」の3つに分類します。\n",
    "\n",
    "#### c. **スローorハイ関数の計算**\n",
    "- 新しいカラム`スローorハイ関数`を追加し、以下の計算式で値を算出する\n",
    "\n",
    "    スローorハイ関数 = 平均3Fタイム - 上り3Fタイム\n",
    "\n",
    "### 3. **データのグループ化**\n",
    "- データを以下の項目でグループ化\n",
    "- 場所\n",
    "- 芝・ダート\n",
    "- 距離\n",
    "- 馬場状態分類\n",
    "\n",
    "### 4. **スローorハイ関数の範囲によるフィルタリング**\n",
    "- `スローorハイ関数`の値を以下の範囲で区切り、範囲ごとにデータをフィルタリング\n",
    "\n",
    "    (-∞, -4.6), (-4.5, -3.6), ..., (3.6, 4.5), (4.6, ∞)\n",
    "\n",
    "- 各範囲ごとにデータフレームを作成し、リストに追加します。\n",
    "\n",
    "\n",
    "### 5. **中央値の算出**\n",
    "- 各グループにおいて、以下のカラムの中央値を計算します：\n",
    "- `走破タイム`\n",
    "- `スローorハイ関数`\n",
    "\n",
    "\n",
    "### 6. **基準タイム（-0.5～0.5の範囲）を基にした補正値の計算**\n",
    "- `スローorハイ関数範囲`が「-0.5～0.5」のデータを抽出し、その走破タイムの中央値を「基準タイム」として保存する。\n",
    "- 基準タイムを使用して、各データの`スローorハイ関数差指数`を計算する。\n",
    "\n",
    "    スローorハイ関数差指数 = 走破タイム - 基準タイム\n",
    "\n",
    "### 7. **ペース補正係数の算出**\n",
    "- 新しいカラム`ペース補正係数`を以下の式で計算して追加する。\n",
    "\n",
    "    ペース補正係数 = スローorハイ関数差指数 / スローorハイ関数\n",
    "    ※ただし、`スローorハイ関数 = 0`の場合は補正係数を0に設定する。\n",
    "\n",
    "### 8. **結果のCSVファイル出力**\n",
    "- 最終的に計算されたデータをCSVファイルとして保存する。\n",
    "- ファイル名には日付が付与される。\n",
    "\n",
    "## 出力\n",
    "- 最終的なデータには以下のカラムが含まれる。\n",
    "- 場所\n",
    "- 芝・ダート\n",
    "- 距離\n",
    "- 馬場状態分類\n",
    "- スローorハイ関数範囲\n",
    "- 走破タイム（中央値）\n",
    "- スローorハイ関数（中央値）\n",
    "- スローorハイ関数差指数\n",
    "- ペース補正係数\n",
    "- 保存先：  ’D:/Keiba/DataTables/40_IndexFiles/10_PacecorrectionTimes1_YYYYMMDD.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/DataTables/30_IndexFiles/10_PacecorrectionTimes1_20241201.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# カラム名の辞書\n",
    "column_mappings = {\n",
    "    '場所': \"場所\",\n",
    "    '芝・ダ': \"芝・ダート\",\n",
    "    '距離': \"距離\",\n",
    "    '馬場状態': \"馬場状態\",\n",
    "    '走破タイム': \"走破タイム\",\n",
    "    'Ave-3F': \"平均3Fタイム\",\n",
    "    '上り3F': \"上り3Fタイム\"\n",
    "}\n",
    "\n",
    "# 1. 成績CSVファイルのパスを選択して読み込み\n",
    "file_path = filedialog.askopenfilename(title=\"ペース補正用成績CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"ペース補正用成績CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "df = pd.read_csv(file_path, low_memory=False, encoding='cp932')\n",
    "\n",
    "# 必要なカラムを抽出\n",
    "selected_columns = list(column_mappings.keys())\n",
    "df_selected = df[selected_columns].copy()\n",
    "\n",
    "# 追加：走破タイムを時間（秒）に変換する関数\n",
    "def convert_time_to_seconds(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return np.nan\n",
    "    parts = time_str.split(\".\")\n",
    "    if len(parts) == 3:\n",
    "        try:\n",
    "            minutes, seconds, tenths = map(int, parts)\n",
    "            total_seconds = minutes * 60 + seconds + tenths * 0.1\n",
    "            return total_seconds\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 2. 走破タイムを秒数に変換\n",
    "df_selected['走破タイム'] = df_selected['走破タイム'].apply(convert_time_to_seconds)\n",
    "\n",
    "# 3. 走破タイムがNaNでないことを確認\n",
    "df_selected = df_selected.dropna(subset=['走破タイム'])\n",
    "\n",
    "# 4. スローorハイ関数用に新しいカラム 'スローorハイ関数' を追加する\n",
    "df_selected['スローorハイ関数'] = df_selected['Ave-3F'] - df_selected['上り3F']\n",
    "\n",
    "# 5. 走破タイムの異常値をIQRを使って除外する（修正箇所）\n",
    "grouped_time = df_selected.groupby(['場所', '芝・ダ', '距離'])\n",
    "\n",
    "def remove_outliers(group):\n",
    "    Q1 = group['走破タイム'].quantile(0.25)\n",
    "    Q3 = group['走破タイム'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # 異常値を除外\n",
    "    return group[(group['走破タイム'] >= lower_bound) & (group['走破タイム'] <= upper_bound)]\n",
    "\n",
    "df_filtered = grouped_time.apply(remove_outliers).reset_index(drop=True)\n",
    "\n",
    "# 6. コース別にグループ化（場所、芝・ダ、距離、馬場状態分類）\n",
    "grouped = df_filtered.groupby(['場所', '芝・ダ', '距離', '馬場状態'])\n",
    "\n",
    "# 7. 各コースごとにスローorハイ関数の範囲でデータをフィルタリング\n",
    "ranges = [\n",
    "    (-np.inf, -4.6),\n",
    "    (-4.5, -3.6),\n",
    "    (-3.5, -2.6),\n",
    "    (-2.5, -1.6),\n",
    "    (-1.5, -0.6),\n",
    "    (-0.5, 0.5),\n",
    "    (0.6, 1.5),\n",
    "    (1.6, 2.5),\n",
    "    (2.6, 3.5),\n",
    "    (3.6, 4.5),\n",
    "    (4.6, np.inf)\n",
    "]\n",
    "\n",
    "# 8. 各グループごとに範囲ごとのデータフレームを作成\n",
    "grouped_dataframes = []\n",
    "\n",
    "for name, group in grouped:\n",
    "    # コースごとのグループ名\n",
    "    location, turf_dirt, distance, track_condition = name\n",
    "\n",
    "    # スローorハイ関数の範囲ごとにデータをフィルタリング\n",
    "    for lower, upper in ranges:\n",
    "        filtered_df = group[(group['スローorハイ関数'] > lower) & (group['スローorハイ関数'] <= upper)].copy()\n",
    "        if not filtered_df.empty:\n",
    "            filtered_df['スローorハイ関数範囲'] = f\"{lower}～{upper}\"\n",
    "            filtered_df['場所'] = location\n",
    "            filtered_df['芝・ダ'] = turf_dirt\n",
    "            filtered_df['距離'] = distance\n",
    "            grouped_dataframes.append(filtered_df)\n",
    "\n",
    "# 9. 全ての範囲ごとのデータをまとめる\n",
    "result_df = pd.concat(grouped_dataframes, ignore_index=True)\n",
    "\n",
    "grouped_medians = result_df.groupby(['場所', '芝・ダ', '距離', 'スローorハイ関数範囲']).agg({\n",
    "    '走破タイム': 'median',\n",
    "    'スローorハイ関数': 'median'\n",
    "}).reset_index()\n",
    "\n",
    "# 10. 各グループごとに基準タイムを計算\n",
    "baseline_medians = {}\n",
    "\n",
    "grouped_by_course = grouped_medians.groupby(['場所', '芝・ダ', '距離'])\n",
    "\n",
    "for group_name, group_df in grouped_by_course:\n",
    "    # 各グループで'-0.5～0.5'の範囲をチェック\n",
    "    baseline_row = group_df[group_df['スローorハイ関数範囲'] == '-0.5～0.5']\n",
    "    if not baseline_row.empty:\n",
    "        # 基準タイムを設定\n",
    "        baseline_median = baseline_row['走破タイム'].iloc[0]\n",
    "    else:\n",
    "        # 例外処理：他の範囲を使用\n",
    "        range_negative = group_df[group_df['スローorハイ関数範囲'] == '-0.6～-1.5']\n",
    "        range_positive = group_df[group_df['スローorハイ関数範囲'] == '0.6～1.5']\n",
    "        if not range_negative.empty and not range_positive.empty:\n",
    "            median_negative = range_negative['走破タイム'].median()\n",
    "            median_positive = range_positive['走破タイム'].median()\n",
    "            baseline_median = (median_negative + median_positive) / 2\n",
    "        elif not range_negative.empty:\n",
    "            baseline_median = range_negative['走破タイム'].median()\n",
    "        elif not range_positive.empty:\n",
    "            baseline_median = range_positive['走破タイム'].median()\n",
    "        else:\n",
    "            # 適切な範囲がない場合は、全データの中央値を基準タイムとする\n",
    "            baseline_median = group_df['走破タイム'].median()\n",
    "    # グループごとの基準タイムを保存\n",
    "    baseline_medians[group_name] = baseline_median\n",
    "\n",
    "# 11. 各行に対して基準タイムを使って補正差を計算\n",
    "def calculate_difference(row):\n",
    "    key = (row['場所'], row['芝・ダ'], row['距離'])\n",
    "    baseline_time = baseline_medians.get(key, None)\n",
    "    if baseline_time is not None:\n",
    "        return row['走破タイム'] - baseline_time\n",
    "    else:\n",
    "        return 0  # 基準タイムがない場合は0を返す\n",
    "\n",
    "grouped_medians['スローorハイ関数差指数'] = grouped_medians.apply(calculate_difference, axis=1)\n",
    "\n",
    "# 12. ペース補正係数のカラムを追加する\n",
    "def calculate_pace_adjustment_coefficient(row):\n",
    "    pace_function = row['スローorハイ関数']\n",
    "    difference_index = row['スローorハイ関数差指数']\n",
    "    if pace_function != 0:\n",
    "        coefficient = round(difference_index / pace_function, 2)\n",
    "        # ペース補正係数の絶対値が10を超える場合、上限値を設定\n",
    "        if abs(coefficient) > 10:\n",
    "            return 10 * (coefficient / abs(coefficient))  # 符号を維持\n",
    "        else:\n",
    "            return coefficient\n",
    "    else:\n",
    "        return 0  # 分母がゼロの場合は0を返す\n",
    "\n",
    "grouped_medians['ペース補正係数'] = grouped_medians.apply(calculate_pace_adjustment_coefficient, axis=1)\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path = f'D:/Keiba/DataTables/30_IndexFiles/10_PacecorrectionTimes1_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "grouped_medians.to_csv(output_path, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path}に保存しました。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基準33ラップを出力するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/DataTables/30_IndexFiles/30_Standard33Laps_20241207.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# 成績CSVファイルのパスを選択\n",
    "file_path = filedialog.askopenfilename(title=\"成績CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"成績CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# 1. 成績CSVファイルを開く\n",
    "df = pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Target出力ファイルに競争種別とクラスコードの分類カラムを追加\n",
    "df['Race_Type_Category'] = df['Race_Type'].apply(categorize_race_type)\n",
    "\n",
    "# 必要なカラムの抽出\n",
    "df = df[['Location','Turf_Dirt','Distance','Turf_Inside_Outside','33_Lap','Race_Type_Category']]\n",
    "\n",
    "# 33_Lapの欠損値を除外\n",
    "df = df.dropna(subset=['33_Lap'])\n",
    "\n",
    "# グループ化\n",
    "grouped = df.groupby(['Location', 'Turf_Dirt', 'Distance', 'Turf_Inside_Outside','Race_Type_Category'])\n",
    "\n",
    "# 各グループの統計量を計算\n",
    "grouped_stats = grouped['33_Lap'].agg(['mean', 'median', 'std']).reset_index()\n",
    "\n",
    "# Zスコアに対応する値を計算\n",
    "grouped_stats['33_Lap'] = round(grouped_stats['mean'],2)  # 平均値\n",
    "\n",
    "# Zスコア +1, -1, +2, -2 に対応する値を計算\n",
    "grouped_stats['33_Lap+1'] = round(grouped_stats['mean'] + grouped_stats['std'],2)\n",
    "grouped_stats['33_Lap-1'] = round(grouped_stats['mean'] - grouped_stats['std'],2)\n",
    "grouped_stats['33_Lap+2'] = round(grouped_stats['mean'] + 2 * grouped_stats['std'],2)\n",
    "grouped_stats['33_Lap-2'] = round(grouped_stats['mean'] - 2 * grouped_stats['std'],2)\n",
    "\n",
    "# 必要なカラムのみを選択\n",
    "result_df = grouped_stats[['Location', 'Turf_Dirt', 'Distance','Turf_Inside_Outside','Race_Type_Category', '33_Lap-2','33_Lap-1','33_Lap', '33_Lap+1', '33_Lap+2', ]]\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path = f'D:/Keiba/DataTables/30_IndexFiles/30_Standard33Laps_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "result_df.to_csv(output_path, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path}に保存しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 直近追切偏差値ファイルを出力するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/DataTables/30_IndexFiles/40_Recent_Standard_Traningdata_20241214.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/40_Recent_Top20_Traningdata_20241214.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/40_Recent_Top10_Traningdata_20241214.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# Wコース追切CSVファイルのパスを選択\n",
    "file_path1 = filedialog.askopenfilename(title=\"Wコース追切CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path1:\n",
    "    print(\"Wコース追切CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# 1. Wコース追切CSVファイルを開く\n",
    "w_traning_df = pd.read_csv(file_path1, low_memory=False, encoding='cp932')\n",
    "\n",
    "# 必要なカラムの抽出\n",
    "w_traning_df = w_traning_df[['場所', '7F', '6F', '5F', '4F', '3F', '2F', '1F']]\n",
    "\n",
    "# カラムのリネームを行う\n",
    "w_traning_df = w_traning_df.rename(columns={'場所': 'コース'})\n",
    "\n",
    "# ラベル書き換え用のマッピング辞書\n",
    "course_mapping1 = {\n",
    "    '美浦': '美Ｗ',\n",
    "    '栗東': 'ＣＷ'\n",
    "}\n",
    "\n",
    "# mapを用いてコース情報に書き換え\n",
    "w_traning_df['コース'] = w_traning_df['コース'].map(course_mapping1)\n",
    "\n",
    "# 坂路コース追切CSVファイルのパスを選択\n",
    "file_path2 = filedialog.askopenfilename(title=\"坂路コース追切CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path2:\n",
    "    print(\"坂路コース追切CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# 2. 坂路コース追切CSVファイルを開く\n",
    "h_traning_df = pd.read_csv(file_path2, low_memory=False, encoding='cp932')\n",
    "\n",
    "# 必要なカラムの抽出\n",
    "h_traning_df = h_traning_df[['場所', 'Time1', 'Time2', 'Time3', 'Time4']]\n",
    "\n",
    "# カラムのリネームを行う（Wコース形式に合わせる）\n",
    "h_traning_df = h_traning_df.rename(columns={\n",
    "    '場所': 'コース',\n",
    "    'Time1': '4F',\n",
    "    'Time2': '3F',\n",
    "    'Time3': '2F',\n",
    "    'Time4': '1F'\n",
    "})\n",
    "\n",
    "# Wコースにないカラムを補完\n",
    "h_traning_df['7F'] = np.nan\n",
    "h_traning_df['6F'] = np.nan\n",
    "h_traning_df['5F'] = np.nan\n",
    "\n",
    "# ラベル書き換え用のマッピング辞書\n",
    "course_mapping2 = {\n",
    "    '美浦': '美坂',\n",
    "    '栗東': '栗坂'\n",
    "}\n",
    "\n",
    "# mapを用いてコース情報に書き換え\n",
    "h_traning_df['コース'] = h_traning_df['コース'].map(course_mapping2)\n",
    "\n",
    "# データフレームを縦に結合\n",
    "combined_df = pd.concat([w_traning_df, h_traning_df], ignore_index=True)\n",
    "\n",
    "# '坂' を含まないコースを抽出\n",
    "round_course_mask = ~combined_df['コース'].str.contains('坂', na=False)\n",
    "\n",
    "# 一時的に元の列を保存\n",
    "temp_7F = combined_df.loc[round_course_mask, '7F']\n",
    "temp_6F = combined_df.loc[round_course_mask, '6F']\n",
    "temp_5F = combined_df.loc[round_course_mask, '5F']\n",
    "temp_4F = combined_df.loc[round_course_mask, '4F']\n",
    "temp_3F = combined_df.loc[round_course_mask, '3F']\n",
    "\n",
    "# 周回コースに対して7F目～3F目を右に1列ずらす\n",
    "combined_df.loc[round_course_mask, '6F'] = temp_7F\n",
    "combined_df.loc[round_course_mask, '5F'] = temp_6F\n",
    "combined_df.loc[round_course_mask, '4F'] = temp_5F\n",
    "combined_df.loc[round_course_mask, '3F'] = temp_4F\n",
    "combined_df.loc[round_course_mask, '2F'] = temp_3F\n",
    "\n",
    "# 7F目は常に NaN に設定\n",
    "combined_df.loc[round_course_mask, '7F'] = np.nan\n",
    "\n",
    "# 7F目は常に NaN に設定\n",
    "combined_df.loc[round_course_mask, '7F'] = np.nan\n",
    "\n",
    "# タイム関連のカラム\n",
    "time_columns = ['7F', '6F', '5F', '4F', '3F', '2F', '1F']\n",
    "\n",
    "# コース別にタイム関連カラムの中央値を計算\n",
    "course_median = combined_df.groupby(['コース'])[time_columns].median().reset_index()\n",
    "\n",
    "# コース別にタイム関連カラムの標準偏差を計算\n",
    "course_std = round(combined_df.groupby(['コース'])[time_columns].std().reset_index(), 2)\n",
    "\n",
    "# 標準偏差のカラム名を変更\n",
    "course_std.rename(columns={col: f'標準偏差_{col}' for col in time_columns}, inplace=True)\n",
    "\n",
    "# 中央値データフレームに標準偏差を結合\n",
    "course_median = pd.merge(course_median, course_std, on='コース', how='left')\n",
    "\n",
    "# 上位20%のデータ平均を計算する関数\n",
    "def calculate_top20times_mean(group):\n",
    "    # 各列の分位点を計算\n",
    "    top20_threshold = group[time_columns].quantile(0.2)\n",
    "\n",
    "    # 上位20%のデータをフィルタリング\n",
    "    top20_data = group[time_columns][group[time_columns] <= top20_threshold]\n",
    "\n",
    "    # 平均値を計算\n",
    "    return top20_data.mean()\n",
    "\n",
    "# 上位10%のデータ平均を計算する関数\n",
    "def calculate_top10times_mean(group):\n",
    "\n",
    "    # 各列の分位点を計算\n",
    "    top10_threshold = group[time_columns].quantile(0.1)\n",
    "\n",
    "    # 上位10%のデータをフィルタリング\n",
    "    top10_data = group[time_columns][group[time_columns] <= top10_threshold]\n",
    "\n",
    "    # 平均値を計算\n",
    "    return top10_data.mean()\n",
    "\n",
    "# グループごとに計算\n",
    "course_top20_mean = round(combined_df.groupby(['コース']).apply(calculate_top20times_mean), 1).reset_index()\n",
    "course_top10_mean = round(combined_df.groupby(['コース']).apply(calculate_top10times_mean), 1).reset_index()\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path1 = f'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Standard_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "course_median.to_csv(output_path1, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path1}に保存しました。\")\n",
    "\n",
    "output_path2 = f'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Top20_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "course_top20_mean.to_csv(output_path2, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path2}に保存しました。\")\n",
    "\n",
    "output_path3 = f'D:/Keiba/DataTables/30_IndexFiles/40_Recent_Top10_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "course_top10_mean.to_csv(output_path3, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path3}に保存しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 過去追切偏差値ファイルを出力するコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/DataTables/30_IndexFiles/41_course_median_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/41_course_top20_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/41_course_top10_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/42_race_median_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/42_race_top20_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/42_race_top10_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/43_class_median_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/43_class_top20_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/43_class_top10_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/44_trainer_median_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/44_trainer_top20_Traningdata_20241212.csvに保存しました。\n",
      "結果をD:/Keiba/DataTables/30_IndexFiles/44_trainer_top10_Traningdata_20241212.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# 追切CSVファイルのパスを選択\n",
    "file_path = filedialog.askopenfilename(title=\"追切CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"追切CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "# 追切CSVファイルを開く\n",
    "traning_df = pd.read_csv(file_path, low_memory=False,encoding='cp932')\n",
    "\n",
    "traning_df = traning_df.copy()\n",
    "\n",
    "# 予想コメントのカラムを「|」で分割\n",
    "split_columns = traning_df['予想コメント'].str.split('|', expand=True)\n",
    "traning_df['日付'] = split_columns[0]\n",
    "traning_df['コース'] = split_columns[1]\n",
    "traning_df['馬場状態'] = split_columns[2]\n",
    "traning_df['騎乗者'] = split_columns[3]\n",
    "traning_df['タイム'] = split_columns[4]\n",
    "traning_df['周回位置'] = split_columns[5]\n",
    "traning_df['脚色'] = split_columns[6]\n",
    "\n",
    "replace_map = {\n",
    "    '南Ｗ': '美Ｗ',\n",
    "    '南Ｄ': '美ダ',\n",
    "    '南ダ': '美ダ',\n",
    "    '南芝': '美芝'\n",
    "}\n",
    "traning_df['コース'] = traning_df['コース'].replace(replace_map)\n",
    "\n",
    "# 7Fから1Fのカラムを np.nan で初期化\n",
    "distance_columns = ['7F', '6F', '5F', '4F', '3F', '2F', '1F']\n",
    "for col in distance_columns:\n",
    "    traning_df[col] = np.nan  # 初期化\n",
    "\n",
    "# 補正タイム用のカラムを追加\n",
    "for col in distance_columns:\n",
    "    traning_df[f'補正_{col}'] = np.nan  # 初期化\n",
    "\n",
    "# 空文字列を NaN に変換\n",
    "traning_df.replace(\"\", pd.NA, inplace=True)\n",
    "\n",
    "# 'コース', '馬場状態', '騎乗者' 列に欠損値がある行を削除（追切データが存在しないレコードを削除）\n",
    "traning_df = traning_df.dropna(subset=['コース', '馬場状態', '騎乗者'])\n",
    "\n",
    "# 各行のタイム情報を適切カラムに配置する処理\n",
    "for index, row in traning_df.iterrows():\n",
    "    times = row['タイム']\n",
    "    if pd.isna(times):\n",
    "        continue\n",
    "\n",
    "    # タイムリストを取得\n",
    "    time_list = times.split('-')\n",
    "    time_length = len(time_list)\n",
    "\n",
    "    # タイムを後ろから順に適切なカラムに配置\n",
    "    for i in range(time_length):\n",
    "        # 数値に変換できるかチェック\n",
    "        try:\n",
    "            traning_df.at[index, distance_columns[-(time_length - i)]] = float(time_list[i])\n",
    "        except ValueError:\n",
    "            # 数値に変換できない場合は NaN を代入\n",
    "            traning_df.at[index, distance_columns[-(time_length - i)]] = np.nan\n",
    "\n",
    "# 周り位置を数値型に変換\n",
    "traning_df['周回位置'] = pd.to_numeric(traning_df['周回位置'], errors='coerce')\n",
    "\n",
    "# タイム補正処理\n",
    "for index, row in traning_df.iterrows():\n",
    "    if not pd.isna(row['周回位置']):\n",
    "        # 補正値を計算\n",
    "        correction_value = (9 - row['周回位置']) * 0.1\n",
    "\n",
    "        # 最も左に存在するタイムを探す\n",
    "        valid_times = [col for col in distance_columns if not pd.isna(row[col])]\n",
    "        if valid_times:\n",
    "            leftmost_col = valid_times[0]\n",
    "            leftmost_index = distance_columns.index(leftmost_col)\n",
    "\n",
    "            # 全体時計に補正値を加算\n",
    "            traning_df.at[index, f'補正_{leftmost_col}'] = round(row[leftmost_col] + correction_value, 1)\n",
    "\n",
    "            # 残り区間タイムに均等割り振り\n",
    "            remaining_cols = distance_columns[leftmost_index + 1:]\n",
    "            if remaining_cols:\n",
    "                equal_correction = correction_value / len(remaining_cols)\n",
    "                for col in remaining_cols:\n",
    "                    if not pd.isna(row[col]):\n",
    "                        traning_df.at[index, f'補正_{col}'] = round(row[col] + equal_correction, 1)\n",
    "        else:\n",
    "            # 周回位置があるがタイムが存在しない場合（通常は発生しない想定）\n",
    "            continue\n",
    "    else:\n",
    "        # 周り位置がない場合、元のタイムを補正タイムに転記\n",
    "        for col in distance_columns:\n",
    "            if not pd.isna(row[col]):\n",
    "                traning_df.at[index, f'補正_{col}'] = row[col]\n",
    "\n",
    "# 出力に必要なカラムを選択\n",
    "format_df = traning_df[['レースID(新)', '場所', '芝・ダ', '距離', '芝(内・外)','競走種別', 'クラスコード', '入線順位',\n",
    "                '調教師','調教師コード','コース', '馬場状態', '騎乗者','補正_7F', '補正_6F', '補正_5F', '補正_4F', '補正_3F', '補正_2F', '補正_1F' ,\n",
    "                '周回位置', '脚色']].copy()\n",
    "\n",
    "# '入線順位'が 0 の行を削除（競争中止した馬を除外）\n",
    "format_df = format_df[format_df['入線順位'] != 0]\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# クラスコードの分類関数\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 114:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 競争種別とクラスコードを書き換え\n",
    "format_df['競走種別'] = format_df['競走種別'].apply(categorize_race_type)\n",
    "format_df['クラスコード'] = format_df['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "top3_data = format_df[format_df['入線順位'] <= 3].copy()\n",
    "\n",
    "# タイム関連のカラム\n",
    "time_columns = ['補正_7F', '補正_6F', '補正_5F', '補正_4F', '補正_3F', '補正_2F', '補正_1F']\n",
    "\n",
    "# タイム列を数値型に変換（必要に応じてNaNを処理）\n",
    "top3_data[time_columns] = top3_data[time_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# グループ化して各列の中央値を計算\n",
    "course_median = round(top3_data.groupby(['コース','馬場状態'])[time_columns].median(),1).reset_index()\n",
    "race_median = round(top3_data.groupby(['芝・ダ','距離','芝(内・外)','コース','馬場状態'])[time_columns].median(),1).reset_index()\n",
    "class_median = round(top3_data.groupby(['競走種別','クラスコード','コース','馬場状態'])[time_columns].median(),1).reset_index()\n",
    "trainer_median = round(top3_data.groupby(['調教師','調教師コード','コース','馬場状態'])[time_columns].median(),1).reset_index()\n",
    "\n",
    "# タイム関連カラムの標準偏差を計算\n",
    "course_std = round(top3_data.groupby(['コース','馬場状態'])[time_columns].std().reset_index(),2)\n",
    "race_std = round(top3_data.groupby(['芝・ダ','距離','芝(内・外)','コース','馬場状態'])[time_columns].std().reset_index(),2)\n",
    "class_std = round(top3_data.groupby(['競走種別','クラスコード','コース','馬場状態'])[time_columns].std().reset_index(),2)\n",
    "trainer_std = round(top3_data.groupby(['調教師','調教師コード','コース','馬場状態'])[time_columns].std().reset_index(),2)\n",
    "\n",
    "# 標準偏差のカラム名を変更\n",
    "course_std.rename(columns={col: f'標準偏差_{col}' for col in time_columns}, inplace=True)\n",
    "race_std.rename(columns={col: f'標準偏差_{col}' for col in time_columns}, inplace=True)\n",
    "class_std.rename(columns={col: f'標準偏差_{col}' for col in time_columns}, inplace=True)\n",
    "trainer_std.rename(columns={col: f'標準偏差_{col}' for col in time_columns}, inplace=True)\n",
    "\n",
    "# 中央値データフレームに標準偏差を結合\n",
    "course_median = pd.merge(course_median, course_std, on=['コース','馬場状態'], how='left')\n",
    "race_median = pd.merge(race_median, race_std, on=['芝・ダ','距離','芝(内・外)','コース','馬場状態'], how='left')\n",
    "class_median = pd.merge(class_median, class_std, on=['競走種別','クラスコード','コース','馬場状態'], how='left')\n",
    "trainer_median = pd.merge(trainer_median, trainer_std, on=['調教師','調教師コード','コース','馬場状態'], how='left')\n",
    "\n",
    "# 上位20%のデータ平均を計算する関数\n",
    "def calculate_top20times_mean(group):\n",
    "    # 各列の分位点を計算\n",
    "    top20_threshold = group[time_columns].quantile(0.2)\n",
    "\n",
    "    # 上位20%のデータをフィルタリング\n",
    "    top20_data = group[time_columns][group[time_columns] <= top20_threshold]\n",
    "\n",
    "    # 平均値を計算\n",
    "    return top20_data.mean()\n",
    "\n",
    "# 上位10%のデータ平均を計算する関数\n",
    "def calculate_top10times_mean(group):\n",
    "\n",
    "    # 各列の分位点を計算\n",
    "    top10_threshold = group[time_columns].quantile(0.1)\n",
    "\n",
    "    # 上位10%のデータをフィルタリング\n",
    "    top10_data = group[time_columns][group[time_columns] <= top10_threshold]\n",
    "\n",
    "    # 平均値を計算\n",
    "    return top10_data.mean()\n",
    "\n",
    "# グループごとに計算\n",
    "course_top20_mean = round(top3_data.groupby(['コース', '馬場状態']).apply(calculate_top20times_mean),1).reset_index()\n",
    "course_top10_mean = round(top3_data.groupby(['コース', '馬場状態']).apply(calculate_top10times_mean),1).reset_index()\n",
    "\n",
    "race_top20_mean = round(top3_data.groupby(['芝・ダ', '距離','芝(内・外)', 'コース', '馬場状態']).apply(calculate_top20times_mean),1).reset_index()\n",
    "race_top10_mean = round(top3_data.groupby(['芝・ダ', '距離','芝(内・外)', 'コース', '馬場状態']).apply(calculate_top10times_mean),1).reset_index()\n",
    "\n",
    "class_top20_mean = round(top3_data.groupby(['競走種別', 'クラスコード', 'コース', '馬場状態']).apply(calculate_top20times_mean),1).reset_index()\n",
    "class_top10_mean = round(top3_data.groupby(['競走種別', 'クラスコード', 'コース', '馬場状態']).apply(calculate_top10times_mean),1).reset_index()\n",
    "\n",
    "trainer_top20_mean = round(top3_data.groupby(['調教師','調教師コード', 'コース', '馬場状態']).apply(calculate_top20times_mean),1).reset_index()\n",
    "trainer_top10_mean = round(top3_data.groupby(['調教師','調教師コード', 'コース', '馬場状態']).apply(calculate_top10times_mean),1).reset_index()\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path1 = f'D:/Keiba/DataTables/30_IndexFiles/41_course_median_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "course_median.to_csv(output_path1, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path1}に保存しました。\")\n",
    "\n",
    "output_path2 = f'D:/Keiba/DataTables/30_IndexFiles/41_course_top20_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "course_top20_mean.to_csv(output_path2, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path2}に保存しました。\")\n",
    "\n",
    "output_path3 = f'D:/Keiba/DataTables/30_IndexFiles/41_course_top10_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "course_top10_mean.to_csv(output_path3, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path3}に保存しました。\")\n",
    "\n",
    "output_path4 = f'D:/Keiba/DataTables/30_IndexFiles/42_race_median_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "race_median.to_csv(output_path4, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path4}に保存しました。\")\n",
    "\n",
    "output_path5 = f'D:/Keiba/DataTables/30_IndexFiles/42_race_top20_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "race_top20_mean.to_csv(output_path5, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path5}に保存しました。\")\n",
    "\n",
    "output_path6 = f'D:/Keiba/DataTables/30_IndexFiles/42_race_top10_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "race_top10_mean.to_csv(output_path6, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path6}に保存しました。\")\n",
    "\n",
    "output_path7 = f'D:/Keiba/DataTables/30_IndexFiles/43_class_median_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "class_median.to_csv(output_path7, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path7}に保存しました。\")\n",
    "\n",
    "output_path8 = f'D:/Keiba/DataTables/30_IndexFiles/43_class_top20_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "class_top20_mean.to_csv(output_path8, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path8}に保存しました。\")\n",
    "\n",
    "output_path9 = f'D:/Keiba/DataTables/30_IndexFiles/43_class_top10_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "class_top10_mean.to_csv(output_path9, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path9}に保存しました。\")\n",
    "\n",
    "output_path10 = f'D:/Keiba/DataTables/30_IndexFiles/44_trainer_median_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "trainer_median.to_csv(output_path10, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path10}に保存しました。\")\n",
    "\n",
    "output_path11 = f'D:/Keiba/DataTables/30_IndexFiles/44_trainer_top20_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "trainer_top20_mean.to_csv(output_path11, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path11}に保存しました。\")\n",
    "\n",
    "output_path12 = f'D:/Keiba/DataTables/30_IndexFiles/44_trainer_top10_Traningdata_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "trainer_top10_mean.to_csv(output_path12, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path12}に保存しました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スピード指数を出力するコード\n",
    "\n",
    "## 概要\n",
    "スピード指数を算出するためのコードを記録します。このスピード指数は競馬のレースごとに馬の成績を評価するための指標で、ペース補正、斤量補正、馬場指数、クラス補正など、複数の要素を組み合わせて算出します。\n",
    "\n",
    "### 処理の概要\n",
    "\n",
    "1. **CSVファイルの読み込み**\n",
    "    - `pandas`を使って成績データのCSVファイルを読み込みます。このデータはレースごとの馬の成績や走破タイムなどが含まれています。\n",
    "\n",
    "2. **データの前処理**\n",
    "\n",
    "    a. **出走取り消し・競争除外の馬を除外**\n",
    "    - 成績データから「外」「止」「消」の馬を除外します。\n",
    "\n",
    "    b. **走破タイムの秒数への変換**\n",
    "    - 走破タイム（`分.秒.10分の1秒`形式）を秒数（浮動小数点数）に変換する関数`convert_time_to_seconds`を使い、`走破タイム_秒`という新しいカラムに変換後の値を追加します。\n",
    "\n",
    "    c. **コーナーロスの計算**\n",
    "    - 各馬のコーナーでのロス距離を考慮した走破タイムの補正を行います。`calculate_corner_loss`関数を用いて、`コーナーロス`という新しいカラムにロス時間を計算して追加します。\n",
    "    - 調整後の走破タイムは`調整走破タイム`というカラムに記録されます。\n",
    "\n",
    "3. **クラスと競争種別の分類**\n",
    "    - 各レースにおける競争種別コードとクラスコードをもとに分類し、新たに`Race_Type_Category`と`Class_Code_Category`カラムを追加します。\n",
    "\n",
    "4. **基準タイムデータとのマージ**\n",
    "    - コースごとの基準タイムデータ（StandardTimes2）およびクラス別基準タイムデータ（StandardTimes3）を読み込み、対象の成績データとマージします。\n",
    "    - マージする際に、カラム名の整合性を取るためにリネーム処理を行います。\n",
    "\n",
    "5. **スローorハイ関数の計算**\n",
    "    - 新しいカラム`スローorハイ関数`を計算し、`Ave-3F`と`上り3F`の差を計算します。その結果を基に`スローorハイ関数範囲`を設定します。\n",
    "    - `スローorハイ関数範囲`はペース補正ファイルと統一するために、あらかじめ定義した範囲で値を設定します。\n",
    "\n",
    "6. **ペース補正ファイルとのマージ**\n",
    "    - ペース補正ファイル（PacecorrectionTimes1）を読み込み、ペース補正係数を対象の成績データに結合します。\n",
    "\n",
    "7. **各補正値の計算**\n",
    "\n",
    "    a. **タイム補正値の計算**\n",
    "    - `Top3_Finish_Time_standard`と`調整走破タイム`を基に、距離補正を考慮してタイム補正値を計算し、`タイム補正値`カラムに保存します。\n",
    "\n",
    "    b. **平均3Fタイム補正値の計算**\n",
    "    - `Top3_Average_3F`がNaNの場合、0に置き換えた上で、`Ave-3F`との差分を計算し、`Ave-3F補正値`として保存します。\n",
    "\n",
    "    c. **斤量補正値の計算**\n",
    "    - 斤量と基準斤量を用いて斤量補正を計算し、`斤量補正値`として保存します。\n",
    "\n",
    "    d. **クラス補正値の計算**\n",
    "    - `Top3_Finish_Time_standard`と`Top3_Finish_Time_class`の差を計算してクラス補正値を求めます。クラス補正値は範囲を-2から+2に収めるため、`np.clip`を使用して値を制限します。\n",
    "\n",
    "    e. **ペース補正値の計算**\n",
    "    - `スローorハイ関数`と`ペース補正係数`を乗算して、`ペース補正値`として保存します。`ペース補正係数`がNaNの場合は0に置き換えます。\n",
    "\n",
    "8. **スピード指数の計算**\n",
    "    - 各補正値を組み合わせて、最終的なスピード指数を算出します。\n",
    "    - 計算式は以下の通りです：\n",
    "    \n",
    "      ```\n",
    "      スピード指数 = タイム補正値 + Ave-3F補正値 + 馬場指数 + 斤量補正値 + クラス補正値 + ペース補正値 + 70\n",
    "      ```\n",
    "    - 計算後、`スピード指数`カラムに保存します。\n",
    "\n",
    "9. **結果の保存**\n",
    "    - 最終的に計算された`スピード指数`を含むデータを新たなCSVファイルとして保存します。\n",
    "    - ファイル名には日付が付与され、指定のディレクトリに保存されます。\n",
    "\n",
    "### 出力\n",
    "- 出力ファイルには以下のカラムが含まれます。\n",
    "  - レースID(新)\n",
    "  - スピード指数\n",
    "- 保存先：`D:/Keiba/Importdata/40_Speed_Score/SpeedScore_YYYYMMDD.csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結果をD:/Keiba/Importdata/40_Speed_Score/SpeedScore_20241201.csvに保存しました。\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, filedialog\n",
    "from IPython.display import display\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# ファイル選択ダイアログを表示するための設定\n",
    "root = Tk()\n",
    "root.withdraw()  # メインウィンドウを非表示にする\n",
    "\n",
    "# スピード指数用成績CSVファイルのパスを選択して読み込み\n",
    "file_path = filedialog.askopenfilename(title=\"スピード指数用成績CSVファイルを選択してください\", filetypes=[(\"CSV Files\", \"*.csv\")])\n",
    "if not file_path:\n",
    "    print(\"スピード指数用成績CSVファイルが選択されなかったため、処理を終了します。\")\n",
    "    exit()\n",
    "\n",
    "df = pd.read_csv(file_path, low_memory=False, encoding='cp932')\n",
    "\n",
    "# 出走取り消しや競争除外（外、止、消）になった馬を除外\n",
    "df = df[~df['着順'].isin(['外', '止', '消'])]\n",
    "\n",
    "# 走破タイムを時間（秒）に変換する関数\n",
    "def convert_time_to_seconds(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return np.nan\n",
    "    # ドットで分割する (例: \"1.54.5\" → [\"1\", \"54\", \"5\"])\n",
    "    parts = time_str.split(\".\")\n",
    "    if len(parts) == 3:\n",
    "        try:\n",
    "            minutes, seconds, tenths = map(int, parts)\n",
    "            total_seconds = minutes * 60 + seconds + tenths * 0.1\n",
    "            return total_seconds\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# 走破タイムを秒に変換\n",
    "df['走破タイム_秒'] = df['走破タイム'].apply(convert_time_to_seconds)\n",
    "\n",
    "# コーナーロスを計算する関数\n",
    "def calculate_corner_loss(row):\n",
    "    corner_positions = [\n",
    "        row.get('馬印4', 1) - 1,\n",
    "        row.get('馬印5', 1) - 1,\n",
    "        row.get('馬印6', 1) - 1,\n",
    "        row.get('馬印7', 1) - 1\n",
    "    ]\n",
    "    total_distance_loss = sum(corner_positions) * 1.5  # 総距離ロス（m）\n",
    "    finish_time_seconds = row['走破タイム_秒']\n",
    "    distance_m = row['距離']\n",
    "\n",
    "    if pd.isna(finish_time_seconds) or pd.isna(distance_m) or finish_time_seconds == 0:\n",
    "        return np.nan\n",
    "\n",
    "    avg_speed = distance_m / finish_time_seconds if finish_time_seconds > 0 else np.nan\n",
    "    corner_loss = total_distance_loss / avg_speed if avg_speed > 0 else 0\n",
    "    return round(corner_loss, 2)\n",
    "\n",
    "# 馬印4～7を数値に変換し、不正な値を1に設定\n",
    "for corner_col in ['馬印4', '馬印5', '馬印6', '馬印7']:\n",
    "    df[corner_col] = pd.to_numeric(df[corner_col], errors='coerce').fillna(1).astype(int)\n",
    "\n",
    "# コーナーロスを計算して新しいカラムに追加\n",
    "df['コーナーロス'] = df.apply(calculate_corner_loss, axis=1)\n",
    "\n",
    "# 調整走破タイムの計算\n",
    "df['調整走破タイム'] = df['走破タイム_秒'] - df['コーナーロス']\n",
    "\n",
    "# 馬場指数の計算\n",
    "df['馬場指数'] = df['レース印１'] / 10\n",
    "\n",
    "# 基準斤量の計算\n",
    "# 斤量を数値に変換する関数\n",
    "def extract_weight(weight_str):\n",
    "    match = re.search(r'\\d+', weight_str)\n",
    "    return int(match.group()) if match else np.nan\n",
    "\n",
    "# 斤量を数値に変換\n",
    "df['斤量'] = df['斤量'].apply(extract_weight)\n",
    "\n",
    "# 基準斤量の計算\n",
    "df['基準斤量'] = df['斤量'] - df['馬齢斤量差']\n",
    "\n",
    "# 競争種別コードの分類関数\n",
    "def categorize_race_type(race_type):\n",
    "    if race_type == 11:\n",
    "        return 'サラブレッド系2歳'\n",
    "    elif race_type == 12:\n",
    "        return 'サラブレッド系3歳'\n",
    "    elif race_type >= 13:\n",
    "        return 'サラブレッド系3歳以上'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# クラスコードの分類関数\n",
    "def categorize_class_code(class_code):\n",
    "    if 7 <= class_code <= 15:\n",
    "        return '新馬・未勝利'\n",
    "    elif class_code == 23:\n",
    "        return '1勝クラス'\n",
    "    elif class_code == 43:\n",
    "        return '2勝クラス'\n",
    "    elif class_code == 67:\n",
    "        return '3勝クラス'\n",
    "    elif class_code >= 114:\n",
    "        return 'OP・重賞'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Target出力ファイルに競争種別とクラスコードの分類カラムを追加\n",
    "df['Race_Type_Category'] = df['競走種別'].apply(categorize_race_type)\n",
    "df['Class_Code_Category'] = df['クラスコード'].apply(categorize_class_code)\n",
    "\n",
    "# スローorハイ関数の範囲を定義\n",
    "ranges = [\n",
    "    (-np.inf, -4.6),\n",
    "    (-4.5, -3.6),\n",
    "    (-3.5, -2.6),\n",
    "    (-2.5, -1.6),\n",
    "    (-1.5, -0.6),\n",
    "    (-0.5, 0.5),\n",
    "    (0.6, 1.5),\n",
    "    (1.6, 2.5),\n",
    "    (2.6, 3.5),\n",
    "    (3.6, 4.5),\n",
    "    (4.6, np.inf)\n",
    "]\n",
    "\n",
    "# スローorハイ関数のラベルを定義 (ペース補正ファイルと統一する)\n",
    "labels = [\n",
    "    '-inf～-4.6', '-4.5～-3.6', '-3.5～-2.6', '-2.5～-1.6', '-1.5～-0.6',\n",
    "    '-0.5～0.5', '0.6～1.5', '1.6～2.5', '2.6～3.5', '3.6～4.5', '4.6～inf'\n",
    "]\n",
    "\n",
    "# Track_Condition の変換\n",
    "df['Track_Condition_Category'] = df['馬場状態'].apply(lambda x: '良・稍' if x in ['良', '稍'] else '重・不' if x in ['重', '不'] else np.nan)\n",
    "\n",
    "# スローorハイ関数を計算\n",
    "df['スローorハイ関数'] = df['Ave-3F'] - df['上り3F']\n",
    "\n",
    "# スローorハイ関数のラベルを設定\n",
    "df['スローorハイ関数範囲'] = pd.cut(df['スローorハイ関数'], bins=[r[0] for r in ranges] + [ranges[-1][1]], labels=labels, right=True)\n",
    "\n",
    "# ベースとなるデータフレーム\n",
    "index_df = df[['レースID(新)',\n",
    "            '場所',\n",
    "            '芝・ダ',\n",
    "            '距離',\n",
    "            'Race_Type_Category',\n",
    "            'Class_Code_Category',\n",
    "            'Track_Condition_Category',\n",
    "            '馬場指数',\n",
    "            '基準斤量',\n",
    "            '斤量',\n",
    "            '走破タイム_秒',\n",
    "            '調整走破タイム',\n",
    "            'Ave-3F',\n",
    "            '上り3F',\n",
    "            'スローorハイ関数',\n",
    "            'スローorハイ関数範囲'\n",
    "            ]]\n",
    "\n",
    "# コース基準タイムファイルのパスを取得（StandardTimes2_を含む最新ファイルを取得）\n",
    "standard_time_file_path1 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/00_StandardTimes3_*.csv'), key=str)\n",
    "\n",
    "# クラス別コース基準タイムファイルのパスを取得（StandardTimes3_を含む最新ファイルを取得）\n",
    "standard_time_file_path2 = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/00_StandardTimes2_*.csv'), key=str)\n",
    "\n",
    "# ペース補正ファイルのパスを取得（10_PacecorrectionTimes1_を含む最新ファイルを取得）\n",
    "pace_setting_file_path = max(glob.glob(r'D:/Keiba/DataTables/30_IndexFiles/10_PacecorrectionTimes1_*.csv'), key=str)\n",
    "\n",
    "# コース基準タイムファイルの読み込み\n",
    "standard_times_df1 = pd.read_csv(standard_time_file_path1, low_memory=False)\n",
    "standard_times_df2 = pd.read_csv(standard_time_file_path2, low_memory=False)\n",
    "\n",
    "# ペース補正ファイルの読み込み\n",
    "pace_setting_df = pd.read_csv(pace_setting_file_path, low_memory=False)\n",
    "\n",
    "# マージのためのカラム名マッピング（基準タイムファイル/Target出力ファイル）\n",
    "column_mappings = {\n",
    "    'Location': '場所',\n",
    "    'Turf_Dirt': '芝・ダ',\n",
    "    'Distance': '距離',\n",
    "    'Track_Condition_Category': '馬場状態',\n",
    "    'Race_Type_Category':'競争種別',\n",
    "    'Class_Code_Category' : 'クラスコード'\n",
    "}\n",
    "\n",
    "\n",
    "# 指数データフレームのカラムリネーム\n",
    "index_df = index_df.rename(columns=column_mappings)\n",
    "\n",
    "# 各基準タイムファイルとマージするためのカラムリネーム\n",
    "standard_times_df1 = standard_times_df1.rename(columns=column_mappings)\n",
    "standard_times_df2 = standard_times_df2.rename(columns=column_mappings)\n",
    "\n",
    "# ペース補正データフレームのカラムリネーム\n",
    "pace_setting_df = pace_setting_df.rename(columns=column_mappings)\n",
    "\n",
    "# 基準タイムファイルをマージ\n",
    "merged_df = pd.merge(\n",
    "    index_df,\n",
    "    standard_times_df1[['場所', '芝・ダ', '距離', '馬場状態','Top3_Average_3F', 'Top3_Finish_Time','Distance_Index']],\n",
    "    on=['場所', '芝・ダ', '距離', '馬場状態'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# クラス別基準タイムファイルをマージ\n",
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    standard_times_df2[['場所', '芝・ダ', '距離', '馬場状態', '競争種別', 'クラスコード', 'Top3_Finish_Time']],\n",
    "    on=['場所', '芝・ダ', '距離', '馬場状態', '競争種別', 'クラスコード'],\n",
    "    how='left',\n",
    "    suffixes=('_standard', '_class')\n",
    ")\n",
    "\n",
    "# ペース補正ファイルをマージ\n",
    "merged_df = pd.merge(\n",
    "    merged_df,\n",
    "    pace_setting_df[['場所', '芝・ダ', '距離', 'スローorハイ関数範囲', 'ペース補正係数']],\n",
    "    on=['場所', '芝・ダ', '距離', 'スローorハイ関数範囲'],\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "# タイム補正値の計算\n",
    "merged_df['タイム補正値'] = (merged_df['Top3_Finish_Time_standard'] - merged_df['調整走破タイム']) * merged_df['Distance_Index']\n",
    "\n",
    "# 平均3Fタイム補正値の計算\n",
    "# 平均3FタイムがNaNの場合は0に置き換え\n",
    "merged_df['Top3_Average_3F'] = merged_df['Top3_Average_3F'].fillna(0)\n",
    "\n",
    "# 平均3Fタイム補正値の計算 (Top3_Average_3FがNaNの場合はAve-3F補正値を0にする)\n",
    "merged_df['Ave-3F補正値'] = np.where(\n",
    "    merged_df['Top3_Average_3F'] == 0,\n",
    "    0,\n",
    "    merged_df['Top3_Average_3F'] - merged_df['Ave-3F']\n",
    ")\n",
    "\n",
    "# 斤量補正値の計算\n",
    "merged_df['斤量補正値'] = (merged_df['斤量'] - merged_df['基準斤量']) / merged_df['Distance_Index']\n",
    "\n",
    "# クラス補正値の計算\n",
    "merged_df['クラス補正値'] = merged_df['Top3_Finish_Time_standard'] - merged_df['Top3_Finish_Time_class']\n",
    "\n",
    "# クラス補正値を -2 から +2 の範囲に収める\n",
    "merged_df['クラス補正値'] = np.clip(merged_df['クラス補正値'], -2, 2)\n",
    "\n",
    "# ペース補正値の計算\n",
    "# ペース補正係数がNaNの場合は0に置き換え\n",
    "merged_df['ペース補正係数'] = merged_df['ペース補正係数'].fillna(0)\n",
    "merged_df['ペース補正値'] = merged_df['スローorハイ関数'] * merged_df['ペース補正係数']\n",
    "\n",
    "# スピード指数の計算\n",
    "merged_df['スピード指数'] = round(merged_df['タイム補正値'] + merged_df['Ave-3F補正値'] + merged_df['馬場指数'] + merged_df['斤量補正値'] + merged_df['クラス補正値'] + merged_df['ペース補正値'] + 70,1)\n",
    "\n",
    "# スピード指数のデータフレーム\n",
    "speedindex_df = merged_df[['レースID(新)','スピード指数']]\n",
    "\n",
    "# データフレームをcsvファイルで保存\n",
    "output_path = f'D:/Keiba/Importdata/40_Speed_Score/SpeedScore_{datetime.now().strftime(\"%Y%m%d\")}.csv'\n",
    "speedindex_df.to_csv(output_path, index=False, encoding='utf_8_sig')\n",
    "print(f\"結果を{output_path}に保存しました。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
